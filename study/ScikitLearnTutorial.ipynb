{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) 사이킷런 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 사이킷런 기반 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런은 <ins>머신러닝 모델 학습</ins>을 위한 `fit` 함수와 <ins>학습된 모델의 예측</ins>을 위한 `predict` 함수를 제공한다.\n",
    "- 지도 학습의 주요 두 축인 **분류(Classification)** 와 **회귀(Regression)** 의 알고리즘을 구현하기 위한 목적으로, 사이킷런에서는 분류 알고리즘을 위한 클래스를 `Classifier`로, 회귀 알고리즘을 위한 클래스를 `Regressor`로 지칭한다.\n",
    "- 또한, 지도 학습의 모든 알고리즘을 구현한 클래스를 통칭해서 `Estimator`라고 부른다.\n",
    "- `Estimator` 클래스는 `fit` 함수와 `predict` 함수를 내부에서 제공하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/tHxOf/btqCbUw5TZM/9pkKG6suDzXZK2qwPHpEA1/img.png\" height=\"350\" alt=\"사이킷런 구현 클래스\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 사이킷런의 주요 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 예제 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.datasets` : 예제 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 변수 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn.preprocessing` \n",
    "    - 데이터 전처리에 필요한 다양한 기능 제공 (인코딩, 정규화, 스케일링 등)\n",
    "- `sklearn.feature_selection`\n",
    "    -  알고리즘에 큰 영향을 미치는 변수를 선택하는 작업을 수행하는 다양한 기능 제공\n",
    "- `sklearn.feature_extraction` \n",
    "    - 텍스트 데이터나 이미지 데이터와 같이 벡터화된 변수를 추출하는 데 사용\n",
    "        - 예) 텍스트 데이터에서 Count Vectorizer 등을 생성하는 기능 제공\n",
    "    - 텍스트 데이터의 변수 추출은 `sklearn.feature_extraction.text` 모듈에 함수가 내장됨.\n",
    "    - 이미지 데이터의 변수 추출은 `sklearn.feature_extraction.image` 모듈에 함수가 내장됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 변수 처리 & 차원 축소\n",
    "- `sklearn.decomposition`\n",
    "    - 차원 축소와 관련된 알고리즘 지원\n",
    "    - **PCA, NMF, Truncated SVD** 등을 통해 차원 축소 기능을 수행할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 데이터 분리, 검증 & 매개변수 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn.model_selection`\n",
    "    - **학습 데이터(Train Data)** 와 **검증 데이터(Validation Data)**, **예측 데이터(Prediction Data)** 로 데이터를 분리하기 위해 사용하는 `train_test_split` 함수가 내장됨.\n",
    "    - 최적의 하이퍼파라미터로 모델을 평가하기 위한 다양한 함수와 기능을 제공함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn.metrics`\n",
    "    - 분류, 회귀, 클러스터링 등에 대한 <ins>다양한 성능 측정 방법</ins>을 제공함.\n",
    "    - 모델 평가를 위한 **Accuracy, Precision, Recall, ROC-AUC, RMSE** 등을 제공함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 머신러닝 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn.ensemble`\n",
    "    - 앙상블 알고리즘 제공\n",
    "    - **랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅** 등을 제공함.\n",
    "- `sklearn.linear_model`\n",
    "    - **선형 회귀, 릿지(Ridge), 라쏘(Lasso)** 및 **로지스틱 회귀** 등의 <ins>회귀(Regression) 관련 알고리즘</ins> 제공\n",
    "    - **SGD(Stochastic Gradient Descent)** 관련 알고리즘도 제공함.\n",
    "- `sklearn.naive_bayes`\n",
    "    - <ins>나이브 베이즈 알고리즘</ins>을 제공함.\n",
    "    - **가우시안 NB, 다항 분포 NB** 등이 있음.\n",
    "- `sklearn.neighbors`\n",
    "    - <ins>최근접 이웃 알고리즘</ins>을 제공함.\n",
    "    - **K-NN** 등이 있음.\n",
    "- `sklearn.svm`\n",
    "    - <ins>서포트 벡터 머신 알고리즘</ins>을 제공함.\n",
    "- `sklearn.tree`\n",
    "    - <ins>트리 기반 머신러닝 알고리즘</ins>을 제공함.\n",
    "    - **의사 결정 트리 알고리즘** 등이 있음.\n",
    "- `sklearn.cluster`\n",
    "    - <ins>비지도 클러스터링 알고리즘</ins>을 제공함.\n",
    "    - **K-평균, 계층형, DBSCAN** 등이 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 유틸리티\n",
    "- `sklearn.pipeline`\n",
    "    - 변수 처리와 같은 <ins>변환 작업</ins>과 머신러닝 알고리즘 학습, 예측 등 <ins>머신러닝 프로세스를 함께 묶어서 실행</ins>할 수 있는 유틸리티를 제공함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 머신러닝 모델 구축 주요 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 학습/데이터 세트 분할\n",
    "2. 데이터 전처리\n",
    "3. 머신러닝 알고리즘을 적용한 모델 구현\n",
    "4. 하이퍼파라미터 변경을 통한 최종 모델 결정\n",
    "5. 성능 평가 과정 반복 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 사이킷런의 내장 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn.datasets` 모듈에 있는 함수를 호출해 <ins>분류</ins>나 <ins>회귀</ins>를 연습하기 위한 데이터 세트를 생성할 수 있다.\n",
    "- 더불어 분류나 클러스터링을 위해 필요한 표본 데이터 세트를 생성할 수 있는 **데이터 생성기 함수** 가 내장되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내장 데이터 세트\n",
    "\n",
    "|함수|설명|\n",
    "|:-:|-|\n",
    "|`datasets.load_boston`| 주로 회귀 목적으로 사용 <br/> 미국 보스턴의 부동산 변수들과 가격에 대한 데이터 세트로 구성|\n",
    "|`datasets.load_breast_cancer`|주로 분류 목적으로 사용 <br/> 위스콘신 유방암 환자의 주요 변수들과 악성/음성 레이블 데이터 세트로 구성|\n",
    "|`datasets.load_diabets`|주로 회귀 목적으로 사용 <br/> 당뇨 환자의 주요 변수들의 데이터 세트로 구성|\n",
    "|`datasets.load_digits`|주로 분류 목적으로 사용 <br/> 0에서 9까지 숫자의 이미지 픽셀 데이터 세트로 구성|\n",
    "|`datasets.load_iris`|주로 분류 목적으로 사용 <br/> 붗꽃에 대한 주요 변수들의 데이터 세트로 구성|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표본 데이터 생성기 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **표본 데이터 생성기 함수** 를 활용하면 <ins>분류</ins>와 <ins>클러스터링</ins>을 위한 데이터 세트를 생성할 수 있다.\n",
    "\n",
    "|함수|설명|\n",
    "|:-:|-|\n",
    "|`datasets.make_classifications`|<ins>분류</ins>를 위한 데이터 세트 생성 <br/> 높은 상관도, 불필요한 속성 등의 노이즈 효과가 적용된 데이터를 무작위로 생성할 수 있음.|\n",
    "|`datasets.make_blobs`|<ins>클러스터링</ins>을 위한 데이터 세트 생성 <br/> 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 세트로 생성할 수 있음.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터세트 타입 :  <class 'sklearn.utils._bunch.Bunch'>\n",
      "붓꽃 데이터세트 키 :  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "print(\"붓꽃 데이터세트 타입 : \", type(iris))\n",
    "\n",
    "keys = iris.keys()\n",
    "print(\"붓꽃 데이터세트 키 : \", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    데이터세트가 <b>딕셔너리</b> 형태이기 때문에 데이터 값을 추출하기 위해서는 <b>iris.data</b> 또는 <b>iris['data']</b>와 같이 <b>data</b> 키를 할당하는 방식으로 프로그래밍해야 한다. <br/>\n",
    "    <b><code style=\"color: black;\">print(iris['target'], iris['feature_names'], iris['DESCR'])    # 데이터 값 추출</code></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names : \n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "target_names : \n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "data : \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      "target : \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 독립변수의 변수명 출력\n",
    "print(\"feature_names : \")     \n",
    "print(iris.feature_names)\n",
    "\n",
    "# 종속변수의 변수명 출력\n",
    "print(\"\\ntarget_names : \")    \n",
    "print(iris.target_names)\n",
    "\n",
    "# 독립변수의 데이터 값 출력\n",
    "print(\"\\ndata : \")    \n",
    "print(iris.data)\n",
    "\n",
    "# 종속변수의 데이터 값 출력\n",
    "print(\"\\ntarget : \")    \n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 사이킷런 머신러닝 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 붓꽃 데이터 세트를 이용하여 붓꽃의 품종을 **분류(Classification)** 해보자.\n",
    "- 붓꽃 데이터 세트는 **꽃잎의 길이와 너비**, **꽃받침의 길이와 너비** 를 <ins>독립 변수</ins>로 구성하고 있으며, **꽃의 품종(Setosa, Versicolor, Virginica)** 을 <ins>종속 변수</ins>로 구성하고 있다.\n",
    "- 분류는 대표적인 지도 학습(Supervised Learning) 방법 중 하나이다.\n",
    "    - 학습을 위한 다양한 피쳐(Feature) 데이터와 분류 결정값인 레이블(Label) 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측하여 분류한다.\n",
    "        - 학습을 위해 주어진 데이터를 **학습 데이터세트** 라고 한다.\n",
    "        - 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트를 **테스트 데이터세트** 라고 한다.\n",
    "    - 명확한 정답이 주어진 데이터를 먼저 학습한 뒤, 미지의 정답을 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)    # 독립 변수의 데이터 출력\n",
    "iris_df['label'] = iris.target    # label 컬럼을 생성한 후, 종속 변수의 변수명을 해당 컬럼에 추가\n",
    "\n",
    "print(iris_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **① 데이터세트 분리** : 데이터세트를 학습 데이터(Train Dataset)과 테스트 데이터(Test Dataset)로 분리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습용 데이터와 테스트 데이터를 분리해보자.\n",
    "- `train_test_split(feature_dataset, target_dataset, test_size, random_state)` 함수를 사용한다.\n",
    "    - `test_size` 입력 매개변수는 <ins>테스트 데이터의 비율</ins>을 나타낸다.\n",
    "    - `random_state`는 함수를 호출할 때마다 같은 학습/테스트 데이터 세트를 생성하기 위해 주어지는 난수 발생 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> All Dataset\n",
      "iris_data :  150\n",
      "\n",
      "> Train Dataset (80%)\n",
      "X_train dataset :  120\n",
      "y_train dataset :  120\n",
      "\n",
      "> Test Dataset (20%)\n",
      "X_test dataset :  30\n",
      "y_test dataset :  30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)    # 데이터 분할 => 테스트 데이터 : 20%, 학습 데이터 : 80% \n",
    "\n",
    "print(\"> All Dataset\")\n",
    "print(\"iris_data : \", len(iris_data))\n",
    "\n",
    "print(\"\\n> Train Dataset (80%)\")\n",
    "print(\"X_train dataset : \", len(X_train))\n",
    "print(\"y_train dataset : \", len(y_train))\n",
    "\n",
    "print(\"\\n> Test Dataset (20%)\")\n",
    "print(\"X_test dataset : \", len(X_test))\n",
    "print(\"y_test dataset : \", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **② 모델 학습** : 학습 데이터를 기반으로 머신러닝 알고리즘에 적용해 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 의사결정 트리를 이용해서 모델 학습을 수행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=11)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "dt_clf.fit(X_train, y_train)    # 모델 학습 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **③ 예측 수행** : 학습된 머신러닝 모델을 이용해 테스트 데이터의 분류(예: 붓꽃 종류)를 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측을 수행해보자. \n",
    "- 예측은 학습 데이터가 아닌 **<ins>테스트 데이터</ins>** 를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = dt_clf.predict(X_test)    # 테스트 데이터 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **④ 평가** : 예측된 결과값과 테스트 데이터의 실제 결과값을 비교해 머신러닝 모델의 성능을 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝 모델의 성능 평가 방법은 여러가지가 있으나, 여기에서는 **정확도** 를 측정해본다.\n",
    "- `accuracy_score(target_dataset, predict_dataset)` 함수를 이용하여 정확도를 측정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "ac_score = accuracy_score(y_test, pred)    # 정확도 구하기\n",
    "\n",
    "print(\"예측 정확도 : \", ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 사이킷런 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런의 머신러닝 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야 할 기본 사항이 있다.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "① <b>사이킷런의 머신러닝 알고리즘에서 결측치(Missing Value)는 허용되지 않는다.</b><br/>\n",
    "- 그러므로 결측치는 고정된 다른 상수로 변환해야 한다. <br/>\n",
    "- 결측치가 얼마 없으면 해당 데이터의 평균값 등으로 간단하게 대체한다. <br/>\n",
    "- 결측치가 대부분이라면 해당 데이터는 삭제하는 것이 좋다. <br/><br/>\n",
    "② <b>사이킷런의 머신러닝 알고리즘은 문자열 값을 허용하지 않는다.</b> <br/>\n",
    "- 모든 문자열 값은 <b>인코딩(Encoding)</b>을 통해 숫자형으로 변환해야 한다. <br/>\n",
    "- 문자열 데이터는 일반적으로 <b>명목형 변수</b>와 <b>텍스트형 변수</b>가 존재할 수 있다. <br/>\n",
    "> <b>명목형 변수</b>는 코드 값으로 변환하여 처리 가능하다. <br/>\n",
    "> <b>텍스트형 변수</b>는 불필요한 변수라고 판단되면 삭제하는 것이 좋다. 왜냐하면 알고리즘을 오히려 복잡하게 만들고 예측 성능을 떨어뜨리기 때문이다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① 레이블 인코딩(Label Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 명목형 변수를 코드형 숫자 값으로 변환하는 것이다.\n",
    "- 예) **[TV, 냉장고, 전자레인지, 컴퓨터]** => TV : `1`, 냉장고 : `2`, 전자레인지 : `3`, 컴퓨터 : `4`\n",
    "\n",
    "<img src=\"https://www.statology.org/wp-content/uploads/2022/08/labelencode2-1.jpg\" alt=\"레이블 인코딩의 예\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값 :  [0 1 2 3 0 1 3 3]\n",
      "인코딩 클래스 :  ['TV' '냉장고' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', 'TV', '냉장고', '컴퓨터', '컴퓨터']\n",
    "\n",
    "encoder = LabelEncoder()    # LabelEncoder 객체 생성\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "print(\"인코딩 변환값 : \", labels)\n",
    "print(\"인코딩 클래스 : \", encoder.classes_)    # 속성값 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인코딩한 값을 다시 **디코딩(Decoding)** 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값 :  ['TV' '냉장고' '전자레인지' '컴퓨터' 'TV' '냉장고' '컴퓨터' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "origins = encoder.inverse_transform([0, 1, 2, 3, 0, 1, 3, 3])    # 디코딩 작업 수행\n",
    "\n",
    "print(\"디코딩 원본값 : \", origins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 숫자 값의 경우 크고 작음에 대한 특성이 작용하기 때문에 레이블 인코딩은 **선형 회귀** 와 같은 알고리즘에는 적합하지 않다.\n",
    "    - 특정 머신러닝 알고리즘에서 가중치가 더 부여되거나 더 중요하게 인식할 가능성이 발생하기 때문이다.\n",
    "- <ins>트리 계열</ins>의 머신러닝 알고리즘은 숫자의 이러한 특성을 반영하지 않으므로 레이블 인코딩을 활용해도 큰 영향이 없다.\n",
    "- **원-핫 인코딩(One-Hot Encoding)** 은 레이블 인코딩의 이러한 문제점을 해결하기 위해 등장하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② 원-핫 인코딩(One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변수 값의 유형에 따라 새로운 변수를 추가해 고윳값에 해당하는 컬럼에만 `1`을 표시하고, 나머지 컬럼에는 `0`을 표시한다.\n",
    "    - <ins>행 형태</ins>로 되어 있는 변수의 고윳값을 <ins>열 형태</ins>로 차원을 변환한 뒤, 고윳값에 해당하는 컬럼에만 `1`을 표시하고, 나머지 컬럼에는 `0`을 표시한다.\n",
    "\n",
    "<img src=\"https://velog.velcdn.com/images/tacohun21/post/ab9c8090-6dbc-40d3-a1d3-ae35cfa2dcad/image.png\" alt=\"원-핫 인코딩의 예\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원-핫 인코딩은 라벨 인코딩과 다르게 주의할 점이 있다.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "① OneHotEncoder로 변환하기 전에 모든 문자열 값이 <ins>숫자형</ins> 값으로 변환되어야 한다. <br/>\n",
    "② 입력 값으로 <ins>2차원 데이터</ins>가 필요하다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "labels = labels.reshape(-1, 1)    # 2차원 형태로 변환 (labels은 이미 라벨 인코딩 실습을 통해 숫자형으로 변환된 상태이다.)\n",
    "\n",
    "oh_encoder = OneHotEncoder()    # OneHotEncoder 객체 생성\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "\n",
    "print(\"원-핫 인코딩 데이터\")\n",
    "print(oh_labels.toarray())\n",
    "\n",
    "print(\"\\n원-핫 인코딩 데이터 차원\")\n",
    "print(oh_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas에서 `get_dummies` 함수를 사용하면 원-핫 인코딩을 더 쉽게 수행할 수 있다.\n",
    "    - 명목형 데이터를 <ins><b>숫자형</b>으로 변환할 필요 없이</ins> 바로 <ins>2차원 데이터로 변환</ins>하여 인코딩을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_전자레인지  item_컴퓨터\n",
       "0     True     False       False     False\n",
       "1    False      True       False     False\n",
       "2    False     False        True     False\n",
       "3    False     False       False      True\n",
       "4     True     False       False     False\n",
       "5    False      True       False     False\n",
       "6    False     False       False      True\n",
       "7    False     False       False      True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "item_df = pd.DataFrame({'item' : items})\n",
    "pd.get_dummies(item_df)    # 원-핫 인코딩 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ 스케일링(Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
    "- 스케일링의 대표적인 방법으로 **표준화(Standardization)** 와 **정규화(Normalization)** 가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 표준화(Standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원 데이터를 평균이 `0`이고 분산이 `1`인 정규 분포를 가진 값으로 변환하는 것\n",
    "\n",
    "$$\\frac{x - \\overline{X}(평균)}{s(표준편차)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정규화(Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 서로 다른 변수의 크기를 통일하기 위해 크기를 변환해주는 것\n",
    "- 개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것\n",
    "- **최대-최소 정규화(Min-Max Normalization)** 를 주로 사용한다.\n",
    "\n",
    "$$\\frac{x-x_{min}}{x_{max} - x_{min}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규 분포를 가질 수 있도록 데이터를 변환하는 것은 머신러닝 알고리즘에서 매우 중요하다.\n",
    "- **서포트 벡터 머신(SVM)** 이나 **선형 회귀(Linear Regression), 로지스틱 회귀(Logistic Regression)** 모델은 <ins>데이터가 <b>정규 분포</b>를 가지고 있다고 가정하고 구현되었기 때문</ins>에 전처리 과정을 통해 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 예제 : `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 스케일링 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값 : \n",
      " sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값 : \n",
      " sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "print(\"feature들의 평균 값 : \\n\", iris_df.mean())\n",
    "print(\"\\nfeature들의 분산 값 : \\n\", iris_df.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 스케일링 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값 : \n",
      " sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값 : \n",
      " sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()    # StandardScaler 객체 생성\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print(\"feature들의 평균 값 : \\n\", iris_df_scaled.mean())\n",
    "print(\"\\nfeature들의 분산 값 : \\n\", iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "모든 컬럼 값의 <b>평균</b>이 0에 아주 가까운 값으로, 그리고 <b>분산</b>은 1에 아주 가까운 값으로 변환되었음을 확인할 수 있다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 예제 : `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `MinMaxScaler`는 데이터값을 `0`과 `1` 사이의 범위 값으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최소 값 : \n",
      " sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최대 값 : \n",
      " sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()     # MinMaxScaler 객체 생성\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\\\n",
    "\n",
    "print(\"feature들의 최소 값 : \\n\", iris_df_scaled.min())\n",
    "print(\"\\nfeature들의 최대 값 : \\n\", iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>fit</b>은 데이터 변환을 위한 기준 정보 설정을 적용한다. <br/>\n",
    "<b>transform</b>은 이렇게 설정된 정보를 이용해 데이터를 변환한다. <br/>\n",
    "<b>fit_transform</b>은 <b>fit</b>과 <b>transform</b>을 한 번에 적용한다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터와 테스트 데이터세트에 이 `fit`과 `transform`을 적용할 때 주의할 부분이 있다.\n",
    "    - <ins>학습 데이터</ins>로 `fit`을 수행한 결과를 이용해 `transform` 변환을 적용해야 한다.\n",
    "        - 그렇지 않을 경우, 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 서로 달라져 올바른 예측 결과를 도출하지 못할 수도 있다.\n",
    "- 머신러닝 모델은 <ins>학습 데이터</ins>를 기반으로 학습되기 때문에 반드시 테스트 데이터는 학습 데이터의 스케일링 기준을 따라야 한다.\n",
    "    - 따라서 <ins><b>테스트 데이터</b>에 다시 `fit`을 적용해서는 안 되며</ins>, <b>학습 데이터</b>로 이미 `fit`이 적용된 스케일링 객체를 이용해 `transform`으로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터 :  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scaled train_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터 :  [0 1 2 3 4 5]\n",
      "Scaled test_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)    # 2차원 형태로 변환\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)    # 학습 데이터 사용\n",
    "train_scaled = scaler.transform(train_array)    # 학습 데이터 사용\n",
    "\n",
    "print(\"원본 train_array 데이터 : \", np.round(train_array.reshape(-1), 2))\n",
    "print(\"Scaled train_array 데이터 : \", np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "\n",
    "# 잘못된 사용\n",
    "# scaler.fit(test_array)\n",
    "test_scaled = scaler.transform(test_array)    # 테스트 데이터 사용 (잘못된 사용)\n",
    "\n",
    "print(\"\\n원본 test_array 데이터 : \", np.round(test_array.reshape(-1), 2))\n",
    "print(\"Scaled test_array 데이터 : \", np.round(test_scaled.reshape(-1), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
