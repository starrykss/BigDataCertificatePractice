{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합법적인 공식 문서 만들기\n",
    "---\n",
    "\n",
    "https://www.youtube.com/watch?v=2Nf6yAgnZTY&list=PLSlDi2AkDv82Qv7B3WiWypQSFmOCb-G_-&index=13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시험 환경(구름IDE)에서는 자동 완성 기능이 제공되지 않는다.\n",
    "- `dir()`, `help()`, `__all__` 함수와 메모장을 적극적으로 사용하여 필요할 때마다 참고하여 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 풀네임 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dir` 함수를 이용하여 패키지에 포함된 모든 속성과 메서드의 풀네임을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas`의 모든 속성과 메서드를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ArrowDtype', 'BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Flags', 'Float32Dtype', 'Float64Dtype', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt8Dtype', '__all__', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_built_with_meson', '_config', '_is_numpy_dev', '_libs', '_pandas_datetime_CAPI', '_pandas_parser_CAPI', '_testing', '_typing', '_version_meson', 'annotations', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'from_dummies', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n"
     ]
    }
   ],
   "source": [
    "print(dir(pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 메모장\n",
    "\n",
    "```text\n",
    "['ArrowDtype', 'BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Flags', 'Float32Dtype', 'Float64Dtype', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt8Dtype', '__all__', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_built_with_meson', '_config', '_is_numpy_dev', '_libs', '_pandas_datetime_CAPI', '_pandas_parser_CAPI', '_testing', '_typing', '_version_meson', 'annotations', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'from_dummies', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pandas`의 `DataFrame`의 함수들을 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '_AXIS_LEN', '_AXIS_ORDERS', '_AXIS_TO_AXIS_NUMBER', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__arrow_c_stream__', '__bool__', '__class__', '__contains__', '__copy__', '__dataframe__', '__dataframe_consortium_standard__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pandas_priority__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_accum_func', '_agg_examples_doc', '_agg_see_also_doc', '_align_for_op', '_align_frame', '_align_series', '_append', '_arith_method', '_arith_method_with_reindex', '_as_manager', '_box_col_values', '_can_fast_transpose', '_check_inplace_and_allows_duplicate_labels', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_cmp_method', '_combine_frame', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_result', '_constructor', '_constructor_from_mgr', '_constructor_sliced', '_constructor_sliced_from_mgr', '_create_data_for_split_and_tight_to_dict', '_data', '_deprecate_downcast', '_dir_additions', '_dir_deletions', '_dispatch_frame_op', '_drop_axis', '_drop_labels_or_levels', '_ensure_valid_index', '_find_valid_index', '_flex_arith_method', '_flex_cmp_method', '_from_arrays', '_from_mgr', '_get_agg_axis', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cleaned_column_resolvers', '_get_column_array', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_get_values_for_csv', '_getitem_bool_array', '_getitem_multilevel', '_getitem_nocopy', '_getitem_slice', '_gotitem', '_hidden_attrs', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_info_repr', '_init_mgr', '_inplace_method', '_internal_names', '_internal_names_set', '_is_copy', '_is_homogeneous_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_view', '_is_view_after_cow_rules', '_iset_item', '_iset_item_mgr', '_iset_not_inplace', '_iter_column_arrays', '_ixs', '_logical_func', '_logical_method', '_maybe_align_series_as_frame', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_min_count_stat_function', '_needs_reindex_multi', '_pad_or_backfill', '_protect_consolidate', '_reduce', '_reduce_axis1', '_reindex_axes', '_reindex_multi', '_reindex_with_indexers', '_rename', '_replace_columnwise', '_repr_data_resource_', '_repr_fits_horizontal_', '_repr_fits_vertical_', '_repr_html_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_sanitize_column', '_series', '_set_axis', '_set_axis_name', '_set_axis_nocheck', '_set_is_copy', '_set_item', '_set_item_frame_value', '_set_item_mgr', '_set_value', '_setitem_array', '_setitem_frame', '_setitem_slice', '_shift_with_freq', '_should_reindex_frame_op', '_slice', '_sliced_from_mgr', '_stat_function', '_stat_function_ddof', '_take_with_is_copy', '_to_dict_of_blocks', '_to_latex_via_styler', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'apply', 'applymap', 'asfreq', 'asof', 'assign', 'astype', 'at', 'at_time', 'attrs', 'axes', 'backfill', 'between_time', 'bfill', 'bool', 'boxplot', 'clip', 'columns', 'combine', 'combine_first', 'compare', 'convert_dtypes', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'explode', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'from_dict', 'from_records', 'ge', 'get', 'groupby', 'gt', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isetitem', 'isin', 'isna', 'isnull', 'items', 'iterrows', 'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lt', 'map', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pad', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select_dtypes', 'sem', 'set_axis', 'set_flags', 'set_index', 'shape', 'shift', 'size', 'skew', 'sort_index', 'sort_values', 'sparse', 'squeeze', 'stack', 'std', 'style', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_orc', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'to_xml', 'transform', 'transpose', 'truediv', 'truncate', 'tz_convert', 'tz_localize', 'unstack', 'update', 'value_counts', 'values', 'var', 'where', 'xs']\n"
     ]
    }
   ],
   "source": [
    "print(dir(pd.DataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 메모장\n",
    "\n",
    "```text\n",
    "['T', '_AXIS_LEN', '_AXIS_ORDERS', '_AXIS_TO_AXIS_NUMBER', '_HANDLED_TYPES', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__array_ufunc__', '__arrow_c_stream__', '__bool__', '__class__', '__contains__', '__copy__', '__dataframe__', '__dataframe_consortium_standard__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pandas_priority__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_accum_func', '_agg_examples_doc', '_agg_see_also_doc', '_align_for_op', '_align_frame', '_align_series', '_append', '_arith_method', '_arith_method_with_reindex', '_as_manager', '_box_col_values', '_can_fast_transpose', '_check_inplace_and_allows_duplicate_labels', '_check_is_chained_assignment_possible', '_check_label_or_level_ambiguity', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_cmp_method', '_combine_frame', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_result', '_constructor', '_constructor_from_mgr', '_constructor_sliced', '_constructor_sliced_from_mgr', '_create_data_for_split_and_tight_to_dict', '_data', '_deprecate_downcast', '_dir_additions', '_dir_deletions', '_dispatch_frame_op', '_drop_axis', '_drop_labels_or_levels', '_ensure_valid_index', '_find_valid_index', '_flex_arith_method', '_flex_cmp_method', '_from_arrays', '_from_mgr', '_get_agg_axis', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cleaned_column_resolvers', '_get_column_array', '_get_index_resolvers', '_get_item_cache', '_get_label_or_level_values', '_get_numeric_data', '_get_value', '_get_values_for_csv', '_getitem_bool_array', '_getitem_multilevel', '_getitem_nocopy', '_getitem_slice', '_gotitem', '_hidden_attrs', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_info_repr', '_init_mgr', '_inplace_method', '_internal_names', '_internal_names_set', '_is_copy', '_is_homogeneous_type', '_is_label_or_level_reference', '_is_label_reference', '_is_level_reference', '_is_mixed_type', '_is_view', '_is_view_after_cow_rules', '_iset_item', '_iset_item_mgr', '_iset_not_inplace', '_iter_column_arrays', '_ixs', '_logical_func', '_logical_method', '_maybe_align_series_as_frame', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_min_count_stat_function', '_needs_reindex_multi', '_pad_or_backfill', '_protect_consolidate', '_reduce', '_reduce_axis1', '_reindex_axes', '_reindex_multi', '_reindex_with_indexers', '_rename', '_replace_columnwise', '_repr_data_resource_', '_repr_fits_horizontal_', '_repr_fits_vertical_', '_repr_html_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_sanitize_column', '_series', '_set_axis', '_set_axis_name', '_set_axis_nocheck', '_set_is_copy', '_set_item', '_set_item_frame_value', '_set_item_mgr', '_set_value', '_setitem_array', '_setitem_frame', '_setitem_slice', '_shift_with_freq', '_should_reindex_frame_op', '_slice', '_sliced_from_mgr', '_stat_function', '_stat_function_ddof', '_take_with_is_copy', '_to_dict_of_blocks', '_to_latex_via_styler', '_typ', '_update_inplace', '_validate_dtype', '_values', '_where', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'apply', 'applymap', 'asfreq', 'asof', 'assign', 'astype', 'at', 'at_time', 'attrs', 'axes', 'backfill', 'between_time', 'bfill', 'bool', 'boxplot', 'clip', 'columns', 'combine', 'combine_first', 'compare', 'convert_dtypes', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'droplevel', 'dropna', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'explode', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'from_dict', 'from_records', 'ge', 'get', 'groupby', 'gt', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isetitem', 'isin', 'isna', 'isnull', 'items', 'iterrows', 'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lt', 'map', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'ndim', 'ne', 'nlargest', 'notna', 'notnull', 'nsmallest', 'nunique', 'pad', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select_dtypes', 'sem', 'set_axis', 'set_flags', 'set_index', 'shape', 'shift', 'size', 'skew', 'sort_index', 'sort_values', 'sparse', 'squeeze', 'stack', 'std', 'style', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_markdown', 'to_numpy', 'to_orc', 'to_parquet', 'to_period', 'to_pickle', 'to_records', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'to_xml', 'transform', 'transpose', 'truediv', 'truncate', 'tz_convert', 'tz_localize', 'unstack', 'update', 'value_counts', 'values', 'var', 'where', 'xs']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런(`sklearn`)에 포함된 속성과 메서드의 풀네임을 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_BUILT_WITH_MESON', '__SKLEARN_SETUP__', '__all__', '__builtins__', '__cached__', '__check_build', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_config', '_distributor_init', 'base', 'clone', 'config_context', 'exceptions', 'externals', 'get_config', 'logger', 'logging', 'os', 'preprocessing', 'random', 'set_config', 'setup_module', 'show_versions', 'sys', 'utils']\n",
      "['calibration', 'cluster', 'covariance', 'cross_decomposition', 'datasets', 'decomposition', 'dummy', 'ensemble', 'exceptions', 'experimental', 'externals', 'feature_extraction', 'feature_selection', 'gaussian_process', 'inspection', 'isotonic', 'kernel_approximation', 'kernel_ridge', 'linear_model', 'manifold', 'metrics', 'mixture', 'model_selection', 'multiclass', 'multioutput', 'naive_bayes', 'neighbors', 'neural_network', 'pipeline', 'preprocessing', 'random_projection', 'semi_supervised', 'svm', 'tree', 'discriminant_analysis', 'impute', 'compose', 'clone', 'get_config', 'set_config', 'config_context', 'show_versions']\n",
      "\n",
      "['Binarizer', 'FunctionTransformer', 'KBinsDiscretizer', 'KernelCenterer', 'LabelBinarizer', 'LabelEncoder', 'MultiLabelBinarizer', 'MinMaxScaler', 'MaxAbsScaler', 'QuantileTransformer', 'Normalizer', 'OneHotEncoder', 'OrdinalEncoder', 'PowerTransformer', 'RobustScaler', 'SplineTransformer', 'StandardScaler', 'TargetEncoder', 'add_dummy_feature', 'PolynomialFeatures', 'binarize', 'normalize', 'scale', 'robust_scale', 'maxabs_scale', 'minmax_scale', 'label_binarize', 'quantile_transform', 'power_transform']\n",
      "Help on class MinMaxScaler in module sklearn.preprocessing._data:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)\n",
      " |\n",
      " |  Transform features by scaling each feature to a given range.\n",
      " |\n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, e.g. between\n",
      " |  zero and one.\n",
      " |\n",
      " |  The transformation is given by::\n",
      " |\n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |\n",
      " |  where min, max = feature_range.\n",
      " |\n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |\n",
      " |  `MinMaxScaler` doesn't reduce the effect of outliers, but it linearly\n",
      " |  scales them down into a fixed range, where the largest occurring data point\n",
      " |  corresponds to the maximum value and the smallest one corresponds to the\n",
      " |  minimum value. For an example visualization, refer to :ref:`Compare\n",
      " |  MinMaxScaler with other scalers <plot_all_scaling_minmax_scaler_section>`.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |\n",
      " |  copy : bool, default=True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |\n",
      " |  clip : bool, default=False\n",
      " |      Set to True to clip transformed values of held-out data to\n",
      " |      provided `feature range`.\n",
      " |\n",
      " |      .. versionadded:: 0.24\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray of shape (n_features,)\n",
      " |      Per feature adjustment for minimum. Equivalent to\n",
      " |      ``min - X.min(axis=0) * self.scale_``\n",
      " |\n",
      " |  scale_ : ndarray of shape (n_features,)\n",
      " |      Per feature relative scaling of the data. Equivalent to\n",
      " |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
      " |\n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |\n",
      " |  data_min_ : ndarray of shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |\n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |\n",
      " |  data_max_ : ndarray of shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |\n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |\n",
      " |  data_range_ : ndarray of shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |\n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |\n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |\n",
      " |      .. versionadded:: 0.24\n",
      " |\n",
      " |  n_samples_seen_ : int\n",
      " |      The number of samples processed by the estimator.\n",
      " |      It will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |\n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |\n",
      " |      .. versionadded:: 1.0\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  minmax_scale : Equivalent function without the estimator API.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler()\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [ 1. 18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[0.   0.  ]\n",
      " |   [0.25 0.25]\n",
      " |   [0.5  0.5 ]\n",
      " |   [1.   1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[1.5 0. ]]\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.OneToOneFeatureMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, feature_range=(0, 1), *, copy=True, clip=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |\n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |\n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |\n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |\n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |\n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |\n",
      " |  transform(self, X)\n",
      " |      Scale features of X according to feature_range.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |\n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |\n",
      " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Same as input features.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |\n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |\n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |\n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |\n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |\n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |\n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `\"polars\"`: Polars output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |\n",
      " |          .. versionadded:: 1.4\n",
      " |              `\"polars\"` option was added.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      " |      This method is called when a class is subclassed.\n",
      " |\n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  __sklearn_clone__(self)\n",
      " |\n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |\n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |\n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(dir(sklearn))      # 비공개, 공개\n",
    "print(sklearn.__all__)   # 공개\n",
    "\n",
    "print()\n",
    "\n",
    "import sklearn.preprocessing   # 실습 환경에서는 preprocessing을 import 해줘야 한다.\n",
    "print(sklearn.preprocessing.__all__)   # preprocessing에 포함된 모든 메서드 확인\n",
    "print(help(sklearn.preprocessing.MinMaxScaler))   # 사용법 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<aside style=\"background-color: rgba(200, 200, 200, 0.4);\">\n",
    "\n",
    "dir(sklearn)은 sklearn 모듈의 모든 속성(함수, 클래스, 변수 등)을 나열하는 명령어입니다. 이는 모든 공개 및 비공개 속성을 포함하여 외부 사용을 위한 것이든 그렇지 않은 것이든 모두 포함합니다. 이것은 모듈에 있는 모든 것을 종합적으로 살펴볼 때 유용합니다.\n",
    "\n",
    "print(sklearn.__all__)은 모듈에서 \"공개\"로 간주되는 것들을 정의한 문자열 목록인 __all__ 속성을 출력합니다. from sklearn import *을 사용할 때, __all__에 나열된 이름만 가져옵니다. 보통 이는 모듈의 저자가 사용자가 직접 사용할 것으로 의도한 가장 중요한 클래스, 함수 및 변수를 포함합니다. 이것은 모듈의 주요 구성 요소를 이해하는 데 유용합니다.\n",
    "</aside>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 사용법 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `help` 함수를 이용하여 메서드의 사용법을 확인할 수 있다.\n",
    "- `DataFrame` 객체의 `fillna` 메서드에 대한 사용법을 찾아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fillna in module pandas.core.generic:\n",
      "\n",
      "fillna(self, value: 'Hashable | Mapping | Series | DataFrame | None' = None, *, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool_t' = False, limit: 'int | None' = None, downcast: 'dict | None | lib.NoDefault' = <no_default>) -> 'Self | None'\n",
      "    Fill NA/NaN values using the specified method.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    value : scalar, dict, Series, or DataFrame\n",
      "        Value to use to fill holes (e.g. 0), alternately a\n",
      "        dict/Series/DataFrame of values specifying which value to use for\n",
      "        each index (for a Series) or column (for a DataFrame).  Values not\n",
      "        in the dict/Series/DataFrame will not be filled. This value cannot\n",
      "        be a list.\n",
      "    method : {'backfill', 'bfill', 'ffill', None}, default None\n",
      "        Method to use for filling holes in reindexed Series:\n",
      "\n",
      "        * ffill: propagate last valid observation forward to next valid.\n",
      "        * backfill / bfill: use next valid observation to fill gap.\n",
      "\n",
      "        .. deprecated:: 2.1.0\n",
      "            Use ffill or bfill instead.\n",
      "\n",
      "    axis : {0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\n",
      "        Axis along which to fill missing values. For `Series`\n",
      "        this parameter is unused and defaults to 0.\n",
      "    inplace : bool, default False\n",
      "        If True, fill in-place. Note: this will modify any\n",
      "        other views on this object (e.g., a no-copy slice for a column in a\n",
      "        DataFrame).\n",
      "    limit : int, default None\n",
      "        If method is specified, this is the maximum number of consecutive\n",
      "        NaN values to forward/backward fill. In other words, if there is\n",
      "        a gap with more than this number of consecutive NaNs, it will only\n",
      "        be partially filled. If method is not specified, this is the\n",
      "        maximum number of entries along the entire axis where NaNs will be\n",
      "        filled. Must be greater than 0 if not None.\n",
      "    downcast : dict, default is None\n",
      "        A dict of item->dtype of what to downcast if possible,\n",
      "        or the string 'infer' which will try to downcast to an appropriate\n",
      "        equal type (e.g. float64 to int64 if possible).\n",
      "\n",
      "        .. deprecated:: 2.2.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Series/DataFrame or None\n",
      "        Object with missing values filled or None if ``inplace=True``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ffill : Fill values by propagating the last valid observation to next valid.\n",
      "    bfill : Fill values by using the next valid observation to fill the gap.\n",
      "    interpolate : Fill NaN values using interpolation.\n",
      "    reindex : Conform object to new index.\n",
      "    asfreq : Convert TimeSeries to specified frequency.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "    ...                    [3, 4, np.nan, 1],\n",
      "    ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      "    ...                    [np.nan, 3, np.nan, 4]],\n",
      "    ...                   columns=list(\"ABCD\"))\n",
      "    >>> df\n",
      "         A    B   C    D\n",
      "    0  NaN  2.0 NaN  0.0\n",
      "    1  3.0  4.0 NaN  1.0\n",
      "    2  NaN  NaN NaN  NaN\n",
      "    3  NaN  3.0 NaN  4.0\n",
      "\n",
      "    Replace all NaN elements with 0s.\n",
      "\n",
      "    >>> df.fillna(0)\n",
      "         A    B    C    D\n",
      "    0  0.0  2.0  0.0  0.0\n",
      "    1  3.0  4.0  0.0  1.0\n",
      "    2  0.0  0.0  0.0  0.0\n",
      "    3  0.0  3.0  0.0  4.0\n",
      "\n",
      "    Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "    2, and 3 respectively.\n",
      "\n",
      "    >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      "    >>> df.fillna(value=values)\n",
      "         A    B    C    D\n",
      "    0  0.0  2.0  2.0  0.0\n",
      "    1  3.0  4.0  2.0  1.0\n",
      "    2  0.0  1.0  2.0  3.0\n",
      "    3  0.0  3.0  2.0  4.0\n",
      "\n",
      "    Only replace the first NaN element.\n",
      "\n",
      "    >>> df.fillna(value=values, limit=1)\n",
      "         A    B    C    D\n",
      "    0  0.0  2.0  2.0  0.0\n",
      "    1  3.0  4.0  NaN  1.0\n",
      "    2  NaN  1.0  NaN  3.0\n",
      "    3  NaN  3.0  NaN  4.0\n",
      "\n",
      "    When filling using a DataFrame, replacement happens along\n",
      "    the same column names and same indices\n",
      "\n",
      "    >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      "    >>> df.fillna(df2)\n",
      "         A    B    C    D\n",
      "    0  0.0  2.0  0.0  0.0\n",
      "    1  3.0  4.0  0.0  1.0\n",
      "    2  0.0  0.0  0.0  NaN\n",
      "    3  0.0  3.0  0.0  4.0\n",
      "\n",
      "    Note that column D is not affected since it is not present in df2.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(pd.DataFrame.fillna))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
