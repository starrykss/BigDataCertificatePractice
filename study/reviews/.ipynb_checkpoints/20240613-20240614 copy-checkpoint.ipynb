{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[20240613 - 20240614](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [20240613 - 20240614](#toc1_)    \n",
    "  - [제1유형](#toc1_1_)    \n",
    "    - [특정 열 추출](#toc1_1_1_)    \n",
    "    - [특정 행 추출](#toc1_1_2_)    \n",
    "    - [파생 변수 추가](#toc1_1_3_)    \n",
    "    - [원-핫 인코딩](#toc1_1_4_)    \n",
    "    - [데이터를 특정 기준으로 그룹화](#toc1_1_5_)    \n",
    "    - [특정한 열을 기준으로 데이터 정렬](#toc1_1_6_)    \n",
    "    - [데이터 결합](#toc1_1_7_)    \n",
    "    - [데이터 결합 (공통된 열을 하나 이상 가지고 있을 경우)](#toc1_1_8_)    \n",
    "    - [조건에 따라 원하는 값 선택하기](#toc1_1_9_)    \n",
    "    - [결측값 확인 1 : `isna()` 함수](#toc1_1_10_)    \n",
    "    - [결측값 확인 2 : `info()` 함수](#toc1_1_11_)    \n",
    "    - [행별, 컬럼별, 전체 결측값 확인](#toc1_1_12_)    \n",
    "    - [결측값 처리 : 삭제](#toc1_1_13_)    \n",
    "    - [결측값 처리 : 단순 대치](#toc1_1_14_)    \n",
    "    - [이상값 검출 : ESD](#toc1_1_15_)    \n",
    "    - [이상값 검출 : 박스 플롯](#toc1_1_16_)    \n",
    "    - [이상값 검출 : IQR 함수](#toc1_1_17_)    \n",
    "    - [데이터 유형 변환](#toc1_1_18_)    \n",
    "    - [`datetime.strptime` 함수](#toc1_1_19_)    \n",
    "    - [`total_seconds` 함수](#toc1_1_20_)    \n",
    "    - [최소-최대 정규화(Min-Max Normalizaion)](#toc1_1_21_)    \n",
    "    - [표준화 : Z-점수](#toc1_1_22_)    \n",
    "    - [표본 추출 함수 : `random.choice` 함수](#toc1_1_23_)    \n",
    "    - [평균 함수](#toc1_1_24_)    \n",
    "    - [중위수](#toc1_1_25_)    \n",
    "    - [최빈수](#toc1_1_26_)    \n",
    "    - [분산](#toc1_1_27_)    \n",
    "    - [표준편차](#toc1_1_28_)    \n",
    "    - [범위](#toc1_1_29_)    \n",
    "    - [백분위, 사분위수 범위](#toc1_1_30_)    \n",
    "    - [순위 계산](#toc1_1_31_)    \n",
    "    - [반올림, 정수형 변환](#toc1_1_32_)    \n",
    "    - [빈도수 파악](#toc1_1_33_)    \n",
    "    - [요약 통계량 확인](#toc1_1_34_)    \n",
    "    - [범주형 - 범주형 데이터 탐색 : `crosstab()` 함수](#toc1_1_35_)    \n",
    "    - [수치형 - 수치형 데이터 탐색 : `corr()` 함수](#toc1_1_36_)    \n",
    "    - [범주형 - 수치형 데이터 탐색 : `groupby()` 함수](#toc1_1_37_)    \n",
    "    - [전체 데이터 파악](#toc1_1_38_)    \n",
    "  - [제2유형](#toc1_2_)    \n",
    "    - [회귀 모형 평가 : MSE(Mean Squared Error; 평균 제곱 오차)](#toc1_2_1_)    \n",
    "    - [회귀 모형 평가 : 결정 계수(Coefficient of Determination : $R^2$)](#toc1_2_2_)    \n",
    "    - [분류 모형 평가 : 예측 함수](#toc1_2_3_)    \n",
    "    - [분류 모형 평가 : 혼동 행렬](#toc1_2_4_)    \n",
    "      - [1️⃣ 정확도(Accuracy)](#toc1_2_4_1_)    \n",
    "      - [2️⃣ 재현율(Recall)](#toc1_2_4_2_)    \n",
    "      - [3️⃣ 정밀도(Precision)](#toc1_2_4_3_)    \n",
    "      - [4️⃣ F1 지표(F1-Score)](#toc1_2_4_4_)    \n",
    "    - [분류 모형 평가 : AUC(Area Under ROC; AUROC)](#toc1_2_5_)    \n",
    "    - [분석 모형 구축 : 랜덤 포레스트](#toc1_2_6_)    \n",
    "      - [종속 변수 : 범주형 (분류 모델)](#toc1_2_6_1_)    \n",
    "      - [종속 변수 : 수치형 (회귀 모델)](#toc1_2_6_2_)    \n",
    "- [제3유형](#toc2_)    \n",
    "  - [Z-검정(Z-Test)](#toc2_1_)    \n",
    "  - [T-검정(T-Test)](#toc2_2_)    \n",
    "    - [1️⃣ 단일 표본 T-검정(One Sample T-Test)](#toc2_2_1_)    \n",
    "      - [단일 표본 정규성 검정](#toc2_2_1_1_)    \n",
    "        - [① 정규성 가정을 만족할 경우](#toc2_2_1_1_1_)    \n",
    "        - [② 정규성 가정을 만족하지 않을 경우](#toc2_2_1_1_2_)    \n",
    "    - [2️⃣ 쌍체 표본 T-검정(Paired Sample T-Test; 대응 표본 T-검정)](#toc2_2_2_)    \n",
    "    - [3️⃣ 독립 표본 T-검정(Independent Sample T-Test)](#toc2_2_3_)    \n",
    "  - [F-검정(F-Test)](#toc2_3_)    \n",
    "  - [카이제곱 검정(Chi-Squared Test: $\\chi^{2}$ Test)](#toc2_4_)    \n",
    "    - [1️⃣ 적합도 검정(Goodness of Fit Test)](#toc2_4_1_)    \n",
    "    - [2️⃣ 독립성 검정(Test of Independence)](#toc2_4_2_)    \n",
    "    - [3️⃣ 동질성 검정(Test of Homogeneity)](#toc2_4_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[제1유형](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[특정 열 추출](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: sepal length (cm), Length: 150, dtype: float64\n",
      "0      0.2\n",
      "1      0.2\n",
      "2      0.2\n",
      "3      0.2\n",
      "4      0.2\n",
      "      ... \n",
      "145    2.3\n",
      "146    1.9\n",
      "147    2.0\n",
      "148    2.3\n",
      "149    1.8\n",
      "Name: petal width (cm), Length: 150, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "print(df['sepal length (cm)'])   # 'sepal length (cm)' 열 출력\n",
    "print(df.iloc[:, 3])   # 3번째 열 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[특정 행 추출](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal length (cm)  sepal width (cm)\n",
      "0                 5.1               3.5\n",
      "1                 4.9               3.0\n",
      "2                 4.7               3.2\n",
      "3                 4.6               3.1\n",
      "4                 5.0               3.6\n",
      "5                 5.4               3.9\n",
      "6                 4.6               3.4\n",
      "7                 5.0               3.4\n",
      "8                 4.4               2.9\n",
      "9                 4.9               3.1\n",
      "10                5.4               3.7\n",
      "11                4.8               3.4\n",
      "12                4.8               3.0\n",
      "13                4.3               3.0\n",
      "14                5.8               4.0\n",
      "15                5.7               4.4\n",
      "16                5.4               3.9\n",
      "17                5.1               3.5\n",
      "18                5.7               3.8\n",
      "19                5.1               3.8\n",
      "20                5.4               3.4\n",
      "21                5.1               3.7\n",
      "22                4.6               3.6\n",
      "23                5.1               3.3\n",
      "24                4.8               3.4\n",
      "25                5.0               3.0\n",
      "26                5.0               3.4\n",
      "27                5.2               3.5\n",
      "28                5.2               3.4\n",
      "29                4.7               3.2\n",
      "30                4.8               3.1\n",
      "31                5.4               3.4\n",
      "32                5.2               4.1\n",
      "33                5.5               4.2\n",
      "34                4.9               3.1\n",
      "35                5.0               3.2\n",
      "36                5.5               3.5\n",
      "37                4.9               3.6\n",
      "38                4.4               3.0\n",
      "39                5.1               3.4\n",
      "40                5.0               3.5\n",
      "41                4.5               2.3\n",
      "42                4.4               3.2\n",
      "43                5.0               3.5\n",
      "44                5.1               3.8\n",
      "45                4.8               3.0\n",
      "46                5.1               3.8\n",
      "47                4.6               3.2\n",
      "48                5.3               3.7\n",
      "49                5.0               3.3\n",
      "sepal length (cm)    4.6\n",
      "sepal width (cm)     3.1\n",
      "petal length (cm)    1.5\n",
      "petal width (cm)     0.2\n",
      "target               0.0\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "df['target'] = iris.target\n",
    "\n",
    "crit = df['target'] == 0\n",
    "a = df[crit]\n",
    "\n",
    "print(a[['sepal length (cm)', 'sepal width (cm)']])   # 'sepal lenght (cm)', 'sepal width (cm)' 열 출력\n",
    "print(df.iloc[3, ])   # 3번째 행 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[파생 변수 추가](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `apply(method)` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target Len\n",
      "0         0   S\n",
      "1         0   S\n",
      "2         0   S\n",
      "3         0   S\n",
      "4         0   S\n",
      "..      ...  ..\n",
      "145       2   L\n",
      "146       2   L\n",
      "147       2   L\n",
      "148       2   L\n",
      "149       2   S\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "def fn(x):\n",
    "    if x > 6:\n",
    "        return 'L'\n",
    "    else:\n",
    "        return 'S'\n",
    "\n",
    "df['Len'] = df['sepal length (cm)'].apply(fn)   # 파생 변수 추가\n",
    "print(df[['target', 'Len']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_4_'></a>[원-핫 인코딩](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표현하고 싶은 단어의 인덱스에 `1`의 값을 부여하고, 다른 인덱스에는 `0`을 부여한다.\n",
    "- `pd.get_dummies()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B      C      D      E\n",
      "0   True  False  False  False  False\n",
      "1  False   True  False  False  False\n",
      "2  False  False   True  False  False\n",
      "3  False  False  False   True  False\n",
      "4  False  False  False  False   True\n",
      "       B      C      D      E\n",
      "0  False  False  False  False\n",
      "1   True  False  False  False\n",
      "2  False   True  False  False\n",
      "3  False  False   True  False\n",
      "4  False  False  False   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'species': ['A', 'B', 'C', 'D', 'E']\n",
    "})\n",
    "encoded_df = pd.get_dummies(df['species'])\n",
    "print(encoded_df)\n",
    "\n",
    "encoded_df = pd.get_dummies(df['species'], drop_first=True)   # 첫 번째 더미 변수 제거\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_5_'></a>[데이터를 특정 기준으로 그룹화](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `groupby()` 함수를 사용한다.\n",
    "    - `mean()`, `var()`, `std()`, `sum()`, `median()`, `min()`, `max()`, `size()` 함수가 함께 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "target                                                           \n",
      "0                   5.006             3.428              1.462   \n",
      "1                   5.936             2.770              4.260   \n",
      "2                   6.588             2.974              5.552   \n",
      "\n",
      "        petal width (cm)  \n",
      "target                    \n",
      "0                  0.246  \n",
      "1                  1.326  \n",
      "2                  2.026  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "print(df.groupby('target').mean())   # 'target'에 대해 그룹 지정 후 평균 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_6_'></a>[특정한 열을 기준으로 데이터 정렬](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sort_values()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target  sepal length (cm)\n",
      "131       2                7.9\n",
      "135       2                7.7\n",
      "122       2                7.7\n",
      "117       2                7.7\n",
      "118       2                7.7\n",
      "..      ...                ...\n",
      "41        0                4.5\n",
      "42        0                4.4\n",
      "38        0                4.4\n",
      "8         0                4.4\n",
      "13        0                4.3\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "df = df[['target', 'sepal length (cm)']]\n",
    "\n",
    "print(df.sort_values(by=['sepal length (cm)'], ascending=False))   # 내림차순으로 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_7_'></a>[데이터 결합](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pd.concat()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b\n",
      "0  s1  A\n",
      "1  s2  B\n",
      "2  s3  C\n",
      "0  s5  E\n",
      "1  s6  F\n",
      "2  s7  G\n",
      "    a  b   a  b\n",
      "0  s1  A  s5  E\n",
      "1  s2  B  s6  F\n",
      "2  s3  C  s7  G\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame({\n",
    "    'a': ['s1', 's2', 's3'],\n",
    "    'b': ['A', 'B', 'C']\n",
    "})\n",
    "y = pd.DataFrame({\n",
    "    'a': ['s5', 's6', 's7'],\n",
    "    'b': ['E', 'F', 'G']\n",
    "})\n",
    "\n",
    "print(pd.concat([x, y], axis=0))   # axis=0 : 행 기준\n",
    "print(pd.concat([x, y], axis=1))   # axis=1 : 열 기준"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_8_'></a>[데이터 결합 (공통된 열을 하나 이상 가지고 있을 경우)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `merge(left, right, how, on)` 함수를 사용한다.\n",
    "    - `how`\n",
    "        - `inner` : 두 데이터프레임에서 공통으로 존재하는 모든 열 병합\n",
    "        - `left` : 왼쪽 데이터프레임 기준으로 병합\n",
    "        - `right` : 오른쪽 데이터프레임 기준으로 병합\n",
    "        - `outer` : 두 데이터프레임에 존재하는 모든 열을 병합\n",
    "    - `on` : 병합 기준이 되는 열의 이름\n",
    "- 공통된 열을 하나 이상 가지고 있는 두 데이터프레임에 대하여 기준이 되는 특정 컬럼의 값이 같은 행끼리 묶어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name  math  english\n",
      "0    b     2        5\n",
      "1    c     3        4 \n",
      "\n",
      "  name  math  english\n",
      "0    a     1      NaN\n",
      "1    b     2      5.0\n",
      "2    c     3      4.0 \n",
      "\n",
      "  name  math  english\n",
      "0    c   3.0        4\n",
      "1    b   2.0        5\n",
      "2    d   NaN        6 \n",
      "\n",
      "  name  math  english\n",
      "0    a   1.0      NaN\n",
      "1    b   2.0      5.0\n",
      "2    c   3.0      4.0\n",
      "3    d   NaN      6.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame({\n",
    "    'name': ['a', 'b', 'c'],\n",
    "    'math': [1, 2, 3]\n",
    "})\n",
    "y = pd.DataFrame({\n",
    "    'name': ['c', 'b', 'd'],\n",
    "    'english': [4, 5, 6]\n",
    "})\n",
    "\n",
    "print(pd.merge(x, y, how='inner', on='name'), '\\n')\n",
    "print(pd.merge(x, y, how='left', on='name'), '\\n')\n",
    "print(pd.merge(x, y, how='right', on='name'), '\\n')\n",
    "print(pd.merge(x, y, how='outer', on='name'), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_9_'></a>[조건에 따라 원하는 값 선택하기](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.where()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "print(a)\n",
    "\n",
    "cond = a > 2\n",
    "b = np.where(cond, 2, a)   # cond가 True 이면 2, False이면 a를 반환\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_10_'></a>[결측값 확인 1 : `isna()` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `isna()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0     41.0    190.0   7.4    67      5    1\n",
      "1     36.0    118.0   8.0    72      5    2\n",
      "2     12.0    149.0  12.6    74      5    3\n",
      "3     18.0    313.0  11.5    62      5    4\n",
      "4      NaN      NaN  14.3    56      5    5\n",
      "..     ...      ...   ...   ...    ...  ...\n",
      "148   30.0    193.0   6.9    70      9   26\n",
      "149    NaN    145.0  13.2    77      9   27\n",
      "150   14.0    191.0  14.3    75      9   28\n",
      "151   18.0    131.0   8.0    76      9   29\n",
      "152   20.0    223.0  11.5    68      9   30\n",
      "\n",
      "[153 rows x 6 columns]\n",
      "     Ozone  Solar.R   Wind   Temp  Month    Day\n",
      "0    False    False  False  False  False  False\n",
      "1    False    False  False  False  False  False\n",
      "2    False    False  False  False  False  False\n",
      "3    False    False  False  False  False  False\n",
      "4     True     True  False  False  False  False\n",
      "..     ...      ...    ...    ...    ...    ...\n",
      "148  False    False  False  False  False  False\n",
      "149   True    False  False  False  False  False\n",
      "150  False    False  False  False  False  False\n",
      "151  False    False  False  False  False  False\n",
      "152  False    False  False  False  False  False\n",
      "\n",
      "[153 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "print(airquality)\n",
    "print(airquality.isna())   # 결측값 확인 (결측값일 경우 True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_11_'></a>[결측값 확인 2 : `info()` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `info()` 함수를 사용하여 데이터프레임의 크기, 열의 이름과 개수, 각 열의 데이터 타입, 결측치의 개수 등을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Ozone    116 non-null    float64\n",
      " 1   Solar.R  146 non-null    float64\n",
      " 2   Wind     153 non-null    float64\n",
      " 3   Temp     153 non-null    int64  \n",
      " 4   Month    153 non-null    int64  \n",
      " 5   Day      153 non-null    int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "print(airquality.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_12_'></a>[행별, 컬럼별, 전체 결측값 확인](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      2\n",
      "      ..\n",
      "148    0\n",
      "149    1\n",
      "150    0\n",
      "151    0\n",
      "152    0\n",
      "Length: 153, dtype: int64 \n",
      "\n",
      "44 \n",
      "\n",
      "Ozone      37\n",
      "Solar.R     7\n",
      "Wind        0\n",
      "Temp        0\n",
      "Month       0\n",
      "Day         0\n",
      "dtype: int64 \n",
      "\n",
      "44 \n",
      "\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "\n",
    "print(airquality.isna().sum(axis=1), '\\n')         # 행별 결측값 개수\n",
    "print(airquality.isna().sum(axis=1).sum(), '\\n')   # 행별 결측값 개수의 총합\n",
    "print(airquality.isna().sum(axis=0), '\\n')         # 열별 결측값 개수\n",
    "print(airquality.isna().sum(axis=0).sum(), '\\n')   # 열별 결측값 개수의 총합\n",
    "\n",
    "print(airquality.shape[0] - airquality.dropna().shape[0])  # 전체 행의 개수 - 결측값을 제거한 후의 전체 행의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_13_'></a>[결측값 처리 : 삭제](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `drop()` 또는 `dropna()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ozone      0\n",
      "Solar.R    0\n",
      "Wind       0\n",
      "Temp       0\n",
      "Month      0\n",
      "Day        0\n",
      "dtype: int64\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "148    0\n",
      "149    0\n",
      "150    0\n",
      "151    0\n",
      "152    0\n",
      "Length: 153, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "\n",
    "# 결측값이 있는 행 삭제\n",
    "airquality1 = airquality.dropna(axis=0)   # 결측값이 있는 행 제거\n",
    "print(airquality1.isna().sum(axis=0))   # 컬럼별 결측값 개수 확인\n",
    "\n",
    "# 결측값이 있는 열 삭제\n",
    "airquality2 = airquality.dropna(axis=1)   # 결측값이 있는 행 제거\n",
    "print(airquality2.isna().sum(axis=1))   # 행별 결측값 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_14_'></a>[결측값 처리 : 단순 대치](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `fillna()` 함수를 사용하여 평균(`mean`), 중위수(`median`) 등으로 결측값을 대치할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ozone\n",
      "False    116\n",
      "True      37\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Ozone\n",
      "False    153\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "32.987884514433944\n",
      "28.693372188220756\n",
      "4.294512326213187\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 평균값으로 대치\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "\n",
    "print(pd.isna(airquality['Ozone']).value_counts(), '\\n')    # 결측값 개수 확인\n",
    "airquality['Ozone'] = airquality['Ozone'].fillna(airquality['Ozone'].mean())   # 평균값으로 결측값 대치\n",
    "print(pd.isna(airquality['Ozone']).value_counts(), '\\n')    # 결측값 개수 확인\n",
    "\n",
    "# 평균값으로 결측값 대치 전과 후의 표준편차의 차이 구하기\n",
    "airquality = pd.read_csv('./datasets/airquality.csv')\n",
    "\n",
    "a = airquality['Ozone'].std()\n",
    "print(a)\n",
    "\n",
    "airquality['Ozone'] = airquality['Ozone'].fillna(airquality['Ozone'].mean())   # 평균값으로 결측값 대치\n",
    "\n",
    "b = airquality['Ozone'].std()\n",
    "print(b)\n",
    "\n",
    "print(np.abs(a - b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_15_'></a>[이상값 검출 : ESD](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu - 3\\sigma < X < \\mu + 3\\sigma \\Leftrightarrow |\\frac{X - \\mu}{\\sigma}| < 3$$\n",
    "\n",
    "- $\\mu$ : 평균\n",
    "- $\\sigma$ : 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    score name\n",
      "0       1    A\n",
      "1       1    B\n",
      "2       1    C\n",
      "3       1    D\n",
      "4       1    E\n",
      "5       1    F\n",
      "6       1    G\n",
      "7       1    H\n",
      "8       1    I\n",
      "9       1    J\n",
      "10      1    K\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'score': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10000000000],\n",
    "    'name': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "})\n",
    "\n",
    "def esd(x):\n",
    "    return abs((x - x.mean()) / x.std()) < 3\n",
    "\n",
    "crit = esd(df['score'])\n",
    "print(df[crit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_16_'></a>[이상값 검출 : 박스 플롯](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `boxplot()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n",
      "65.0\n",
      "70.0\n",
      "75.0\n",
      "75.0\n",
      "[200]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'score': [65, 60, 70, 75, 200],\n",
    "    'name': ['A', 'B', 'C', 'D', 'E']\n",
    "})\n",
    "box_score = plt.boxplot(df['score'])\n",
    "\n",
    "minimum = box_score['whiskers'][0].get_ydata()[1]\n",
    "q1 = box_score['boxes'][0].get_ydata()[1]\n",
    "q2 = box_score['medians'][0].get_ydata()[0]\n",
    "q3 = box_score['boxes'][0].get_ydata()[2]\n",
    "maximum = box_score['whiskers'][1].get_ydata()[1]\n",
    "\n",
    "outliers = []\n",
    "\n",
    "for point in df['score']:\n",
    "    if point < minimum or point > maximum:\n",
    "        outliers.append(point)\n",
    "\n",
    "print(minimum)\n",
    "print(q1)\n",
    "print(q2)\n",
    "print(q3)\n",
    "print(maximum)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_17_'></a>[이상값 검출 : IQR 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<정상값> \n",
      "    score  name\n",
      "0     65   Kim\n",
      "1     60  Park\n",
      "2     70    Yu\n",
      "3     75    Jo\n",
      "\n",
      "<이상값> \n",
      "    score  name\n",
      "4    200  Jung\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'score': [65, 60, 70, 75, 200],\n",
    "    'name': ['Kim', 'Park', 'Yu', 'Jo', 'Jung']\n",
    "})\n",
    "\n",
    "# |값| < Q2 - 2*IQR\n",
    "target = df['score']\n",
    "min_score = target.median() - 2 * iqr(target)\n",
    "max_score = target.median() + 2 * iqr(target)\n",
    "\n",
    "# 이상값이 아닌 값들만 출력\n",
    "crit1 = (target >= min_score) & (target <= max_score)\n",
    "print(\"<정상값> \\n\", df[crit1])\n",
    "\n",
    "print()\n",
    "\n",
    "# 이상값 출력\n",
    "crit2 = (target < min_score) | (target > max_score)\n",
    "print(\"<이상값> \\n\", df[crit2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_18_'></a>[데이터 유형 변환](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `astype()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Class   6 non-null      int64  \n",
      " 1   Age     6 non-null      float64\n",
      " 2   Part    6 non-null      int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 276.0 bytes\n",
      "None \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   Class   6 non-null      category\n",
      " 1   Age     6 non-null      int32   \n",
      " 2   Part    6 non-null      float64 \n",
      "dtypes: category(1), float64(1), int32(1)\n",
      "memory usage: 342.0 bytes\n",
      "None \n",
      "\n",
      "  Class  Age  Part\n",
      "0     1    1   1.0\n",
      "1     2    2   2.0\n",
      "2     3    3   3.0\n",
      "3     1    1   1.0\n",
      "4     2    2   2.0\n",
      "5     1    1   1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Class': [1, 2, 3, 1, 2, 1],\n",
    "    'Age': [1, 3.2, 11.8, 33.2, 42.9, 33.2],\n",
    "    'Part': [3, 7, 2, 1, 3, 5]\n",
    "})\n",
    "\n",
    "print(df.info(), '\\n')\n",
    "\n",
    "df['Class'] = df['Class'].astype('category')   # 범주형으로 변환\n",
    "df['Age'] = df['Class'].astype('int')          # int 형으로 변환\n",
    "df['Part'] = df['Class'].astype('float')       # float 형으로 변환\n",
    "\n",
    "print(df.info(), '\\n')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_19_'></a>[`datetime.strptime` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자열을 `datetime` 객체로 변환하는데 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 3 1\n",
      "1999 3 1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "a = datetime.strptime(\"1999 March 1\", \"%Y %B %d\")\n",
    "y = a.year\n",
    "m = a.month\n",
    "d = a.day\n",
    "\n",
    "print(f\"{y} {m} {d}\")\n",
    "\n",
    "b = datetime.strptime(\"3-1 1919\", \"%m-%d %Y\")\n",
    "y = a.year\n",
    "m = a.month\n",
    "d = a.day\n",
    "\n",
    "print(f\"{y} {m} {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_20_'></a>[`total_seconds` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 객체가 나타내는 총 초수 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "x = datetime(1999, 3, 1, 12, 1, 0)    # 1999년 3월 1일 12시 1분 0초\n",
    "y = datetime(1999, 3, 1, 12, 2, 0)    # 1999년 3월 1일 12시 2분 0초\n",
    "z = (x - y).total_seconds()\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_21_'></a>[최소-최대 정규화(Min-Max Normalizaion)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규화는 데이터의 범위를 `0`과 `1` 사이로 변환하여 데이터의 분포를 조정하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MinMax = \\frac{X - Min}{Max - Min}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sklearn`의 `MinMaxScaler` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,) \n",
      " [1 3 5 7 9]\n",
      "(5, 1) \n",
      " [[1]\n",
      " [3]\n",
      " [5]\n",
      " [7]\n",
      " [9]]\n",
      "[0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = np.array([1, 3, 5, 7, 9])\n",
    "\n",
    "# MinMaxScaler를 사용하려면 데이터를 2차원으로 바꿔주어야 한다.\n",
    "print(data.shape, \"\\n\", data)\n",
    "x = data.reshape(-1, 1)\n",
    "print(x.shape, \"\\n\", x)\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "scaled_data = mms.fit_transform(x)\n",
    "\n",
    "print(scaled_data.flatten())    # 2차원 -> 1차원으로 변환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `numpy`로 직접 함수 만들어서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 3, 5, 7, 9])\n",
    "\n",
    "def minmax(arr):\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "\n",
    "print(minmax(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_22_'></a>[표준화 : Z-점수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표준화는 어떤 특정값들이 정규 분포를 따른다고 가정하고 값들을 `0`의 평균, `1`의 표준편차를 갖도록 해주는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z = \\frac{X - \\overline{X}}{s}$$\n",
    "\n",
    "- $s$ : 표본표준편차\n",
    "- $\\overline{X}$ : 표본평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4408920985006264e-17\n",
      "1.0\n",
      "[-1.26491106 -0.63245553  0.          0.63245553  1.26491106]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 3, 5, 7, 9])\n",
    "\n",
    "def standardize(a):\n",
    "    return (a - np.mean(a)) / np.std(a, ddof=1)  # (값 - 평균) / 표준편차\n",
    "\n",
    "data_zscore = standardize(data)\n",
    "print(np.mean(data_zscore))   # 평균\n",
    "print(np.std(data_zscore, ddof=1))   # 표준편차\n",
    "print(data_zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_23_'></a>[표본 추출 함수 : `random.choice` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순 무작위 추출을 수행하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  9  7 10  2]\n",
      "[6 9 1 8 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numbers = np.arange(1, 11)\n",
    "\n",
    "s = np.random.choice(numbers, size=5, replace=False)   # 비복원 추출\n",
    "print(s)\n",
    "\n",
    "s = np.random.choice(numbers, size=5, replace=True)    # 복원 추출\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_24_'></a>[평균 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자료를 모두 더한 후 자료 개수로 나눈 값\n",
    "- `np.mean()`, `trim_mean()`, `np.nanmean()`을 사용한다.\n",
    "    - `trim_mean()`을 사용하려면 `scipy.stats`를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.48076923076923\n",
      "25.5\n",
      "nan\n",
      "4.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "x = np.concatenate([np.arange(0, 51), [50]])\n",
    "\n",
    "print(np.mean(x))   # 평균\n",
    "print(trim_mean(x, 0.10))   # 양끝에서 10%를 제외한 후 평균\n",
    "\n",
    "y = np.array([12, 7, 4, -5, np.nan])\n",
    "print(np.mean(y))   # 평균\n",
    "print(np.nanmean(y))   # NaN을 제외한 후의 평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_25_'></a>[중위수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 데이터값을 순서대로 배열하였을 때 중앙에 위치한 데이터값\n",
    "- `np.median()`, `np.nanmedian()`을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "5.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([12, 7, 4, -5, np.nan])\n",
    "print(np.median(x))    # 중위수\n",
    "print(np.nanmedian(x))   # 결측값을 제거한 후 중위수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_26_'></a>[최빈수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터값 중에서 빈도수가 가장 높은 데이터 값\n",
    "- `np.bincount(arr).argmax()` 함수를 사용한다.\n",
    "    - `bincount` 함수를 통해 각 요소의 빈도를 계산하여 반환하고, `argmax` 함수를 사용하여 최댓값의 인덱스인 최빈수를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([2, 1, 1, 3, 1])\n",
    "print(np.bincount(x).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_27_'></a>[분산](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 평균으로부터 얼마나 떨어져 있는지를 나타내는 값\n",
    "- `np.var()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([3, 4, 5, 2, 4, 3, 4])\n",
    "print(np.var(x, ddof=1))     # ddof=0 : 모집단, ddof=1 : 표본집단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_28_'></a>[표준편차](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분산에서 양의 제곱근을 취한 값 ($\\sqrt{분산}$)\n",
    "- `np.std()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9759000729485333\n",
      "2.258317958127243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([3, 4, 5, 2, 4, 3, 4])   # 표준편차\n",
    "print(np.std(x, ddof=1))     # ddof=0 : 모집단, ddof=1 : 표본집단\n",
    "\n",
    "y = np.array([3, np.nan, 2, 3, 8, 3, 2])    # 결측값을 제거한 표준편차\n",
    "print(np.nanstd(y, ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_29_'></a>[범위](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최댓값에서 최솟값을 뺸 값\n",
    "- `np.ptp()`(Peak to Peak) 함수를 사용한다.\n",
    "    - 또는 `np.min()`, `np.max()`, `np.abs()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 7, 3, 5, 11, 4, 6])\n",
    "\n",
    "# 범위 구하기 1\n",
    "print(np.ptp(x))\n",
    "\n",
    "# 범위 구하기 2\n",
    "min_value = np.min(x)\n",
    "max_value = np.max(x)\n",
    "print(np.abs(min_value - max_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_30_'></a>[백분위, 사분위수 범위](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `percentile()` 함수를 사용하여 백분위를 계산할 수 있다.\n",
    "- `iqr()` 함수를 사용하여 사분위수 범위를 계산할 수 있다.\n",
    "    - $IQR = Q_3 - Q_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import iqr\n",
    "\n",
    "x = np.array([3, 4, 5, 2, 4, 3, 4])\n",
    "\n",
    "q1 = np.percentile(x, 25)\n",
    "q3 = np.percentile(x, 75)\n",
    "\n",
    "iqr1 = q3 - q1    # Q3 - Q1\n",
    "iqr2 = iqr(x)   # IQR\n",
    "\n",
    "print(iqr1)\n",
    "print(iqr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_31_'></a>[순위 계산](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pd.Series(x).rank(method)` 함수를 사용한다.\n",
    "    - `method`\n",
    "        - `average` : 동일한 값을 가진 항목들 -> 평균 순위 부여 (기본값)\n",
    "        - `first` : 데이터가 나타나는 순서대로 부여\n",
    "        - `min` : 동일한 값을 가진 항목들 -> 가장 작은 순위 부여\n",
    "        - `dense` : 순위를 부여할 때 연속적인 정수를 사용하여 순위 부여\n",
    "        - (예) 1등=2등 > 3등\n",
    "            - `first` : 1, 2, 3\n",
    "            - `min` : 1, 1, 3\n",
    "            - `dense` : 1, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.5\n",
      "1    1.5\n",
      "2    3.0\n",
      "3    5.0\n",
      "4    4.0\n",
      "dtype: float64 \n",
      "\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    5.0\n",
      "4    4.0\n",
      "dtype: float64 \n",
      "\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    3.0\n",
      "3    5.0\n",
      "4    4.0\n",
      "dtype: float64 \n",
      "\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    2.0\n",
      "3    4.0\n",
      "4    3.0\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = np.array([1, 1, 5, 9, 7])\n",
    "\n",
    "print(pd.Series(x).rank(method='average'), '\\n')   # 평균\n",
    "print(pd.Series(x).rank(method='first'), '\\n')  # 데이터가 나타나는 순서대로\n",
    "print(pd.Series(x).rank(method='min'), '\\n')   # 동일한 값 -> 가장 작은 순위\n",
    "print(pd.Series(x).rank(method='dense'), '\\n')   # 연속적인 정수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_32_'></a>[반올림, 정수형 변환](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `round()` 함수를 사용하여 반올림한다.\n",
    "- `int()` 함수를 사용하여 정수형으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(round(3.1425, 2))    # 소수 둘째 자리까지 표현 (셋째 자리에서 반올림)\n",
    "print(int(3.1425))   # 정수형 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_33_'></a>[빈도수 파악](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `value_counts()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyl\n",
      "8    14\n",
      "4    11\n",
      "6     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mtcars = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "print(pd.Series(mtcars['cyl']).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_34_'></a>[요약 통계량 확인](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `describe()` 함수를 사용한다.\n",
    "- 최솟값, 제1사분위수, 중위수, 평균, 제3사분위수, 최댓값 등의 요약 통계량을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    32.000000\n",
      "mean      3.217250\n",
      "std       0.978457\n",
      "min       1.513000\n",
      "25%       2.581250\n",
      "50%       3.325000\n",
      "75%       3.610000\n",
      "max       5.424000\n",
      "Name: wt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mtcars = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "print(mtcars['wt'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_35_'></a>[범주형 - 범주형 데이터 탐색 : `crosstab()` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pd.crosstab()` 함수를 사용하여 2개 이상의 범주형 변수 간의 관계를 파악한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyl  4  6   8\n",
      "am           \n",
      "0    3  4  12\n",
      "1    8  3   2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mtcars = pd.read_csv('./datasets/mtcars.csv')\n",
    "print(pd.crosstab(mtcars['am'], mtcars['cyl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_36_'></a>[수치형 - 수치형 데이터 탐색 : `corr()` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수치형 - 수치형 데이터는 상관 계수로 변수 간의 상관 관계를 파악한다.\n",
    "- `corr(x, y, method)` 함수를 사용하여 구할 수 있다.\n",
    "    - `method`\n",
    "        - `pearson` : 피어슨 상관 계수 (기본값)\n",
    "            - 두 변수가 연속형 데이터일 경우 사용\n",
    "            - 두 변수가 정규성을 만족한다는 가정 필요\n",
    "        - `spearman` : 스피어만 상관 계수\n",
    "            - 두 변수가 순서적 데이터일 경우 사용\n",
    "            - 스피어만 상관 계수에서 연속형 자료를 순서적 자료로 변환하여 사용\n",
    "            - 두 변수가 정규성을 만족하지 않는 경우 or 순서적 데이터인 경우 사용\n",
    "        - `kendall` : 켄달 순위 상관 계수\n",
    "            - 두 변수가 순서적 데이터일 경우 사용\n",
    "            - 변수 $x_i, y_i$가 주어져, $x_i$가 증가할 때 $y_i$가 증가할 경우 부합(Concordant), $x_i$가 증가할 때 $y_i$가 감소할 경우 비부합(Discordant)으로 한다.\n",
    "            - 두 변수가 정규성을 만족하지 않는 경우 or 순서적 데이터인 경우 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8676593765172281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "cor_mpg_wt = mtcars['mpg'].corr(mtcars['wt'])\n",
    "print(cor_mpg_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pregnant  768 non-null    int64  \n",
      " 1   glucose   763 non-null    float64\n",
      " 2   pressure  733 non-null    float64\n",
      " 3   triceps   541 non-null    float64\n",
      " 4   insulin   394 non-null    float64\n",
      " 5   mass      757 non-null    float64\n",
      " 6   pedigree  768 non-null    float64\n",
      " 7   age       768 non-null    int64  \n",
      " 8   diabetes  768 non-null    object \n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 54.1+ KB\n",
      "None\n",
      "         pressure     triceps     insulin         age\n",
      "count  394.000000  394.000000  394.000000  394.000000\n",
      "mean    70.654822   29.106599  155.548223   30.814721\n",
      "std     12.469919   10.504273  118.775855   10.198971\n",
      "min     24.000000    7.000000   14.000000   21.000000\n",
      "25%     62.000000   21.000000   76.250000   23.000000\n",
      "50%     70.000000   29.000000  125.000000   27.000000\n",
      "75%     78.000000   36.750000  190.000000   36.000000\n",
      "max    110.000000   63.000000  846.000000   81.000000\n",
      "          pressure   triceps   insulin       age\n",
      "pressure  1.000000  0.232342  0.098272  0.299845\n",
      "triceps   0.232342  1.000000  0.184888  0.170694\n",
      "insulin   0.098272  0.184888  1.000000  0.220261\n",
      "age       0.299845  0.170694  0.220261  1.000000\n",
      "          pressure   triceps   insulin       age\n",
      "pressure  1.000000  0.249867  0.130463  0.328234\n",
      "triceps   0.249867  1.000000  0.245188  0.246585\n",
      "insulin   0.130463  0.245188  1.000000  0.267437\n",
      "age       0.328234  0.246585  0.267437  1.000000\n",
      "          pressure   triceps   insulin       age\n",
      "pressure  1.000000  0.174742  0.090656  0.229840\n",
      "triceps   0.174742  1.000000  0.169702  0.166394\n",
      "insulin   0.090656  0.169702  1.000000  0.188594\n",
      "age       0.229840  0.166394  0.188594  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/PimaIndiansDiabetes2.csv')\n",
    "print(df.info(), end='\\n')\n",
    "\n",
    "df = df.iloc[:, [2, 3, 4, 7]]\n",
    "df = df.dropna()  # 결측치 제거\n",
    "print(df.describe())\n",
    "\n",
    "print(df.corr(method='pearson'))   # 피어슨 상관 계수\n",
    "print(df.corr(method='spearman'))  # 스피어만 상관 계수\n",
    "print(df.corr(method='kendall'))   # 켄달 순위 상관 계수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_37_'></a>[범주형 - 수치형 데이터 탐색 : `groupby()` 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 범주형 데이터의 항목들을 그룹으로 간주하고, 항목들에 관한 기술 통계량으로 데이터를 탐색\n",
    "- `groupby()` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyl\n",
      "4    26.663636\n",
      "6    19.742857\n",
      "8    15.100000\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "print(mtcars.groupby('cyl')['mpg'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_38_'></a>[전체 데이터 파악](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `info()` 함수를 사용하여 데이터프레임 또는 시리즈의 요약 정보를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Series name: wt\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "32 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 388.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "print(df['wt'].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `head(n)` 함수를 사용하여 데이터의 앞부분을 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.620\n",
      "1    2.875\n",
      "2    2.320\n",
      "3    3.215\n",
      "4    3.440\n",
      "Name: wt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "print(df['wt'].head())   # 기본값(n) : 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tail(n)` 함수를 사용하여 데이터의 뒷부분을 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27    1.513\n",
      "28    3.170\n",
      "29    2.770\n",
      "30    3.570\n",
      "31    2.780\n",
      "Name: wt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "print(df['wt'].tail())   # 기본값(n) : 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[제2유형](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[회귀 모형 평가 : MSE(Mean Squared Error; 평균 제곱 오차)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mean_squared_error(y_true, y_pred, squared)` 함수를 사용하여 MSE, RMSE 값을 구할 수 있다.\n",
    "    - `y_true` : 실제값 배열\n",
    "    - `y_pred` : 모델의 예측값 배열\n",
    "    - `squared`\n",
    "        - `True` : MSE (기본값)\n",
    "        - `False` : RMSE\n",
    "- MSE, RMSE는 값이 <ins>낮을수록</ins> 정확도가 <ins>높다</ins>고 할 수 있다.\n",
    "- $RMSE = \\sqrt{MSE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.8660254037844386\n",
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_true = [3, 5, 7, 9]\n",
    "y_pred = [2, 5, 8, 10]\n",
    "\n",
    "print(mean_squared_error(y_true, y_pred))\n",
    "print(mean_squared_error(y_true, y_pred, squared=False))   # RMSE\n",
    "print(mean_squared_error(y_true, y_pred, squared=True))    # MSE (기본값)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[회귀 모형 평가 : 결정 계수(Coefficient of Determination : $R^2$)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 회귀 분석의 성능 검증 지표로 많이 이용 (선형이 아닌 회귀 모형에도 이용 가능)\n",
    "- 회귀 모형이 실제값을 얼마나 잘 나타내는지에 대한 비율\n",
    "- 결정 계수가 `1`에 <ins>가까울수록</ins> 실제값을 잘 설명 ($0 ≤ R^2 ≤ 1$)\n",
    "- `r2_score(y_true, y_pred)` 함수를 사용한다.\n",
    "    - `y_true` : 실제값 배열\n",
    "    - `y_pred` : 모델의 예측값 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_true = [3, 5, 7, 9]\n",
    "y_pred = [2, 5, 8, 10]\n",
    "\n",
    "print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_3_'></a>[분류 모형 평가 : 예측 함수](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측 함수는 분류 모형에서만 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.predict(X)` 함수를 사용하여 새로운 입력 데이터에 대한 예측값을 확인할 수 있다.\n",
    "    - `model` : 학습된 모델 객체\n",
    "    - `X` : 예측하려는 입력 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model_predict_proba(x)` 함수를 사용하여 각 클래스에 속할 확률을 확인할 수 있다.\n",
    "    - `model` : 학습된 모델 객체\n",
    "    - `X` : 예측하려는 입력 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터:\n",
      " [[6.1 2.8 4.7 1.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]]\n",
      "\n",
      "각 클래스에 속할 확률 (predict_proba):\n",
      " [[3.80451428e-03 8.27740653e-01 1.68454833e-01]\n",
      " [9.46981194e-01 5.30186076e-02 1.98739195e-07]\n",
      " [8.86460303e-09 1.54857733e-03 9.98451414e-01]\n",
      " [6.48690078e-03 7.92228033e-01 2.01285066e-01]\n",
      " [1.45813479e-03 7.74129008e-01 2.24412858e-01]]\n",
      "\n",
      "가장 가능성이 높은 클래스의 레이블 (predict):\n",
      " [1 0 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "x = X_test[:5]  # 테스트 데이터의 일부 샘플\n",
    "proba_predictions = model.predict_proba(x)\n",
    "class_predictions = model.predict(x)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"입력 데이터:\\n\", x)\n",
    "print(\"\\n각 클래스에 속할 확률 (predict_proba):\\n\", proba_predictions)\n",
    "print(\"\\n가장 가능성이 높은 클래스의 레이블 (predict):\\n\", class_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_4_'></a>[분류 모형 평가 : 혼동 행렬](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 혼동 행렬(Confusion Matrix) : 분석 모델에서 구한 분류의 예측 범주와 데이터의 실제 분류 범주를 교차표(Cross Table) 형태로 정리한 행렬\n",
    "- `confusion_matrix(y_true, y_pred)` 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동 행렬:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"혼동 행렬:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 행은 클래스 0에 대한 결과를 나타냅니다:\n",
    "\n",
    "```text\n",
    "10개의 샘플이 클래스 0으로 올바르게 예측되었습니다.\n",
    "0개의 샘플이 클래스 1으로 잘못 예측되었습니다.\n",
    "0개의 샘플이 클래스 2로 잘못 예측되었습니다.\n",
    "두 번째 행은 클래스 1에 대한 결과를 나타냅니다:\n",
    "\n",
    "0개의 샘플이 클래스 0으로 잘못 예측되었습니다.\n",
    "7개의 샘플이 클래스 1으로 올바르게 예측되었습니다.\n",
    "1개의 샘플이 클래스 2로 잘못 예측되었습니다.\n",
    "세 번째 행은 클래스 2에 대한 결과를 나타냅니다:\n",
    "\n",
    "0개의 샘플이 클래스 0으로 잘못 예측되었습니다.\n",
    "0개의 샘플이 클래스 1으로 잘못 예측되었습니다.\n",
    "12개의 샘플이 클래스 2로 올바르게 예측되었습니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_4_1_'></a>[1️⃣ 정확도(Accuracy)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 분류 범주를 정확하게 예측한 비율\n",
    "- 전체 예측에서 참 긍정(TP)과 참 부정(TN)이 차지하는 비율 ($\\frac{TP+TN}{TP+TN+FP+FN}$)\n",
    "- `accuracy_score(y_true, y_pred)` 함수를 사용한다.\n",
    "    - `y_true` : 실제값 배열\n",
    "    - `y_pred` : 모델의 예측값 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_4_2_'></a>[2️⃣ 재현율(Recall)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제로 긍정인 범주 중에서 긍정으로 올바르게 예측(TP)한 빕율 ($\\frac{TP}{TP+FN}$)\n",
    "- `recall_score(y_true, y_pred)` 함수를 사용한다.\n",
    "    - `y_true` : 실제값 배열\n",
    "    - `y_pred` : 모델의 예측값 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_4_3_'></a>[3️⃣ 정밀도(Precision)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 긍정으로 예측한 비율 중에서 실제로 긍정(TP)인 비율 ($\\frac{TP}{TP+FP}$)\n",
    "- `precision_score(y_true, y_pred)` 함수를 사용한다.\n",
    "    - `y_true` : 실제값 배열\n",
    "    - `y_pred` : 모델의 예측값 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_4_4_'></a>[4️⃣ F1 지표(F1-Score)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정밀도와 민감도(재현율)를 하나로 합한 성능 지표 ($2 \\times \\frac{Precision + Recall}{Precision \\times Recall}$)\n",
    "- 정밀도와 민감도 양쪽이 모두 클 때 F1 지표도 큰 값을 가진다.\n",
    "    - `0`~`1` 사이의 범위를 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]]\n",
      "0.6\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_true = [1, 0, 1, 0, 1]\n",
    "y_pred = [1, 1, 1, 0, 0]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(recall_score(y_true, y_pred))\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_5_'></a>[분류 모형 평가 : AUC(Area Under ROC; AUROC)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC 곡선(Receiver Operating Characteristic Curve)의 아랫 부분의 면적\n",
    "- 항상 `0.5`~`1`의 값을 가지며, `1`에 <ins>가까울수록</ins> 좋은 모형이다.\n",
    "- `roc_auc_score(y_true, y_pred)` 함수를 사용한다.\n",
    "    - `y_true` : 실제값 배열\n",
    "    - `y_pred` : 모델의 예측값 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = [1, 0, 1, 0, 1]\n",
    "y_pred = [1, 1, 1, 0, 0]\n",
    "\n",
    "print(roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_6_'></a>[분석 모형 구축 : 랜덤 포레스트](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_6_1_'></a>[종속 변수 : 범주형 (분류 모델)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `RandomForesetClassifier(n_estimators, criterion, max_depth)` 함수를 사용한다.\n",
    "    - `n_estimators` : 생성할 트리 개수\n",
    "    - `criterion` : 트리의 분할 기준\n",
    "        - `gini` : 지니 지수 (기본값)\n",
    "        - `entropy` : 엔트로피 지수\n",
    "    - `max_depth` : 트리의 최대 깊이 (기본값 : `None`)\n",
    "        - 트리의 깊이가 깊어질수록 모델의 복잡도가 증가하고 과적합될 확률 높아짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pregnant  768 non-null    int64  \n",
      " 1   glucose   763 non-null    float64\n",
      " 2   pressure  733 non-null    float64\n",
      " 3   triceps   541 non-null    float64\n",
      " 4   insulin   394 non-null    float64\n",
      " 5   mass      757 non-null    float64\n",
      " 6   pedigree  768 non-null    float64\n",
      " 7   age       768 non-null    int64  \n",
      " 8   diabetes  768 non-null    object \n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 54.1+ KB\n",
      "None\n",
      "[0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[[11  2]\n",
      " [18 48]]\n",
      "0.7468354430379747\n",
      "0.3793103448275862\n",
      "0.8461538461538461\n",
      "0.5238095238095238\n",
      "0.6696551724137931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('./datasets/PimaIndiansDiabetes2.csv')\n",
    "\n",
    "# print(df.describe())\n",
    "# print(df.head(3))\n",
    "print(df.info())\n",
    "\n",
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "# print(df.info())\n",
    "\n",
    "# 종속 변수, 독립 변수 분리\n",
    "x = df.drop('diabetes', axis=1)   # 독립 변수\n",
    "y = df['diabetes']    # 종속 변수\n",
    "\n",
    "## 범주형 -> 수치형 변환\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_test)\n",
    "print(pred)\n",
    "\n",
    "# 혼동 행렬 확인\n",
    "cm = confusion_matrix(pred, y_test, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "# 평가 지표 확인\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(recall_score(y_test, pred))\n",
    "print(precision_score(y_test, pred))\n",
    "print(f1_score(y_test, pred))\n",
    "print(roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_6_2_'></a>[종속 변수 : 수치형 (회귀 모델)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `RandomForesetRegressor(n_estimators, criterion, max_depth)` 함수를 사용한다.\n",
    "    - `n_estimators` : 생성할 트리 개수\n",
    "    - `criterion` : 트리의 분할 기준\n",
    "        - `mse` : 평균 제곱 오차 (기본값)\n",
    "    - `max_depth` : 트리의 최대 깊이 (기본값 : `None`)\n",
    "        - 트리의 깊이가 깊어질수록 모델의 복잡도가 증가하고 과적합될 확률 높아짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pregnant  768 non-null    int64  \n",
      " 1   glucose   763 non-null    float64\n",
      " 2   pressure  733 non-null    float64\n",
      " 3   triceps   541 non-null    float64\n",
      " 4   insulin   394 non-null    float64\n",
      " 5   mass      757 non-null    float64\n",
      " 6   pedigree  768 non-null    float64\n",
      " 7   age       768 non-null    int64  \n",
      " 8   diabetes  768 non-null    object \n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 54.1+ KB\n",
      "None\n",
      "[0.294656   0.30865152 0.24088431 0.46286357 0.46238068 0.09297074\n",
      " 0.29151045 0.14136509 0.09011284 0.21982593 0.53757298 0.23893945\n",
      " 0.3454403  0.59175592 0.17694128 0.1651356  0.53290256 0.10726227\n",
      " 0.1870601  0.09011284 0.21298719 0.11327466 0.72972904 0.09290593\n",
      " 0.10291526 0.56381926 0.11893794 0.09290593 0.38712714 0.10218122\n",
      " 0.83891033 0.15945862 0.09011284 0.28317224 0.2608335  0.11605798\n",
      " 0.17582283 0.3781862  0.11152638 0.80146978 0.31895508 0.15018946\n",
      " 0.53684904 0.50939057 0.37264359 0.26668555 0.10942472 0.09011284\n",
      " 0.24615242 0.45875699 0.27088473 0.09323634 0.09290593 0.60417744\n",
      " 0.21513909 0.10575319 0.72063328 0.49412145 0.85747256 0.23321109\n",
      " 0.31298986 0.26209534 0.74104222 0.3531488  0.09011284 0.28133278\n",
      " 0.13890059 0.34929385 0.09290593 0.46221085 0.10355499 0.61086774\n",
      " 0.09290593 0.68492009 0.09011284 0.14035148 0.22099411 0.21630651\n",
      " 0.38882471]\n",
      "0.36530062748311004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('./datasets/PimaIndiansDiabetes2.csv')\n",
    "\n",
    "# print(df.describe())\n",
    "# print(df.head(3))\n",
    "print(df.info())\n",
    "\n",
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "# print(df.info())\n",
    "\n",
    "# 종속 변수, 독립 변수 분리\n",
    "x = df.drop('diabetes', axis=1)   # 독립 변수\n",
    "y = df['diabetes']    # 종속 변수\n",
    "\n",
    "## 범주형 -> 수치형 변환\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestRegressor(n_estimators=100, max_depth=2)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_test)\n",
    "print(pred)\n",
    "\n",
    "# MSE 확인\n",
    "print(mean_squared_error(y_test, pred, squared=False))   # MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[제3유형](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Z-검정(Z-Test)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z = \\frac{\\overline{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n",
    "\n",
    "- $\\overline{X}$ : 표본 평균\n",
    "- $\\mu$ : 모평균\n",
    "- $\\sigma$ : 모표준편차\n",
    "- $n$ : 표본의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 귀무가설에서 검정 통계량의 분포를 정규 분포로 근사할 수 있는 통계 검정\n",
    "- 정규 분포를 가정하며, 추출된 표본이 동일 모집단에 속하는지 가설을 검증하기 위해 사용\n",
    "- 모집단 분산 $\\sigma^2$을 이미 <ins>알고</ins> 있을 때 분포의 **평균** 을 테스트\n",
    "- Z-검정 통계량 값이 임계치(Critical Value)보다 크고 작음에 따라 가설을 기각 또는 채택한다.\n",
    "    - **p-value > 유의수준($\\alpha$)** : 귀무가설 채택\n",
    "    - **p-value < 유의수준($\\alpha$)** : 대립가설 채택\n",
    "- `norm.cdf(z)` 함수를 사용한다.\n",
    "    - `z` : z-검정 통계량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- 공장에서 생산한 제품 평균 높이는 26cm이며 <ins>표준편차는 5cm</ins>로 확인되었다.\n",
    "    - 분산 : $\\sigma^2 = 5^2 = 25$ (모집단의 분산 파악 가능)\n",
    "- 제품의 높이를 측정한 표본 7개의 데이터는 다음과 같다.\n",
    "- 유의 수준이 `0.05`일 때, 데이터를 기반으로 제품의 <mark>평균</mark> 높이를 검정하려고 한다.\n",
    "\n",
    "```text\n",
    "제품의 높이(cm) : 25, 27, 31, 23, 24, 30, 26\n",
    "귀무가설(H0) : 모평균은 26cm (모평균 = 표본평균)\n",
    "대립가설(H1) : 모평균이 26cm가 아님 (모평균 ≠ 표본평균)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: 26.571428571428573\n",
      "z-값: 0.3023715784073826\n",
      "p-값: 0.7623688184698392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 데이터 설정\n",
    "x = np.array([25, 27, 31, 23, 24, 30, 26])\n",
    "\n",
    "# 평균 계산\n",
    "mean_x = np.mean(x)\n",
    "print(\"평균:\", mean_x)\n",
    "\n",
    "# z-값 계산\n",
    "sigma = 5  # 모표준편차\n",
    "n = len(x)  # 표본 크기\n",
    "z = (mean_x - 26) / (sigma / np.sqrt(n))\n",
    "print(\"z-값:\", z)\n",
    "\n",
    "# p-값 계산\n",
    "p = (1 - norm.cdf(z)) * 2\n",
    "print(\"p-값:\", p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[T-검정(T-Test)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 독립변수 : 범주형, 종속변수 : 수치형\n",
    "- 두 집단의 <mark style='background-color: skyblue'>**평균**</mark> 을 비교하는 검정 방법\n",
    "- 표본이 **정규성, 등분산성, 독립성** 을 만족할 경우 적용한다.\n",
    "- 모집단이 정규 분포라는 정도만 알고, $\\sigma^{2}$(모분산)을 모를 때 $s^{2}$(표본분산)으로 대체하여 모평균($\\mu$)를 구할 때 사용한다.\n",
    "- 적은 표본으로도 모집단 평균을 추정하려고 정규 분포 대신에 사용되는 확률 분포"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_1_'></a>[1️⃣ 단일 표본 T-검정(One Sample T-Test)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한 집단의 평균이 모집단의 평균과 같은지 검정하는 방법\n",
    "- <ins>모집단의 평균이 알려진 경우</ins>, 하나의 표본 집단의 평균을 구하고 모집단의 평균과 표본 집단의 평균이 같은지를 검정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T = \\frac{\\overline{X} - \\mu}{\\frac{s}{\\sqrt{n}}}$$\n",
    "\n",
    "- $\\overline{X}$ : 표본 평균\n",
    "- $\\mu$ : 모평균\n",
    "- $s$ : 표본 표준 편차\n",
    "- $n$ : 표본의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_1_'></a>[단일 표본 정규성 검정](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단일 표본 T-검정을 수행하기 전 표본에 대한 **정규성** 을 검정하려면 샤피로 윌크 검정을 사용한다.\n",
    "- `shapiro.test(x)` 함수를 사용한다.\n",
    "    - `x` : 정규성 검정을 수행할 데이터\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값)이 출력된다.\n",
    "- 샤피로-윌크 검정의 결과에서 p-값이 일반적으로 `0.05`보다 <ins>크면</ins> 데이터가 정규 분포를 <ins>따른다</ins>고 볼 수 있다. \n",
    "    - p-값이 `0.05`보다 <ins>작으면</ins> 데이터가 정규 분포를 따르지 <ins>않는다</ins>고 결론 내릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <span>✅ p-값이 유의수준(α)보다 <ins>클</ins> 경우 <b>귀무가설</b>을 채택한다. (p-값 > 유의수준 => 귀무가설 채택)</span><br/>\n",
    "    <span>✅ p-값이 유의수준(α)보다 <ins>작을</ins> 경우 <b>대립가설</b>을 채택한다. (p-값 < 유의수준 => 대립가설 채택)</span><br/>\n",
    "    <span>✅ 보통 귀무가설에 옳다고 생각되는 것을 지정한다. (예: 정규성 만족)</span><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W 값: 0.98505924025743\n",
      "p 값: 0.774149900641557\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(123)  # 재현성을 위해 시드 설정\n",
    "x = np.random.normal(loc=0, scale=1, size=50)  # 평균 0, 표준편차 1인 정규분포를 따르는 50개의 데이터 생성\n",
    "\n",
    "# 샤피로-윌크 검정 수행\n",
    "result = shapiro(x)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"W 값:\", result.statistic)\n",
    "print(\"p 값:\", result.pvalue)   # p-값이 0.05보다 크므로 정규 분포를 따른다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc2_2_1_1_1_'></a>[① 정규성 가정을 만족할 경우](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 정규성 가정을 만족한다면 `ttest_1samp(a, popmean)` 함수를 사용하여 T-검정을 수행한다.\n",
    "    - `a` : 표본으로부터 관측한 값\n",
    "    - `popmean` : 검정 시 기준이 되는 값($\\mu_0$)\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값)이 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- 공장에서 트렌드에 맞는 신제품을 출시했다.\n",
    "- 생산된 신제품 7개의 높이를 측정한 결과는 다음과 같다.\n",
    "- 유의수준이 0.05일 때, <ins>신제품의 <mark>평균</mark> 높이가 11cm인지 아닌지</ins>에 대해 양측 검정을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "신제품의 높이(cm) : 12, 14, 16, 19, 11, 17, 13\n",
    "귀무가설(H0) : 신제품 높이의 평균은 11cm이다.\n",
    "대립가설(H1) : 신제품 높이의 평균은 11cm가 아니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height\n",
      "0      12\n",
      "1      14\n",
      "2      16\n",
      "3      19\n",
      "4      11\n",
      "5      17\n",
      "6      13 \n",
      "\n",
      "ShapiroResult(statistic=0.9641614571212591, pvalue=0.8535413398236595)\n",
      "TtestResult(statistic=3.2826608214930637, pvalue=0.016766749930606027, df=6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, ttest_1samp\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'height': [12, 14, 16, 19, 11, 17, 13]\n",
    "})\n",
    "\n",
    "print(df, '\\n')\n",
    "\n",
    "# (1) 정규성 검정\n",
    "target = df['height']\n",
    "print(shapiro(target))   # p-값이 유의수준 0.05보다 크기 때문에 귀무가설 채택 (정규성 만족 O)\n",
    "\n",
    "# (2) T-검정\n",
    "print(ttest_1samp(target, popmean=11))   # p-값이 유의수준 0.05보다 작기 때문에 대립가설 채택 (신제품 높이의 평균은 11cm가 아니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc2_2_1_1_2_'></a>[② 정규성 가정을 만족하지 않을 경우](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 정규성을 만족하지 않는다면 `wilcoxon(x, alternative)` 함수를 사용하여 검정을 수행한다.\n",
    "    - `x` : 표본으로부터 관측한 값\n",
    "    - `alternative` : 검정 방향\n",
    "        - `two.sided` : 양측 검정\n",
    "        - `less` : 단측 검정일 때, 표본 평균이 특정 값보다 <ins>작은지</ins>에 대한 검정 (좌측 검정)\n",
    "        - `greater` : 단측 검정일 때, 표본 평균이 특정 값보다 <ins>큰지</ins>에 대한 검정 (우측 검정)\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값)이 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- `cats` 데이터는 고양이들의 성별, 몸무게, 심장의 무게를 담고 있다.\n",
    "- 유의 수준이 0.05일 때, `cats` 데이터에서 고양이들의 <ins>평균 몸무게가 2.1kg인지 아닌지</ins>에 대해 **양측 검정**을 수행한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "귀무가설(H0) : 고양이들의 평균 몸무게가 2.1kg이다.\n",
    "대립가설(H1) : 고양이들의 평균 몸무게가 2.1kg가 아니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  144 non-null    int64  \n",
      " 1   Sex         144 non-null    object \n",
      " 2   Bwt         144 non-null    float64\n",
      " 3   Hwt         144 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 4.6+ KB\n",
      "None \n",
      "\n",
      "ShapiroResult(statistic=0.9518791269479144, pvalue=6.730857622701013e-05)\n",
      "WilcoxonResult(statistic=50.0, pvalue=2.765612175340855e-23)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, wilcoxon\n",
    "\n",
    "df = pd.read_csv('./datasets/cats.csv')\n",
    "print(df.info(), '\\n')\n",
    "\n",
    "# (1) 정규성 검정\n",
    "target = df['Bwt']   # 몸무게\n",
    "result = shapiro(target)\n",
    "print(result)   # p-값이 유의수준 0.05 보다 작으므로 대립가설 채택 (정규성 만족 X)\n",
    "\n",
    "# (2) T-검정\n",
    "crit_value = 2.1   # 검정 시 기준이 되는 값\n",
    "result = wilcoxon(target - crit_value, alternative='two-sided')   # target 값에서 검정 시 기준이 되는 값을 빼준다. 양측 검정\n",
    "print(result)   # p-값이 0.05 보다 작으므로 대립가설 채택 (고양이들 평균 몸무게 2.1kg 아니다.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_2_'></a>[2️⃣ 쌍체 표본 T-검정(Paired Sample T-Test; 대응 표본 T-검정)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <ins>한 집단에서 처치를 받기 전과 후의 차이</ins>를 알아보기 위해 사용\n",
    "- 표본(Sample)이 하나, 독립 변수가 1개일 때 사용된다.\n",
    "- 하나의 모집단에서 크기가 $n$개인 <ins>하나</ins>의 표본을 추출한 후, 표본 내의 개체들에 대해서 <ins>2번</ins> 측정한다.\n",
    "    - 따라서 관측값들은 서로 독립적이지 않고 쌍(Pair)으로 이루어져 있다.\n",
    "    - **짝지어진 T-검정(Matched Pair T-Test)** 이라고도 한다.\n",
    "- 모집단의 관측값이 정규 분포를 만족한다는 **정규성 가정** 을 만족해야 한다.\n",
    "- 종속 변수는 **<ins>연속형</ins>** 변수 이어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T = \\frac{\\bar{d} - \\mu_{d}}{\\frac{s}{\\sqrt{n}}}$$\n",
    "\n",
    "- $\\bar{d}$ : 두 표본 집단 평균의 차이\n",
    "- $\\mu_{d}$ : 두 모집단 평균의 차이\n",
    "- $s$ : 표본 표준 편차\n",
    "- $n$ : 표본의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ttest_rel(x, y, alternative)` 함수를 사용한다.\n",
    "    - `x` : 처리 방법이 `x`일 때의 관측값 (수치형 벡터)\n",
    "    - `y` : 처리 방법이 `y`일 때의 관측값 (수치형 벡터)\n",
    "    - `alternative` : 검정 방향\n",
    "        - `two.sided` : 양측 검정\n",
    "        - `less` : 단측 검정일 때, 표본 평균이 특정 값보다 <ins>작은지</ins>에 대한 검정 (좌측 검정)\n",
    "        - `greater` : 단측 검정일 때, 표본 평균이 특정 값보다 <ins>큰지</ins>에 대한 검정 (우측 검정)\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값), `df`(자유도)가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- 7명의 환자를 대상으로 수면 영양제를 복용하기 전과 후의 수면 시간을 측정하여 영양제의 효과가 있는지를 판단하고자 한다.\n",
    "    - <ins>한 집단에서 처치를 받기 전과 후의 차이</ins>를 알아본다.\n",
    "- 유의수준이 `0.05`일 때 영양제 복용 전과 후의 평균 수면 시간에 차이가 있는지를 알아보는데, **단측 검정** 을 수행하여 영양제 복용 후에 수면 시간이 더 늘어났는지를 검정하려고 한다.\n",
    "- 수면 영양제를 복용하기 전과 후의 수면 시간은 다음과 같다.\n",
    "- 표본이 정규성을 만족한다는 가정 하에 단측 검정을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "수면 영양제 복용 전 7명의 환자들의 수면 시간 : 5, 3, 8, 4, 3, 2, 1\n",
    "수면 영양제 복용 후 7명의 환자들의 수면 시간 : 8, 6, 6, 5, 8, 7, 3\n",
    "귀무가설(H0) : 수면 영양제를 복용하기 전과 후의 평균 수면 시간에는 차이가 없다. (μx - μy = D = 0)\n",
    "대립가설(H1) : 수면 영양제를 복용하기 전과 후의 평균 수면 시간에는 차이는 0보다 작다. (수면 영양제를 복용한 후 평균 수면 시간이 늘어났다.) (μx - μy = D < 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   before  after\n",
      "0       5      8\n",
      "1       3      6\n",
      "2       8      6\n",
      "3       4      5\n",
      "4       3      8\n",
      "5       2      7\n",
      "6       1      3 \n",
      "\n",
      "TtestResult(statistic=-2.633628675421043, pvalue=0.019435182851729293, df=6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'before': [5, 3, 8, 4, 3, 2, 1],\n",
    "    'after': [8, 6, 6, 5, 8, 7, 3]\n",
    "})\n",
    "\n",
    "print(data, '\\n')\n",
    "\n",
    "# 쌍체 표본 T-검정 수행\n",
    "result = ttest_rel(data['before'], data['after'], alternative='less')   # 단측 검정 (좌측 검정)\n",
    "print(result)   # p-값이 0.05 보다 작으므로 대립가설 채택 (수면 영양제 복용 후 평균 수면 시간이 늘어났다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_3_'></a>[3️⃣ 독립 표본 T-검정(Independent Sample T-Test)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 <ins>서로 다른 모집단에서 추출</ins>된 경우 사용할 수 있는 분석 방법\n",
    "- <ins>독립된 두 집단의 <mark>평균</mark> 차이</ins>를 검정하는 방법\n",
    "- 검정 전 반드시 **정규성, 등분산성** 가정을 만족하는지 확인한다.\n",
    "    - 표본의 수에 따른 **정규성** 증명 방법\n",
    "        - 10개 미만\n",
    "            - 정규성을 만족하지 못한다고 가정\n",
    "            - 비모수적인 방법인 **만-위트니 검정(Mann-Whitney Test)** 적용\n",
    "        - 10개 이상 ~ 30개 이하\n",
    "            - **샤피로-윌크 검정(Shapiro-Wilk Test)**\n",
    "            - **콜모고로프-스미르노프 검정(Kolmogorov-Smirnov Test)**\n",
    "        - 30개 이상\n",
    "            - **중심 극한 정리**\n",
    "- 두 모집단은 <ins>정규성을 만족</ins>해야 하고, <ins>서로 독립적</ins>이어야 하며, <ins>분산이 서로 같아야(등분산성 만족)</ins> 한다.\n",
    "    - 등분산 가정은 비교하고자 하는 두 집단의 모분산이 동일함을 의미하며, 등분산성 만족 여부에 따라 다른 계산 방법이 사용된다.\n",
    "        - 이 가정을 확인하기 위해 독립 표본 T-검정 수행 과정에서는 **등분산 검정** 을 먼저 수행한 후 검정 통계량을 계산한다.\n",
    "- 독립 변수는 <ins>범주형</ins>, 종속 변수는 <ins>연속형</ins>이어야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T = \\frac{(\\overline{X}_{1} - \\overline{X}_2) - (\\mu_1 - \\mu_2)}{\\sqrt{s^{2}_{p}(\\frac{1}{n_{1}} + \\frac{1}{n_{2}})}}$$\n",
    "\n",
    "- $\\overline{X}_{1}$ : 집단1의 평균\n",
    "- $\\overline{X}_{2}$ : 집단2의 평균\n",
    "- $s^{2}_{p}$ : 통합 분산 추정량\n",
    "- $n_{1}$ : 집단1의 표본 개수\n",
    "- $n_{2}$ : 집단2의 표본 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **등분산 검정** 을 위해 `levene(sample1, sample2, center)` 함수를 사용한다.\n",
    "    - `sample1` : 모집단1로부터 측정한 관측값 (수치형 벡터)\n",
    "    - `sample2` : 모집단2로부터 측정한 관측값 (수치형 벡터)\n",
    "    - `center` : 분포의 중심을 정의하는 방법\n",
    "        - `median` : 중위수 (기본값)\n",
    "        - `mean` : 평균\n",
    "- **독립 표본 T-검정** 을 위해 `ttest_ind(sample1, sample2, alternative, equal_var)` 함수를 사용한다.\n",
    "    - `sample1` : 모집단1로부터 측정한 관측값 (수치형 벡터)\n",
    "    - `sample2` : 모집단2로부터 측정한 관측값 (수치형 벡터)\n",
    "    - `alternative` : 검정 방향\n",
    "        - `two.sided` : 양측 검정\n",
    "        - `less` : 단측 검정일 때, 표본 평균이 특정 값보다 <ins>작은지</ins>에 대한 검정 (좌측 검정)\n",
    "        - `greater` : 단측 검정일 때, 표본 평균이 특정 값보다 <ins>큰지</ins>에 대한 검정 (우측 검정)\n",
    "    - `equal_var` : 등분산성을 만족하는지의 여부\n",
    "        - `True` : 등분산성 만족\n",
    "        - `False` : 등분산성 불만족 (기본값)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- `cats` 데이터는 고양이들의 성별(`Sex`), 몸무게(`Bwt`), 심장의 무게(`Hwt`)를 담고 있다.\n",
    "- 유의 수준이 0.05일 때 고양이들의 성별에 따른 몸무게의 평균은 통계적으로 다르다고 할 수 있는지에 대한 검정을 수행하려고 한다.\n",
    "    - 독립 변수(성별) : 범주형, 종속 변수(몸무게) : 연속형 \n",
    "    - 독립된 두 집단의 평균 차이 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "귀무가설(H0) : 고양이의 성별에 따른 평균 몸무게에는 통계적으로 유의미한 차이가 없음.\n",
    "대립가설(H1) : 고양이의 성별에 따른 평균 몸무게에는 통계적으로 유의미한 차이가 있음.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  144 non-null    int64  \n",
      " 1   Sex         144 non-null    object \n",
      " 2   Bwt         144 non-null    float64\n",
      " 3   Hwt         144 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 4.6+ KB\n",
      "None \n",
      "\n",
      "LeveneResult(statistic=19.43101190877999, pvalue=2.0435285255189404e-05) \n",
      "\n",
      "TtestResult(statistic=-8.70948849909559, pvalue=8.831034455859356e-15, df=136.83788299625363)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, levene\n",
    "\n",
    "df = pd.read_csv('./datasets/cats.csv')\n",
    "print(df.info(), '\\n')\n",
    "\n",
    "# (1) 그룹 지정\n",
    "group1 = df[df['Sex'] == 'F']['Bwt']\n",
    "group2 = df[df['Sex'] == 'M']['Bwt']\n",
    "\n",
    "# (2) 등분산성 검정\n",
    "result = levene(group1, group2)\n",
    "print(result, '\\n')   # p-값이 유의수준 0.05보다 작으므로 대립 가설 채택 (등분산성 만족 X)\n",
    "\n",
    "# (3) 독립 표본 T-검정\n",
    "result = ttest_ind(group1, group2, equal_var=False)   # 등분산성 가정 X\n",
    "print(result)   # p-값이 0.05보다 작으므로 대립가설 채택 (고양이의 성별에 따른 평균 몸무게에는 통계적으로 유의미한 차이가 있음.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[F-검정(F-Test)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 표본의 <mark style='background-color: skyblue'><b>분산</b></mark>에 대한 차이가 통계적으로 유의미한지 판별하는 검정\n",
    "- <ins>두 모집단 분산 간의 비율</ins>에 대한 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F = \\frac{s^{2}_{1}}{s^{2}_{2}} \\quad (s^{2}_{1} > s^{2}_{2})$$\n",
    "\n",
    "- $s^{2}_{1}, s^{2}_{2}$ : 표본 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `f.cdf(x, dfn, dfd)` 함수를 사용한다.\n",
    "    - `f` : F-검정 통계량\n",
    "    - `dfn` : F-분포의 분자의 자유도\n",
    "    - `dfd` : F-분포의 분모의 자유도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- 유의 수준이 0.05일 때 무작위로 5개의 값을 생성한 두 그룹(`df1`, `df2`)의 <ins>분산</ins>이 같은지에 대한 검정을 하려고 한다.\n",
    "    - 두 표본의 분산에 대한 차이가 통계적으로 유의미한지 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "1번 그룹 : 1, 2, 3, 4, 6\n",
    "2번 그룹 : 4, 5, 6, 7, 8\n",
    "귀무가설(H0) : 두 그룹의 분산은 같음.\n",
    "대립가설(H1) : 두 그룹의 분산은 같지 않음.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 분산값:  3.7\n",
      "df2 분산값:  2.5\n",
      "(1.11, 0.921871791478988)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "df1 = np.array([1, 2, 3, 4, 6])\n",
    "df2 = np.array([4, 5, 6, 7, 8])\n",
    "\n",
    "# (1) 분산값 확인\n",
    "print('df1 분산값: ', np.var(df1, ddof=1))\n",
    "print('df2 분산값: ', np.var(df2, ddof=1))\n",
    "\n",
    "# (2) F-검정\n",
    "def f_test(x, y):\n",
    "    s1 = np.var(x, ddof=1)\n",
    "    s2 = np.var(y, ddof=2)\n",
    "\n",
    "    # F = s1 / s2 (s1 > s2) 규칙을 만족시켜 준다.\n",
    "    if s1 < s2:\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    f_value = s1 / s2\n",
    "\n",
    "    # F 통계량은 표본 분산을 사용하므로, (데이터의 개수 - 1)로 계산해 자유도를 맞춰준다.\n",
    "    x_dof = x.size - 1\n",
    "    y_dof = y.size - 1\n",
    "\n",
    "    p_value = (1 - f.cdf(f_value, x_dof, y_dof)) * 2   # 양측 검정이므로 2를 곱해준다.\n",
    "\n",
    "    return f_value, p_value\n",
    "\n",
    "result = f_test(df1, df2)\n",
    "\n",
    "print(result)    # p-값이 유의 수준 0.05보다 크므로 귀무가설 채택 (두 그룹의 분산은 같음.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[카이제곱 검정(Chi-Squared Test: $\\chi^{2}$ Test)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <ins>**범주형** 자료 간의 차이</ins>를 보여주는 분석 방법\n",
    "- 관찰된 빈도가 기대되는 빈도와 유의하게 다른지를 검정하는 방법\n",
    "- 교차 분석은 <ins>3가지</ins>로 분류할 수 있다.\n",
    "    - 적합도 검정(Goodness of Fit Test)\n",
    "    - 독립성 검정(Test of Independence)\n",
    "    - 동질성 검정(Test of Homogeneity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_1_'></a>[1️⃣ 적합도 검정(Goodness of Fit Test)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표본 집단의 분포가 <ins>주어진 특정 분포를 따르고 있는지</ins> 검정하는 방법\n",
    "- 적합도 검정의 자료를 구분하는 범주가 <ins>상호 베타적</ins>이어야 한다.\n",
    "    - 예) 성별(남자, 여자), 등수(1등, 2등, 3등)\n",
    "- 귀무 가설은 '표본 집단의 분포가 주어진 특정 분포를 따른다.'로 설정한다.\n",
    "- 관찰 빈도와 기대 빈도의 차이가 클수록 귀무가설을 기각(대립가설을 채택)할 확률이 높아진다.\n",
    "- 적합도 검정에서 `자유도`는 `(범주의 수) - 1`로 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `chisquare(f_obs, f_exp)` 함수를 사용한다.\n",
    "    - `f_obs` : 관찰 빈도를 나타내는 데이터\n",
    "    - `f_exp` : 기대 빈도를 나타내는 데이터\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값)가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- 유의 수준이 0.05일 때 초등학교에 남학생이 90명, 여학생이 160명이 있다.\n",
    "- 남학생, 여학생 비율이 45%와 55%인지를 **카이제곱 검정** 을 이용하여 분석하려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "귀무가설(H0) : 초등학교 남학생, 여학생의 비율은 45%와 55%\n",
    "대립가설(H1) : 초등학교 남학생, 여학생의 비율은 45%와 55%가 아님.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=8.181818181818182, pvalue=0.004231232899758152)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "num = np.array([90, 160])   # 관찰 빈도\n",
    "expected = np.array([0.45, 0.55]) * np.sum(num)   # 기대 빈도\n",
    "\n",
    "# 카이제곱 검정 : 적합도 검정 수행\n",
    "result = chisquare(num, f_exp=expected)\n",
    "print(result)   # p-값이 0.05 보다 작으므로 대립가설 채택 (초등학교 남학생, 여학생 비율은 45%와 55%가 아님.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_2_'></a>[2️⃣ 독립성 검정(Test of Independence)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변수가 <ins>2개 이상의 범주로 분할되어 있을 때</ins> 사용\n",
    "- 각 범주가 서로 독립적인지, 서로 연관성이 있는지를 검정하는 방법\n",
    "    - 예) 학년(1학년, 2학년, 3학년)이라는 범주형 데이터(`요인1`)와 선호 과목(국, 영, 수)이라는 범주형 데이터(`요인2`) 간에 <ins>서로 연관성이 있는 것인지 아니면 독립적인지</ins>를 판단하는 것과 같은 문제에서 독립성 검정 사용\n",
    "- 귀무 가설은 '요인1과 요인2는 독립적이다.'로 설정한다.\n",
    "    - 귀무 가설 : 학년별 선호 과목은 독립적\n",
    "    - 대립 가설 : 학년별 선호 과목은 독립적이지 않음.\n",
    "- 독립성 검정에서 `자유도`는 `{(범주1의 수) - 1} * {(범주2의 수) - 1}` 로 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `chi2_contingency(observed)` 함수를 사용한다.\n",
    "    - `observed` : 2개 이상의 변수를 포함하는 2차원 배열\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값), `dof`(자유도), `expected_freq`(기대빈도)가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예제\n",
    "\n",
    "- 유의 수준이 0.05일 때 `survey` 데이터 세트에서 <ins>성별에 따른 운동 빈도가 관계가 있는지</ins>를 카이제곱 검정을 이용하여 분석하려고 한다.\n",
    "    - 성별 : 범주형 데이터, 운동 빈도 : 범주형 데이터\n",
    "    - 각 범주가 서로 독립적인지 아닌지를 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "귀무가설(H0) : 성별에 따른 운동 빈도는 독립\n",
    "대립가설(H1) : 성별에 따른 운동 빈도는 독립이 아님.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exer    Freq  Some\n",
      "Sex               \n",
      "Female    49    58\n",
      "Male      65    40 \n",
      "\n",
      "Chi2ContingencyResult(statistic=4.904232352768243, pvalue=0.0267909570897706, dof=1, expected_freq=array([[57.53773585, 49.46226415],\n",
      "       [56.46226415, 48.53773585]]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "df = pd.read_csv('./datasets/survey.csv')\n",
    "\n",
    "# (1) 교차표 형태로 만들기 (2개 이상의 변수를 포함하는 2차원 배열로 만들기)\n",
    "tb = pd.crosstab(df['Sex'], df['Exer'])\n",
    "print(tb, '\\n')\n",
    "\n",
    "# (2) 카이제곱 검정 : 독립성 검정 수행\n",
    "result = chi2_contingency(tb)\n",
    "print(result)    # p-값이 0.05보다 작으므로 대립가설 채택 (성별에 따른 운동 빈도는 독립이 아님.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_4_3_'></a>[3️⃣ 동질성 검정(Test of Homogeneity)](#toc0_)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각각의 독립적인 부모 집단으로부터 정해진 표본의 크기만큼 자료를 추출하는 경우, 관측값들이 정해진 범주 내에서 서로 동질한지(비슷하게 나타나고 있는지) 여부를 검정하는 기법\n",
    "    - 예) 남학생과 여학생 그룹에 대하여 각 그룹이 선호하는 과목이 같은지 여부를 판단하는 것과 같은 문제에서 동질성 검정 사용\n",
    "- 귀무 가설은 '모집단은 동질하다.'로 설정한다.\n",
    "- 동질성 검정과 독립성 검정은 개념상의 차이가 있을 뿐, 계산 방식은 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `chi2_contingency(observed)` 함수를 사용한다.\n",
    "    - `observed` : 2개 이상의 변수를 포함하는 2차원 배열\n",
    "    - 검정 결과로 `statistics`(통계값), `pvalue`(p-값), `dof`(자유도), `expected_freq`(기대빈도)가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 Statistic: 23.799999999999997\n",
      "p-value: 8.759622201519535e-05\n",
      "Degrees of Freedom: 4\n",
      "Expected Frequencies:\n",
      " [[21.17647059 17.64705882 21.17647059]\n",
      " [21.17647059 17.64705882 21.17647059]\n",
      " [17.64705882 14.70588235 17.64705882]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 예제 데이터: 교차표 (contingency table)\n",
    "# 예시로 두 개의 범주형 변수가 각각 3개의 범주를 가지는 경우\n",
    "data = np.array([[10, 20, 30],\n",
    "                 [20, 20, 20],\n",
    "                 [30, 10, 10]])\n",
    "\n",
    "# chi2_contingency 함수 사용\n",
    "chi2, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Chi2 Statistic:\", chi2)\n",
    "print(\"p-value:\", p)    # p-값이 0.05 보다 작으므로 대립가설 채택 (두 집단은 동질하지 않다.)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\\n\", expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
