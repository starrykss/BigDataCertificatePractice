{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20240610\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제1유형\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P210201.csv')\n",
    "\n",
    "top10 = df['crim'].sort_values(ascending=False).head(10)\n",
    "# print(top10)\n",
    "\n",
    "tenth = top10.iloc[9]\n",
    "df['crim'] = np.where(df['crim'] >= tenth, tenth, df['crim'])\n",
    "over80 = df[df['age'] >= 80]\n",
    "# print(over80['age'].describe())\n",
    "\n",
    "ans = round(over80['crim'].mean(), 2)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./datasets/P210202.csv\")\n",
    "\n",
    "nrow = int(len(df) * 0.8)   # 상위 80%\n",
    "df = df.iloc[:nrow, :]\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "a = df['total_bedrooms'].std()\n",
    "median_train = df['total_bedrooms'].median()\n",
    "df['total_bedrooms'] = df['total_bedrooms'].fillna(median_train)\n",
    "\n",
    "b = df['total_bedrooms'].std()\n",
    "\n",
    "ans = round(np.abs(a - b), 2)\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6421430\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P210203.csv')\n",
    "\n",
    "# charges 항목의 이상값의 합 구하기\n",
    "target = df['charges']\n",
    "\n",
    "lower = np.mean(target) - 1.5 * np.std(target)\n",
    "upper = np.mean(target) + 1.5 * np.std(target)\n",
    "\n",
    "crit = (target <= lower) | (target >= upper)\n",
    "ans = round(target[crit].sum())\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "0\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P210301.csv')\n",
    "\n",
    "# 결측값이 있는 모든 행 제거하기\n",
    "numNA = sum(df.isnull().any(axis=1))  # axis=1 : 행\n",
    "print(numNA)\n",
    "\n",
    "df = df.dropna()   # 결측값 제거\n",
    "numNA = sum(df.isnull().any(axis=1))\n",
    "print(numNA)\n",
    "\n",
    "# 데이터의 순서대로 상위 70%의 데이터를 학습 데이터로 만들기\n",
    "nrow = int(len(df) * 0.7)\n",
    "df = df.iloc[:nrow, :]\n",
    "\n",
    "# 학습 데이터의 house_median_age 컬럼의 Q1 구하기 (정수로 출력)\n",
    "qt = np.quantile(df['housing_median_age'], q=0.25)\n",
    "ans = int(qt)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210302.csv')\n",
    "\n",
    "\n",
    "# 데이터가 없는 것을 결측값으로 하여 비율 구하기\n",
    "na_rate = df.isna().sum() / len(df)\n",
    "# print(na_rate)\n",
    "\n",
    "# 결측값 비율이 가장 높은 컬럼 이름 구하기\n",
    "na_rate = pd.DataFrame(na_rate)\n",
    "ds = na_rate.sort_values(by=0, ascending=False)  # 내림차순 정렬\n",
    "print(ds.index[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7865.34\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P210303.csv')\n",
    "\n",
    "# country, year, new_sp 컬럼 결측값 제거\n",
    "target = ['country', 'year', 'new_sp']\n",
    "df = df[target].dropna()\n",
    "\n",
    "# 2000년도의 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수 구하기\n",
    "crit1 = df['year'] == 2000\n",
    "mean_count = np.mean(df[crit1]['new_sp'])\n",
    "ans1 = round(mean_count, 2)\n",
    "print(ans1)\n",
    "\n",
    "# 2000년도의 결핵 발생 건수가 2000년도 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수보다 결핵 발생 건수가 높은 국가의 개수 구하기\n",
    "crit2 = df[crit1]['new_sp'] >= mean_count\n",
    "country = df[crit1][crit2]\n",
    "ans2 = len(country)\n",
    "print(ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220401.csv')\n",
    "\n",
    "# 1사분위수, 3사분위수 구하기\n",
    "q1 = np.quantile(df['y'], q=0.25)  # df['y'].quantile(0.25)\n",
    "q3 = np.quantile(df['y'], q=0.75)  # df['y'].quantile(0.75)\n",
    "\n",
    "# 3사분위수 - 1사분위수 구하기 (정수)\n",
    "result = q3 - q1\n",
    "ans = int(result)\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P220402.csv')\n",
    "\n",
    "# num_loves, num_wows : 긍정, 전체 반응에서 긍정인 비율 구하기\n",
    "df['positive'] = (df['num_loves'] + df['num_wows']) / df['num_reactions']\n",
    "\n",
    "# 긍정인 비율이 0.4보다 크고 0.5보다 작은 개수 구하기\n",
    "crit = (df['positive'] > 0.4) & (df['positive'] < 0.5)\n",
    "result = df[crit]\n",
    "\n",
    "ans = len(result)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P220403.csv')\n",
    "\n",
    "# 2018년 1월에 넷플릭스에 추가한 작품 구하기\n",
    "df['date_added'] = pd.to_datetime(df['date_added'], format=\"%B %d, %Y\")   # datetime64 형식으로 바꾸기\n",
    "# print(df['date_added'])\n",
    "\n",
    "# United Kingdom에 2018년 1월에 단독으로 제작된 작품 개수 구하기\n",
    "crit = (df['country'] == 'United Kingdom') & (df['date_added'].dt.year == 2018) & (df['date_added'].dt.month == 1)\n",
    "result = len(df[crit])\n",
    "ans = int(result)\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220501.csv', encoding='euc-kr')\n",
    "\n",
    "# 기준에 따른 데이터 추출\n",
    "crit = (df['종량제봉투종류'] == '규격봉투') & (df['종량제봉투용도'] == '음식물쓰레기') & (df['2L가격'] != 0)\n",
    "\n",
    "# 2L 가격의 평균값 구하기\n",
    "mean_price = df['2L가격'].mean()\n",
    "ans = int(mean_price)\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P220502.csv')\n",
    "\n",
    "# BMI 계산하여 분류 (bmi = weight / (height)^2)\n",
    "df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "\n",
    "# 정상 체중 범위 구간 인원, 위험 체중 범위 구간 인원의 차이를 절댓값 구하기\n",
    "crit1 = (df['BMI'] >= 18.5) & (df['BMI'] < 23)\n",
    "normal_count = len(df[crit1])\n",
    "\n",
    "crit2 = (df['BMI'] >= 23) & (df['BMI'] < 25)\n",
    "danger_count = len(df[crit2])\n",
    "\n",
    "ans = int(np.abs(normal_count - danger_count))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220503.csv', encoding='euc-kr')\n",
    "\n",
    "# df.info()\n",
    "\n",
    "# 순전입학생수 = 총전입학생수 - 총전출학생수\n",
    "df['순전입학생수'] = df['전입학생수(계)'] - df['전출학생수(계)']\n",
    "\n",
    "# 순전입학생수가 가장 큰 학교의 전체 학생수 구하기\n",
    "df = df.sort_values(by='순전입학생수', ascending=False)\n",
    "ans = df['전체학생수(계)'].iloc[0]\n",
    "\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230601.csv')\n",
    "\n",
    "# datetime64로 형식 바꾸기\n",
    "df['신고일시'] = pd.to_datetime(df['신고일시'])\n",
    "df['출동일시'] = pd.to_datetime(df['출동일시'])\n",
    "\n",
    "# 출동소방서별 신고일시로부터 출동일시까지의 연도별 월평균 구하기\n",
    "df['diff_time'] = (df['출동일시'] - df['신고일시']).dt.total_seconds()   # 초단위\n",
    "\n",
    "df = df.groupby([df['출동소방서'], df['신고일시'].dt.year, df['신고일시'].dt.month]).mean('diff_time')   # diff_time 열 평균 계산\n",
    "\n",
    "# 가장 늦게 출동한 출동소방서의 월평균 시간을 분단위로 나타내기\n",
    "df = df.sort_values(by='diff_time', ascending=False)\n",
    "\n",
    "result_date = df['diff_time'].head(1)\n",
    "result_num = float(result_date.iloc[0]) / 60   # 분단위\n",
    "\n",
    "ans = round(result_num)  # 정수로\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P230602.csv')\n",
    "\n",
    "# 교사 1인당 학생수 구하기\n",
    "df['tch_std'] = (df['student_1'] + df['student_2'] + df['student_3'] + df['student_4'] + df['student_5'] + df['student_6']) / df['teacher']\n",
    "\n",
    "# 교사 1인당 학생수가 가장 많은 학교 선정하기\n",
    "df_sort = df.sort_values(by='tch_std', ascending=False)\n",
    "\n",
    "result = df_sort['teacher'].head(1)\n",
    "ans = result.iloc[-1]   # 마지막 컬럼\n",
    "\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year   강력범    절도범    폭력범    지능범   풍속범  기타형사범  crim_sum\n",
      "6  2013  6276  61585  65422  76541  1562  20565    231951\n",
      "5  2012  6023  61329  70623  72238  1942  19345    231500\n",
      "4  2011  6905  54294  72044  71252  2377  16484    223356\n",
      "2  2009  4495  37175  73069  72262  6203  16864    210068\n",
      "19329\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./datasets/P230603.csv')\n",
    "\n",
    "# 연도별 월평균 범죄 건수 구하기\n",
    "df['crim_sum'] = df['강력범'] + df['절도범'] + df['폭력범'] + df['지능범'] + df['풍속범'] + df['기타형사범']\n",
    "df['year'] = df['년월'].str[:4]   # 앞에서 4글자 추출\n",
    "\n",
    "df1 = df.groupby('year', as_index=False).sum('crim_sum').sort_values(by='crim_sum', ascending=False)\n",
    "print(df1.head(4))   # 가장 많이 발생한 연도 : 2013년 확인\n",
    "\n",
    "# 가장 범죄가 많이 발생한 연도의 월평균 범죄 건수 구하기\n",
    "crit = df['year'] == '2013'\n",
    "df2 = df[crit]\n",
    "\n",
    "result_mean = df2['crim_sum'].mean()\n",
    "ans = round(result_mean)  # 정수로\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제2유형\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[987 343]\n",
      " [236 437]]\n",
      "0.7109335996005991\n",
      "0.7421052631578947\n",
      "0.8070318887980377\n",
      "0.7732079905992949\n",
      "0.6957183076562133\n",
      "[[0.38       0.62      ]\n",
      " [0.20666667 0.79333333]\n",
      " [0.60666667 0.39333333]\n",
      " ...\n",
      " [0.37333333 0.62666667]\n",
      " [0.29       0.71      ]\n",
      " [0.30333333 0.69666667]]\n",
      "         ID      pred\n",
      "0      8010  0.620000\n",
      "1      8011  0.793333\n",
      "2      8012  0.393333\n",
      "3      8013  0.563333\n",
      "4      8014  0.380000\n",
      "...     ...       ...\n",
      "2985  10995  0.710000\n",
      "2986  10996  0.583333\n",
      "2987  10997  0.626667\n",
      "2988  10998  0.710000\n",
      "2989  10999  0.696667\n",
      "\n",
      "[2990 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# (1) 훈련용 데이터\n",
    "## 데이터 불러오기\n",
    "df1 = pd.read_csv('./datasets/P210204-01.csv')\n",
    "\n",
    "## 요약 통계량 확인\n",
    "# print(df1.describe())\n",
    "\n",
    "## 속성 및 결측값 확인\n",
    "# print(df1.info())\n",
    "\n",
    "## 범주형으로 바꾸기\n",
    "df1['Reached.on.Time_Y.N'] = df1['Reached.on.Time_Y.N'].astype('category')\n",
    "\n",
    "# (2) 평가용 데이터\n",
    "df2 = pd.read_csv('./datasets/P210204-02.csv')\n",
    "\n",
    "## 요약 통계량 확인\n",
    "# print(df2.describe())\n",
    "\n",
    "## 속성 및 결측값 확인\n",
    "# print(df2.info())\n",
    "\n",
    "# (3) 데이터 전처리\n",
    "## 독립변수, 종속변수 구하기\n",
    "x = df1.drop('Reached.on.Time_Y.N', axis=1)\n",
    "y = df1['Reached.on.Time_Y.N']\n",
    "\n",
    "## 원-핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# (4) 모델링\n",
    "## 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded.drop('ID', axis=1), y, test_size=0.25)\n",
    "\n",
    "## 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "## 예측값 구하기\n",
    "pred = md.predict(x_valid)\n",
    "\n",
    "## 모델 평가\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(recall_score(y_valid, pred))\n",
    "print(precision_score(y_valid, pred))\n",
    "print(f1_score(y_valid, pred))\n",
    "print(roc_auc_score(y_valid, pred))\n",
    "\n",
    "# (5) 평가\n",
    "x_test = df2\n",
    "\n",
    "## 원-핫 인코딩\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "## 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_encoded.drop('ID', axis=1), y)\n",
    "\n",
    "pred = md.predict_proba(x_test_encoded.drop('ID', axis=1))\n",
    "print(pred)\n",
    "\n",
    "## 내보내기\n",
    "result = pd.DataFrame({\n",
    "    \"ID\": df2[\"ID\"],\n",
    "    \"pred\": pred[:, 1]\n",
    "})\n",
    "\n",
    "print(result)\n",
    "result.to_csv(\"./outputs/20240602Q2-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82  59]\n",
      " [ 15 217]]\n",
      "0.8016085790884718\n",
      "0.5815602836879432\n",
      "0.845360824742268\n",
      "0.6890756302521008\n",
      "0.7584525556370749\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8009, 1491]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m## 모델링\u001b[39;00m\n\u001b[0;32m     55\u001b[0m md \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m pred \u001b[38;5;241m=\u001b[39m md\u001b[38;5;241m.\u001b[39mpredict_proba(x_test_encoded)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "File \u001b[1;32mc:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32mc:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\utils\\validation.py:1281\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1281\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8009, 1491]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# 데이터 불러오기\n",
    "df1 = pd.read_csv('./datasets/P210304-01.csv')\n",
    "\n",
    "# print(df1.describe())\n",
    "# print(df1.info())\n",
    "\n",
    "df1['TravelInsurance'] = df1['TravelInsurance'].astype('category')\n",
    "\n",
    "df2 = pd.read_csv('./datasets/P210304-02.csv')\n",
    "\n",
    "# print(df2.describe())\n",
    "# print(df2.info())\n",
    "\n",
    "# 데이터 정제\n",
    "## 독립, 종속 구분\n",
    "x = df1.drop('TravelInsurance', axis=1)\n",
    "y = df1['TravelInsurance']\n",
    "\n",
    "## 원핫 인코딩\n",
    "encoded_x = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 모델링\n",
    "## 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(encoded_x, y, test_size=0.25)\n",
    "\n",
    "## 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "## 예측\n",
    "pred = md.predict(x_valid)\n",
    "\n",
    "## 평가\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(recall_score(y_valid, pred))\n",
    "print(precision_score(y_valid, pred))\n",
    "print(f1_score(y_valid, pred))\n",
    "print(roc_auc_score(y_valid, pred))\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "x_test = df2\n",
    "\n",
    "## 원핫 인코딩\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "## 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_encoded, y)\n",
    "\n",
    "pred = md.predict_proba(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    \"index\": df2[\"X\"],\n",
    "    \"y_pred\": pred[:, 1]\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
