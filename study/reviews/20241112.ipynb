{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20241112\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì œ1ìœ í˜•\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 1 (21ë…„ 2íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BostonHousing ë°ì´í„°\n",
    "- `crim` í•­ëª©ì˜ ìƒìœ„ì—ì„œ 10ë²ˆì§¸ ê°’(ìƒìœ„ 10ê°œì˜ ê°’ ì¤‘ì—ì„œ ê°€ì¥ ì ì€ ê°’)ìœ¼ë¡œ ìƒìœ„ 10ê°œì˜ ê°’ì„ ë³€í™˜í•˜ê³ , `age`ê°€ 80 ì´ìƒì¸ ê°’ì— ëŒ€í•˜ì—¬ `crim`ì˜ í‰ê·  êµ¬í•˜ê¸°\n",
    "- ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•´ì„œ ì†Œìˆ˜ì  2ì§¸ ìë¦¬ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ëª¨ë²” ë‹µì•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.76\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210201.csv')\n",
    "\n",
    "# crim í•­ëª©ì˜ ìƒìœ„ì—ì„œ 10ë²ˆì§¸ ê°’ ë½‘ê¸°\n",
    "new_df = df.sort_values(by='crim', ascending=False)   # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "top10 = new_df.head(10)\n",
    "top10_value = top10['crim'].iloc[9]\n",
    "\n",
    "# ìƒìœ„ 10ê°œì˜ ê°’ ë³€í™˜í•˜ê¸°\n",
    "df['crim'] = np.where(df['crim'] >= top10_value, top10_value, df['crim'])\n",
    "\n",
    "# ageê°€ 80 ì´ìƒì¸ ê°’ì— ëŒ€í•˜ì—¬ crimì˜ í‰ê·  êµ¬í•˜ê¸°\n",
    "mean_value = df['crim'][df['age'] >= 80].mean()\n",
    "answer = round(mean_value, 2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gpt ë‹µì•ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ìƒìœ„ `n`ë²ˆì§¸ ê°’ ë½‘ê¸° : `df['col'].nlargest(n).iloc[-1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.76\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210201.csv')\n",
    "\n",
    "# 'crim' í•­ëª©ì˜ ìƒìœ„ 10ë²ˆì§¸ ê°’ ë½‘ê¸°\n",
    "top10_value = df['crim'].nlargest(10).iloc[-1]\n",
    "\n",
    "# ìƒìœ„ 10ê°œì˜ ê°’ì„ ë³€í™˜í•˜ê¸°\n",
    "df['crim'] = np.where(df['crim'] >= top10_value, top10_value, df['crim'])\n",
    "\n",
    "# 'age'ê°€ 80 ì´ìƒì¸ ê°’ì— ëŒ€í•´ 'crim'ì˜ í‰ê·  êµ¬í•˜ê¸°\n",
    "answer = round(df.loc[df['age'] >= 80, 'crim'].mean(), 2)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 2 (21ë…„ 2íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- housing ë°ì´í„°\n",
    "- ë°ì´í„°ì˜ ì²« ë²ˆì§¸ í–‰ë¶€í„° ìˆœì„œëŒ€ë¡œ 80%ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí•œ í›„, `total_bedrooms` ë³€ìˆ˜ì˜ ê²°ì¸¡ê°’(NA)ì„ `total_bedrooms` ë³€ìˆ˜ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê³  ëŒ€ì²´ ì „ì˜ `total_bedrooms` ë³€ìˆ˜ í‘œì¤€í¸ì°¨ ê°’ê³¼ ëŒ€ì²´ í›„ì˜ `total_bedrooms` ë³€ìˆ˜ í‘œì¤€í¸ì°¨ ê°’ì˜ ì°¨ì´ì˜ ì ˆëŒ“ê°’ êµ¬í•˜ê¸°\n",
    "- ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ëª¨ë²” ë‹µì•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kss34\\AppData\\Local\\Temp\\ipykernel_29564\\3535471237.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['total_bedrooms'] = train_df['total_bedrooms'].fillna(train_df['total_bedrooms'].median())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210202.csv')\n",
    "\n",
    "# ìƒìœ„ 80%ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí•˜ê¸°\n",
    "nrow = int(len(df) * 0.8)\n",
    "train_df = df[:nrow]\n",
    "\n",
    "a = train_df['total_bedrooms'].std()\n",
    "\n",
    "# total_bedrooms ë³€ìˆ˜ì˜ ê²°ì¸¡ê°’ì„ total_bedrooms ë³€ìˆ˜ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "train_df['total_bedrooms'] = train_df['total_bedrooms'].fillna(train_df['total_bedrooms'].median())\n",
    "\n",
    "b = train_df['total_bedrooms'].std()\n",
    "\n",
    "# ëŒ€ì²´ ì „ì˜ total_bedrooms ë³€ìˆ˜ í‘œì¤€í¸ì°¨ ê°’ê³¼ ëŒ€ì²´ í›„ì˜ total_bedrooms ë³€ìˆ˜ í‘œì¤€í¸ì°¨ ê°’ì˜ ì°¨ì´ì˜ ì ˆëŒ“ê°’ êµ¬í•˜ê¸°\n",
    "answer = round(abs(a - b), 2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gpt ë‹µì•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('./datasets/P210202.csv')\n",
    "\n",
    "# ìƒìœ„ 80%ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí•˜ê¸°\n",
    "train_df = df.iloc[:int(len(df) * 0.8)]\n",
    "\n",
    "# total_bedrooms ë³€ìˆ˜ì˜ ê²°ì¸¡ê°’ì„ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê³ , í‘œì¤€í¸ì°¨ ì°¨ì´ì˜ ì ˆëŒ“ê°’ ê³„ì‚°í•˜ê¸°\n",
    "answer = round(abs(train_df['total_bedrooms'].std() - train_df['total_bedrooms'].fillna(train_df['total_bedrooms'].median()).std()), 2)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 3 (21ë…„ 2íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Insurance ë°ì´í„°\n",
    "- `charges` í•­ëª©ì—ì„œ ì´ìƒê°’ì˜ í•© êµ¬í•˜ê¸°\n",
    "- ì´ìƒê°’ì€ í‰ê· ì—ì„œ 1.5 í‘œì¤€í¸ì°¨ ì´ìƒì¸ ê°’ìœ¼ë¡œ í•˜ê³ , ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6421430\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210203.csv')\n",
    "\n",
    "# ì´ìƒê°’ -> x > upper or x < lower\n",
    "# upper = í‰ê·  + 1.5 * í‘œì¤€í¸ì°¨\n",
    "# lower = í‰ê·  - 1.5 * í‘œì¤€í¸ì°¨\n",
    "\n",
    "target = df['charges']\n",
    "\n",
    "mean_value = target.mean()\n",
    "std_value = target.std()\n",
    "\n",
    "upper = mean_value + 1.5 * std_value\n",
    "lower = mean_value - 1.5 * std_value\n",
    "\n",
    "cond = (target < lower) | (target > upper)\n",
    "answer = int(target[cond].sum())\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 4 (21ë…„ 3íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- housing ë°ì´í„°\n",
    "- ê²°ì¸¡ê°’ì´ ìˆëŠ” ëª¨ë“  í–‰ì„ ì œê±°í•œ í›„ ë°ì´í„°ì˜ ìˆœì„œëŒ€ë¡œ ìƒìœ„ 70%ì˜ ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ë§Œë“¤ê³ , í›ˆë ¨ ë°ì´í„°ì˜ `housing_median_age` ì»¬ëŸ¼ì˜ ì œ1ì‚¬ë¶„ìœ„ìˆ˜(Q1) êµ¬í•˜ê¸°\n",
    "- ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210301.csv')\n",
    "\n",
    "# ê²°ì¸¡ê°’ì´ ìˆëŠ” ëª¨ë“  í–‰ ì œê±°í•˜ê¸°\n",
    "# print(np.sum(df.isna().any(axis=1)))  # ê²°ì¸¡ê°’ ê°œìˆ˜ ì¶œë ¥í•´ë³´ê¸°\n",
    "df = df.dropna()\n",
    "\n",
    "# ë°ì´í„°ì˜ ìˆœì„œëŒ€ë¡œ ìƒìœ„ 70%ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ë§Œë“¤ê¸°\n",
    "nrow = int(len(df) * 0.7)\n",
    "train_df = df[:nrow]\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°ì˜ house_median_age ì»¬ëŸ¼ì˜ Q1 êµ¬í•˜ê¸°\n",
    "answer = int(train_df['housing_median_age'].quantile(0.25))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 5 (21ë…„ 3íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- íƒ€ì´íƒ€ë‹‰ ë°ì´í„°\n",
    "- ë°ì´í„°ê°€ ì—†ëŠ” ê²ƒì„ ê²°ì¸¡ê°’ìœ¼ë¡œ í•˜ì—¬ ê²°ì¸¡ê°’ì˜ ë¹„ìœ¨ì„ êµ¬í•˜ê³ , ê²°ì¸¡ê°’ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ ì»¬ëŸ¼ ì´ë¦„ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "Age          0.198653\n",
      "Embarked     0.002245\n",
      "PassengerId  0.000000\n",
      "Survived     0.000000\n",
      "Pclass       0.000000\n",
      "Name         0.000000\n",
      "Sex          0.000000\n",
      "SibSp        0.000000\n",
      "Parch        0.000000\n",
      "Ticket       0.000000\n",
      "Fare         0.000000 \n",
      "\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210302.csv')\n",
    "\n",
    "# ë°ì´í„°ê°€ ì—†ëŠ” ê²ƒì„ ê²°ì¸¡ê°’ìœ¼ë¡œ í•˜ì—¬ ê²°ì¸¡ê°’ì˜ ë¹„ìœ¨ êµ¬í•˜ê¸°\n",
    "total_count = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "\n",
    "ratio = missing_count / total_count\n",
    "\n",
    "# ê²°ì¸¡ê°’ì˜ ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ ì»¬ëŸ¼ ì´ë¦„ êµ¬í•˜ê¸°\n",
    "ratio = pd.DataFrame(ratio)\n",
    "\n",
    "sorted_ratio = ratio.sort_values(by=0, ascending=False)\n",
    "print(sorted_ratio, '\\n')\n",
    "\n",
    "answer = sorted_ratio.index[0]   # index[n]ëŠ” ì»¬ëŸ¼ ì´ë¦„ì„ ë°˜í™˜í•œë‹¤.\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 6 (21ë…„ 3íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì—°ë„ë³„ ê° êµ­ê°€ì˜ ê²°í•µ ê°ì—¼ì— ëŒ€í•œ ìœ ë³‘ë¥  ë°ì´í„°\n",
    "- `country`, `year`, `new_sp` ì»¬ëŸ¼ì— ê²°ì¸¡ê°’ì´ ìˆì„ ê²½ìš° ì œê±°í•˜ê³  2000ë…„ë„ì— êµ­ê°€ë³„ ê²°í•µ ë°œìƒ ê±´ìˆ˜ì— ëŒ€í•œ í‰ê·  ê²°í•µ ë°œìƒ ê±´ìˆ˜ë¥¼ êµ¬í•˜ê³ , 2000ë…„ë„ì˜ ê²°í•µ ë°œìƒ ê±´ìˆ˜ê°€ 2000ë…„ë„ êµ­ê°€ë³„ ê²°í•µ ë°œìƒ ê±´ìˆ˜ì— ëŒ€í•œ í‰ê·  ê²°í•µ ë°œìƒ ê±´ìˆ˜ë³´ë‹¤ ê²°í•µ ë°œìƒ ê±´ìˆ˜ê°€ ë†’ì€ êµ­ê°€ì˜ ê°œìˆ˜ êµ¬í•˜ê¸°\n",
    "- êµ­ê°€ë³„ ê²°í•µ ë°œìƒ ê±´ìˆ˜ì— ëŒ€í•œ í‰ê·  ê²°í•µ ë°œìƒ ê±´ìˆ˜ë¥¼ ì¶œë ¥í•  ë•Œ, ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7865.34\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210303.csv')\n",
    "\n",
    "# country, year, new_sp ì»¬ëŸ¼ì—ì„œ ê²°ì¸¡ê°’ ì œê±°í•˜ê¸°\n",
    "df['country'] = df['country'].dropna()\n",
    "df['year'] = df['year'].dropna()\n",
    "df['new_sp'] = df['new_sp'].dropna()\n",
    "\n",
    "# 2000ë…„ë„ì— êµ­ê°€ë³„ ê²°í•µ ë°œìƒ ê±´ìˆ˜ì— ëŒ€í•œ í‰ê·  ê²°í•µ ë°œìƒ ê±´ìˆ˜ êµ¬í•˜ê¸°\n",
    "cond = df['year'] == 2000\n",
    "target_df = df[cond]\n",
    "\n",
    "mean_count = round(target_df['new_sp'].mean(), 2)\n",
    "print(mean_count)\n",
    "\n",
    "# 2000ë…„ë„ì˜ ê²°í•µ ë°œìƒ ê±´ìˆ˜ê°€ 2000ë…„ë„ êµ­ê°€ë³„ ê²°í•µ ë°œìƒ ê±´ìˆ˜ì— ëŒ€í•œ í‰ê·  ê²°í•µ ë°œìƒ ê±´ìˆ˜ë³´ë‹¤ ê²°í•µ ë°œìƒ ê±´ìˆ˜ê°€ ë†’ì€ êµ­ê°€ì˜ ê°œìˆ˜ êµ¬í•˜ê¸°\n",
    "cond = target_df['new_sp'] >= mean_count\n",
    "answer = len(target_df[cond])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 7 (22ë…„ 4íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "    - (1) y ë³€ìˆ˜ì˜ 1ì‚¬ë¶„ìœ„ì™€ 3ì‚¬ë¶„ìœ„ ê°’ êµ¬í•˜ê¸°\n",
    "    - (2) 3ì‚¬ë¶„ìœ„ìˆ˜ì—ì„œ 1ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ ëº€ ê°’ êµ¬í•˜ê¸°\n",
    "    - (3) ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 40.25, Q3: 77.0\n",
      "Q3-Q1(IQR): 36.75\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220401.csv')\n",
    "\n",
    "# (1) y ë³€ìˆ˜ì˜ 1ì‚¬ë¶„ìœ„ì™€ 3ì‚¬ë¶„ìœ„ ê°’ êµ¬í•˜ê¸°\n",
    "target = df['y']\n",
    "\n",
    "q1 = target.quantile(0.25)\n",
    "q3 = target.quantile(0.75)\n",
    "\n",
    "print(f\"Q1: {q1}, Q3: {q3}\")\n",
    "\n",
    "# (2) 3ì‚¬ë¶„ìœ„ìˆ˜ì—ì„œ 1ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ ëº€ ê°’ êµ¬í•˜ê¸°\n",
    "diff_value = q3 - q1\n",
    "\n",
    "print(f\"Q3-Q1(IQR): {diff_value}\") \n",
    "\n",
    "# (3) ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "answer = int(diff_value)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 8 (22ë…„ 4íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í˜ì´ìŠ¤ë¶ í‰ê°€ ë°ì´í„°\n",
    "- 'ì¢‹ì•„ìš”' ìˆ˜(`num_loves`)ì™€ 'ë†€ëì–´ìš”'(`num_wows`)ë¥¼ ê¸ì •ì˜ í‰ê°€ë¡œ ë³´ê³  ì „ì²´ ë°˜ì‘(`num_reactions`)ì—ì„œ ê¸ì •ì¸ ë¹„ìœ¨ì´ 0.4ë³´ë‹¤ í¬ê³  0.5ë³´ë‹¤ ì‘ì€ ë¹„ë””ì˜¤ ê°œìˆ˜ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220402.csv')\n",
    "\n",
    "# ì¢‹ì•„ìš” ìˆ˜ì™€ ë†€ëì–´ìš” ìˆ˜ë¥¼ ê¸ì •ì˜ í‰ê°€ë¡œ ë³´ê³  ì „ì²´ ì¤‘ì—ì„œ ë¹„ìœ¨ êµ¬í•˜ê¸°\n",
    "df['positive_ratio'] = (df['num_loves'] + df['num_wows']) / df['num_reactions']\n",
    "\n",
    "# ì „ì²´ ë°˜ì‘ì—ì„œ ê¸ì •ì¸ ë¹„ìœ¨ì´ 0.4ë³´ë‹¤ í¬ê³  0.5ë³´ë‹¤ ì‘ì€ ë¹„ë””ì˜¤ ê°œìˆ˜ êµ¬í•˜ê¸°\n",
    "cond = (df['status_type'] == 'video') & ((df['positive_ratio'] > 0.4) & (df['positive_ratio'] < 0.5))\n",
    "answer = len(df[cond])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 9 (22ë…„ 4íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë„·í”Œë¦­ìŠ¤ì—ì„œ ì‚¬ìš©ëœ ì‘í’ˆë“¤ì˜ ëª©ë¡ ë°ì´í„°\n",
    "- 2018ë…„ 1ì›”ì— ë„·í”Œë¦­ìŠ¤ì—ì„œ ì¶”ê°€í•œ ì‘í’ˆ ì¤‘ 'United Kingdom'ì—ì„œ ë‹¨ë…ìœ¼ë¡œ ì œì‘ëœ ì‘í’ˆì˜ ê°œìˆ˜ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220403.csv')\n",
    "\n",
    "# ë‚ ì§œ í•­ëª©ì„ datetime64 í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸°\n",
    "df['date_added'] = pd.to_datetime(df['date_added'])\n",
    "\n",
    "# 2018ë…„ 1ì›”ì— ì¶”ê°€í•œ ì‘í’ˆ ì¤‘, 'United Kingdom'ì—ì„œ ë‹¨ë…ìœ¼ë¡œ ì œì‘ëœ ì‘í’ˆì˜ ê°œìˆ˜ êµ¬í•˜ê¸°\n",
    "cond1 = (df['date_added'].dt.year == 2018) & (df['date_added'].dt.month == 1)\n",
    "cond2 = df['country'] == 'United Kingdom'\n",
    "\n",
    "answer = len(df[cond1 & cond2])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 10 (22ë…„ 5íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì¢…ëŸ‰ì œ ì“°ë ˆê¸° ë°ì´í„°\n",
    "- ì“°ë ˆê¸° ë°ì´í„°ì—ì„œ ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¥¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ , í‰ê·  ê°€ê²©ì„ ì œì¶œ í˜•ì‹ì— ë”°ë¼ ì œì¶œí•˜ê¸°\n",
    "    - ì¢…ëŸ‰ì œë´‰íˆ¬ì¢…ë¥˜ : ê·œê²©ë´‰íˆ¬\n",
    "    - ì¢…ëŸ‰ì œë´‰íˆ¬ìš©ë„ : ìŒì‹ë¬¼ì“°ë ˆê¸°\n",
    "    - ì¢…ëŸ‰ì œë´‰íˆ¬ìš©ëŸ‰ : 2L\n",
    "    - ê°€ê²©ì´ 0ì¸ ê²ƒì€ êµ¬ë§¤í•˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ, í‰ê·  ê³„ì‚°í•  ë•Œ ì œì™¸í•œë‹¤.\n",
    "- ì •ìˆ˜í˜•ìœ¼ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220501.csv', encoding='euckr')\n",
    "\n",
    "# ì¢…ëŸ‰ì œë´‰íˆ¬ì¢…ë¥˜ : ê·œê²©ë´‰íˆ¬, ì¢…ëŸ‰ì œë´‰íˆ¬ìš©ë„ : ìŒì‹ë¬¼ì“°ë ˆê¸°, ì¢…ëŸ‰ì œë´‰íˆ¬ìš©ëŸ‰ : 2L (ê°€ê²©ì´ 0ì¸ ê²ƒì€ ì œì™¸í•˜ê¸°)\n",
    "cond = (df['ì¢…ëŸ‰ì œë´‰íˆ¬ì¢…ë¥˜'] == 'ê·œê²©ë´‰íˆ¬') & (df['ì¢…ëŸ‰ì œë´‰íˆ¬ìš©ë„'] == 'ìŒì‹ë¬¼ì“°ë ˆê¸°') & (df['2Lê°€ê²©'] != 0)\n",
    "new_df = df[cond]\n",
    "\n",
    "# í‰ê·  ê°€ê²© êµ¬í•˜ê¸°\n",
    "mean_price = new_df['2Lê°€ê²©'].mean()\n",
    "answer = int(mean_price)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 11 (22ë…„ 5íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Body ë°ì´í„°\n",
    "- ë‹¤ìŒ ê¸°ì¤€ì— ì˜í•´ BMIë¥¼ ê³„ì‚°í•˜ì—¬ ë¶„ë¥˜í•˜ê³ , ì •ìƒ ì²´ì¤‘ ë²”ìœ„ì˜ êµ¬ê°„ì— ìˆëŠ” ì¸ì›ê³¼ ìœ„í—˜ ì²´ì¤‘ ë²”ìœ„ì˜ êµ¬ê°„ì— ìˆëŠ” ì¸ì›ì˜ ì°¨ì´ë¥¼ ì ˆëŒ“ê°’ìœ¼ë¡œ êµ¬í•˜ê¸°\n",
    "    - BMI = Weight / HeightÂ² (weight : kg, height : m)\n",
    "    - ì €ì²´ì¤‘ :  BMI < 18.5\n",
    "    - ì •ìƒì²´ì¤‘ : 18.5 â‰¤ BMI < 23\n",
    "    - ìœ„í—˜ì²´ì¤‘ : 23 â‰¤ BMI < 25\n",
    "    - ë¹„ë§Œ : 25 â‰¤ BMI\n",
    "- BMI ê³„ì‚°ì‹œ ë‹¨ìœ„ì— ìœ ì˜í•˜ê³ , ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220502.csv')\n",
    "\n",
    "# BMI ê³„ì‚°í•˜ê¸°\n",
    "df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)    # âœ… ë‹¨ìœ„ì— ì£¼ì˜í•  ê²ƒ!\n",
    "\n",
    "# ì •ìƒ ì²´ì¤‘ ë²”ìœ„ êµ¬ê°„ì˜ ì¸ì› ìˆ˜ì™€ ìœ„í—˜ ì²´ì¤‘ ë²”ìœ„ êµ¬ê°„ì˜ ì¸ì› ìˆ˜ êµ¬í•˜ê¸°\n",
    "cond1 = (18.5 <= df['BMI']) & (df['BMI'] < 23)\n",
    "healthy = len(df[cond1])\n",
    "\n",
    "cond2 = (23 <= df['BMI']) & (df['BMI'] < 25)\n",
    "danger = len(df[cond2])\n",
    "\n",
    "answer = int(abs(healthy - danger))\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 12 (22ë…„ 5íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ìˆœì „ì…í•™ìƒìˆ˜ê°€ ê°€ì¥ í° í•™êµì˜ ì „ì²´ í•™ìƒìˆ˜ êµ¬í•˜ê¸°\n",
    "    - ìˆœì „ì…í•™ìƒìˆ˜ = ì´ì „ì…í•™ìƒìˆ˜ - ì´ì „ì¶œí•™ìƒìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220503.csv', encoding='euckr')\n",
    "\n",
    "# ìˆœì „ì…í•™ìƒìˆ˜ êµ¬í•˜ê¸° (ìˆœì „ì…í•™ìƒìˆ˜ = ì´ì „ì…í•™ìƒìˆ˜ - ì´ì „ì¶œí•™ìƒìˆ˜)\n",
    "df['ìˆœì „ì…í•™ìƒìˆ˜'] = df['ì „ì…í•™ìƒìˆ˜(ê³„)'] - df['ì „ì¶œí•™ìƒìˆ˜(ê³„)']\n",
    "\n",
    "# ìˆœì „ì…í•™ìƒìˆ˜ê°€ ê°€ì¥ í° í•™êµì˜ ì „ì²´ í•™ìƒìˆ˜ êµ¬í•˜ê¸°\n",
    "new_df = df.sort_values(by='ìˆœì „ì…í•™ìƒìˆ˜', ascending=False).reset_index(drop=True)\n",
    "answer = new_df['ì „ì²´í•™ìƒìˆ˜(ê³„)'].iloc[0]\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 13 (23ë…„ 6íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì¶œë™ì†Œë°©ì„œë³„ë¡œ ì£¼ë¯¼ìœ¼ë¡œë¶€í„° ì—°ë½ë°›ì€ ì‹ ê³ ì¼ì‹œì™€ ì¶œë™í•œ ì¶œë™ì¼ì‹œë¥¼ ê¸°ë¡í•œ ë°ì´í„°\n",
    "- ì¶œë™ì†Œë°©ì„œë³„ ì‹ ê³ ì¼ì‹œë¡œë¶€í„° ì¶œë™ì¼ì‹œê¹Œì§€ì˜ ì—°ë„ë³„ ì›”í‰ê· ì„ êµ¬í•˜ê³ , ê°€ì¥ ëŠ¦ê²Œ ì¶œë™í•œ ì¶œë™ì†Œë°©ì„œì˜ ì›”í‰ê·  ì‹œê°„ì„ ë¶„ë‹¨ìœ„ë¡œ ì œì¶œ í˜•ì‹ì— ë§ê²Œ ì œì¶œí•˜ê¸°\n",
    "- ì‹œê°„ì€ 30ì´ˆ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì œì¶œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230601.csv')\n",
    "\n",
    "# ì‹ ê³ ì¼ì‹œ, ì¶œë™ì¼ì‹œ ì»¬ëŸ¼ì„ datetime64 í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê¸°\n",
    "df['ì‹ ê³ ì¼ì‹œ'] = pd.to_datetime(df['ì‹ ê³ ì¼ì‹œ'])\n",
    "df['ì¶œë™ì¼ì‹œ'] = pd.to_datetime(df['ì¶œë™ì¼ì‹œ'])\n",
    "\n",
    "# ì¶œë™ì†Œë°©ì„œë³„ ì‹ ê³ ì¼ì‹œë¡œë¶€í„° ì¶œë™ì¼ì‹œê¹Œì§€ ì—°ë„ë³„ ì›”í‰ê·  êµ¬í•˜ê¸°\n",
    "df['ì‹œê°„ì°¨ì´'] = (df['ì¶œë™ì¼ì‹œ'] - df['ì‹ ê³ ì¼ì‹œ']).dt.total_seconds()\n",
    "\n",
    "df = df.groupby([df['ì¶œë™ì†Œë°©ì„œ'], df['ì‹ ê³ ì¼ì‹œ'].dt.year, df['ì‹ ê³ ì¼ì‹œ'].dt.month]).mean('ì‹œê°„ì°¨ì´')\n",
    "df = df.sort_values(by='ì‹œê°„ì°¨ì´', ascending=False)\n",
    "\n",
    "# ê°€ì¥ ëŠ¦ê²Œ ì¶œë™í•œ ì¶œë™ì†Œë°©ì„œì˜ ì›”í‰ê·  ì‹œê°„ì„ ë¶„ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚´ê¸°\n",
    "result_date = df['ì‹œê°„ì°¨ì´'].head(1)\n",
    "result_num = float(result_date.iloc[0]) / 60    # ë¶„ë‹¨ìœ„\n",
    "answer = int(result_num)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 14 (23ë…„ 6íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì´ˆë“±í•™êµì˜ í•™ë…„ë³„ í•™ìƒ ìˆ˜ì™€ êµì‚¬ ìˆ˜ë¥¼ ê¸°ë¡í•œ ë°ì´í„°\n",
    "- êµì‚¬ 1ì¸ë‹¹ í•™ìƒ ìˆ˜ê°€ ê°€ì¥ ë§ì€ í•™êµë¥¼ ì„ ì •í•˜ê³ , ì„ ì •ëœ í•™êµì˜ êµì‚¬ ìˆ˜ë¥¼ ì œì¶œ í˜•ì‹ì— ë§ê²Œ ì œì¶œí•˜ê¸°\n",
    "- í•™êµëª… ì¤‘ë³µì€ ì—†ê³ , ë‹¨ì¼ í•™êµì˜ í•™ìƒ ìˆ˜, êµì‚¬ ìˆ˜ ë°ì´í„°ë§Œ ìˆëŠ” ê²ƒìœ¼ë¡œ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230602.csv')\n",
    "\n",
    "# êµì‚¬ 1ì¸ë‹¹ í•™ìƒìˆ˜ê°€ ê°€ì¥ ë§ì€ í•™êµ ì„ ì •í•˜ê¸°\n",
    "df['student_number_per_teacher'] = (df['student_1'] + df['student_2'] + df['student_3'] + df['student_4'] + df['student_5'] + df['student_6']) / df['teacher']\n",
    "df_sorted = df.sort_values(by='student_number_per_teacher', ascending=False)\n",
    "\n",
    "target_df = df_sorted.head(1)\n",
    "\n",
    "# ì„ ì •ëœ í•™êµì˜ êµì‚¬ìˆ˜ êµ¬í•˜ê¸°\n",
    "answer = target_df['teacher'].iloc[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 15 (23ë…„ 6íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì›”ë³„ ë²”ì£„ë¥¼ ê¸°ë¡í•œ ë°ì´í„°\n",
    "- ì—°ë„ë³„ ì›”í‰ê·  ë²”ì£„ ê±´ìˆ˜ë¥¼ êµ¬í•˜ê³ , ê°€ì¥ ë²”ì£„ê°€ ë§ì´ ë°œìƒí•œ ì—°ë„ì˜ ì›”í‰ê·  ë²”ì£„ ê±´ìˆ˜ êµ¬í•˜ê¸°\n",
    "- íŒŒì´ì¬ì˜ ê²½ìš° CSV íŒŒì¼ì„ ì½ì„ ë•Œ `index_col=0` ì˜µì…˜ì„ ì ìš©í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19329\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230603.csv')\n",
    "\n",
    "# ë…„ì›” ì»¬ëŸ¼ì„ datetime64 ì»¬ëŸ¼ìœ¼ë¡œ ë°”ê¾¸ê¸°\n",
    "df['ë…„ì›”'] = pd.to_datetime(df['ë…„ì›”'])\n",
    "\n",
    "# ì—°ë„ë³„ ì›”í‰ê·  ë²”ì£„ ê±´ìˆ˜ êµ¬í•˜ê¸°\n",
    "df['ë°œìƒì—°ë„'] = df['ë…„ì›”'].dt.year\n",
    "df['ë°œìƒì›”'] = df['ë…„ì›”'].dt.month\n",
    "df['ì´ë²”ì£„ê±´ìˆ˜'] = df['ê°•ë ¥ë²”'] + df['ì ˆë„ë²”'] + df['í­ë ¥ë²”'] + df['ì§€ëŠ¥ë²”'] + df['í’ì†ë²”'] + df['ê¸°íƒ€í˜•ì‚¬ë²”']\n",
    "\n",
    "df = df.groupby(by=['ë°œìƒì—°ë„']).mean()   # ì›”í‰ê·  ë²”ì£„ ê±´ìˆ˜\n",
    "\n",
    "# ê°€ì¥ ë²”ì£„ê°€ ë§ì´ ë°œìƒí•œ ì—°ë„ì˜ ì›”í‰ê·  ë²”ì£„ ê±´ìˆ˜ êµ¬í•˜ê¸°\n",
    "df = df.sort_values(by='ì´ë²”ì£„ê±´ìˆ˜', ascending=False).head(1)\n",
    "answer = int(df['ì´ë²”ì£„ê±´ìˆ˜'].iloc[0])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 16 (23ë…„ 7íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í•™ìƒ 15ëª…ì˜ êµ­ì–´, ìˆ˜í•™, ì˜ì–´, ê³¼í•™ ì‹œí—˜ ì ìˆ˜ (ê° í•™ìƒì€ 4ê³¼ëª© ì¤‘ 3ê³¼ëª©ì„ ì„ íƒí•´ì„œ ì‹œí—˜ë´¤ë‹¤.)\n",
    "- êµ­ì–´, ìˆ˜í•™, ì˜ì–´, ê³¼í•™ ê³¼ëª© ì¤‘ ê°€ì¥ ë§ì€ í•™ìƒë“¤ì´ ì‘ì‹œí•œ ì‹œí—˜ì„ ì„ íƒí•˜ê³ , í•´ë‹¹ ê³¼ëª©ì˜ ì ìˆ˜ë¥¼ í‘œì¤€í™” í–ˆì„ ë•Œ ê°€ì¥ í° í‘œì¤€í™” ì ìˆ˜ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> í‘œì¤€í™”(Standardization)\n",
    "> - ì–´ë–¤ íŠ¹ì •ì˜ ê°’ë“¤ì´ **ì •ê·œ ë¶„í¬**ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•˜ê³  ê°’ë“¤ì„ `0`ì˜ **í‰ê· ,** `1`ì˜ **í‘œì¤€í¸ì°¨**ë¥¼ ê°–ë„ë¡ í•´ì£¼ëŠ” ê¸°ë²•\n",
    "\n",
    "> **Z-ì ìˆ˜(Z-Score)**\n",
    "> \n",
    "> - ì´ìƒê°’(Outlier) ë¬¸ì œë¥¼ í”¼í•˜ëŠ” ê¸°ë²•\n",
    "> - ë°ì´í„°ë“¤ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•˜ê³ , í‰ê·  ëŒ€ë¹„ ëª‡ í‘œì¤€í¸ì°¨ë§Œí¼ ë°ì´í„°ê°€ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ë¥¼ ì ìˆ˜í™”í•œë‹¤.\n",
    "> - `X`ì˜ ê°’ì´ í‰ê· ê³¼ ì¼ì¹˜í•˜ë©´ `0`, í‰ê· ë³´ë‹¤ ì‘ìœ¼ë©´ **ìŒìˆ˜**, í‰ê· ë³´ë‹¤ í¬ë©´ **ì–‘ìˆ˜**ê°€ ë˜ë©°, í‘œì¤€í¸ì°¨ê°€ í¬ë©´ Z-ìŠ¤ì½”ì–´ëŠ” `0`ì— ê°€ê¹Œì›Œì§„ë‹¤.\n",
    "\n",
    "> $$Z = \\frac{X - \\overline{X}}{s}$$\n",
    "\n",
    "> $$X: ë°ì´í„° \\quad \\overline{X}: í‘œë³¸í‰ê·  \\quad s: í‘œë³¸í‘œì¤€í¸ì°¨ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 12 11 9\n",
      "1.713855688712825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "df = pd.read_csv('./datasets/P230701.csv')\n",
    "\n",
    "# ê° ê³¼ëª©ë³„ ê²°ì¸¡ì¹˜ ì œê±° í›„ ê°œìˆ˜ íŒŒì•…í•˜ê¸°\n",
    "count_korean = df['êµ­ì–´'].dropna().count()\n",
    "count_math = df['ìˆ˜í•™'].dropna().count()\n",
    "count_english = df['ì˜ì–´'].dropna().count()\n",
    "count_science = df['ê³¼í•™'].dropna().count()\n",
    "\n",
    "print(count_korean, count_math, count_english, count_science)\n",
    "\n",
    "target = df['êµ­ì–´']\n",
    "\n",
    "# í‘œì¤€í™” (Z-ì ìˆ˜ í‘œì¤€í™” = X-í‰ê·  / í‘œì¤€í¸ì°¨) í›„ ê°€ì¥ í° ì ìˆ˜ êµ¬í•˜ê¸°\n",
    "target = target.dropna()   # ê²°ì¸¡ì¹˜ ì œê±°\n",
    "\n",
    "answer = zscore(target).max()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 17 (23ë…„ 7íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32ê°œ ë³€ìˆ˜ê°„ ìƒê´€ ê´€ê³„ë¥¼ í™•ì¸í–ˆì„ ë•Œ, `var_11` ì»¬ëŸ¼ê³¼ ìƒê´€ ê³„ìˆ˜ì˜ ì ˆëŒ“ê°’ì´ ê°€ì¥ í° ë³€ìˆ˜ë¥¼ ì°¾ì•„ í•´ë‹¹ ë³€ìˆ˜ì˜ í‰ê· ê°’ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_44\n",
      "0.22367215340392685\n",
      "0.06404313251242914\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230702.csv')\n",
    "\n",
    "# var_11 ì»¬ëŸ¼ê³¼ ìƒê´€ ê³„ìˆ˜ì˜ ì ˆëŒ“ê°’ì´ ê°€ì¥ í° ë³€ìˆ˜ ì°¾ê¸°\n",
    "df_corr = df.corr(numeric_only=True)   # ìƒê´€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "\n",
    "target = df_corr['var_11']\n",
    "\n",
    "abs_target = np.abs(target)   # ì ˆëŒ“ê°’ ì”Œìš°ê¸°\n",
    "sorted_target = abs_target.sort_values(ascending=False)   # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "\n",
    "result_variable = sorted_target.index[1]\n",
    "print(result_variable)    # ë³€ìˆ˜ëª…\n",
    "print(sorted_target['var_44'])   # ë³€ìˆ˜ê°’\n",
    "\n",
    "# ì°¾ì€ ë³€ìˆ˜ì˜ í‰ê· ê°’ êµ¬í•˜ê¸°\n",
    "answer = df[result_variable].mean()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 18 (23ë…„ 7íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `var_6` ì»¬ëŸ¼ì˜ 1, 3ì‚¬ë¶„ìœ„ìˆ˜ ê°ê° IQRì˜ 1.5ë°° ë²—ì–´ë‚œ ì´ìƒì¹˜ì˜ ìˆ«ì êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5939812454434104 0.6428288851668509 1.2368101306102612\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230703.csv')\n",
    "\n",
    "# var_6 ì»¬ëŸ¼ì˜ 1, 3ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ êµ¬í•˜ê³ , IQR êµ¬í•˜ê¸°\n",
    "target = df['var_6']\n",
    "\n",
    "q1 = target.quantile(0.25)\n",
    "q3 = target.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "print(q1, q3, iqr)\n",
    "\n",
    "# IQRì˜ 1.5ë°° ë²—ì–´ë‚œ ì´ìƒì¹˜ ìˆ«ì êµ¬í•˜ê¸°\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "cond = (target < lower) | (target > upper)\n",
    "\n",
    "answer = len(df[cond]['var_6'])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 19 (24ë…„ 8íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ëŒ€ë¥™ë³„ í‰ê·  ë§¥ì£¼ ì†Œë¹„ëŸ‰ì´ ë§ì€ ê³³ì„ ê³ ë¥´ê³ , í•´ë‹¹ ëŒ€ë¥™ì—ì„œ ë‹¤ì„¯ë²ˆì§¸ë¡œ ë§¥ì£¼ ì†Œë¹„ëŸ‰ì´ ë§ì€ ë‚˜ë¼ êµ¬í•˜ê¸°\n",
    "- ì •ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P240801.csv')\n",
    "# print(df.info())\n",
    "\n",
    "# ëŒ€ë¥™ë³„ í‰ê·  ë§¥ì£¼ ì†Œë¹„ëŸ‰ ê°€ì¥ ë§ì€ ê³³ êµ¬í•˜ê¸°\n",
    "new_df = df.groupby(by='continent')['beer_servings'].mean()\n",
    "new_df = new_df.sort_values(ascending=False)\n",
    "# print(new_df)\n",
    "\n",
    "continent = new_df.index[0]\n",
    "print(continent)   # Europe\n",
    "\n",
    "# í•´ë‹¹ ëŒ€ë¥™ì—ì„œ ë‹¤ì„¯ë²ˆì§¸ë¡œ ë§¥ì£¼ ì†Œë¹„ëŸ‰ì´ ë§ì€ ë‚˜ë¼ êµ¬í•˜ê¸°\n",
    "cond = df['continent'] == 'Europe'\n",
    "df_europe = df[cond]\n",
    "# print(df_europe)\n",
    "\n",
    "sorted_df_europe = df_europe.sort_values(by=\"beer_servings\", ascending=False).reset_index()   # ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "# print(sorted_df_europe.head(5))\n",
    "\n",
    "answer = sorted_df_europe.iloc[4]['beer_servings']   # ë§¥ì£¼ ì†Œë¹„ëŸ‰ ë‹¤ì„¯ë²ˆì§¸ë¡œ í° ë‚˜ë¼ì˜ ë§¥ì£¼ ì†Œë¹„ëŸ‰ êµ¬í•˜ê¸°\n",
    "print(answer)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 20 (24ë…„ 8íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê´€ê´‘ê° ë¹„ìœ¨ì´ ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ë‚˜ë¼ì˜ `ê´€ê´‘` ìˆ˜ë¥¼ `a`ë¼ê³  ì •ì˜í•˜ê³ , ê´€ê´‘ê° ìˆ˜ê°€ ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ë‚˜ë¼ì˜ `ê³µë¬´` ìˆ˜ë¥¼ `b`ë¼ê³  ì •ì˜í•œ í›„, a+bì˜ ê°’ êµ¬í•˜ê¸°\n",
    "- ê´€ê´‘ê° ë¹„ìœ¨ - ê´€ê´‘ ì…êµ­ ì¸ì› / (ê´€ê´‘ ì…êµ­ ì¸ì› + ê³µë¬´ ì…êµ­ ì¸ì›)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   êµ­ê°€  ê´€ê´‘ì…êµ­  ê³µë¬´ì…êµ­     ê´€ê´‘ê°ë¹„ìœ¨\n",
      "0  ì¤‘êµ­   120    60  0.666667\n",
      "1  í™ì½©    74    38  0.660714\n",
      "2  ë…ì¼    50    26  0.657895\n",
      "3  ë¯¸êµ­    60    90  0.400000\n",
      "4  ì¼ë³¸   100   165  0.377358\n",
      "74\n",
      "   êµ­ê°€  ê´€ê´‘ì…êµ­  ê³µë¬´ì…êµ­     ê´€ê´‘ê°ë¹„ìœ¨\n",
      "0  ì¤‘êµ­   120    60  0.666667\n",
      "1  ì¼ë³¸   100   165  0.377358\n",
      "2  í™ì½©    74    38  0.660714\n",
      "3  ë¯¸êµ­    60    90  0.400000\n",
      "4  ë…ì¼    50    26  0.657895\n",
      "165\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê°€ìƒì˜ ë°ì´í„°í”„ë ˆì„ ìƒì„± (ë°ì´í„°ì…‹ í™•ì¸ ë¶ˆê°€)\n",
    "data = {\n",
    "    'êµ­ê°€': ['í™ì½©', 'ë…ì¼', 'ì¼ë³¸', 'ì¤‘êµ­', 'ë¯¸êµ­'],\n",
    "    'ê´€ê´‘ì…êµ­': [74, 50, 100, 120, 60], \n",
    "    'ê³µë¬´ì…êµ­': [38, 26, 165, 60, 90],  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ê´€ê´‘ê° ë¹„ìœ¨ êµ¬í•˜ê¸°\n",
    "df['ê´€ê´‘ê°ë¹„ìœ¨'] = df['ê´€ê´‘ì…êµ­'] / (df['ê´€ê´‘ì…êµ­'] + df['ê³µë¬´ì…êµ­'])\n",
    "\n",
    "# ê´€ê´‘ê° ë¹„ìœ¨ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "ratio_sorted_df = df.sort_values(by=\"ê´€ê´‘ê°ë¹„ìœ¨\", ascending=False).reset_index(drop=True)\n",
    "print(ratio_sorted_df)\n",
    "\n",
    "# ê´€ê´‘ê° ë¹„ìœ¨ì´ ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ë‚˜ë¼ì˜ ê´€ê´‘ì…êµ­ ìˆ˜ êµ¬í•˜ê¸°\n",
    "a = ratio_sorted_df.loc[1, 'ê´€ê´‘ì…êµ­']\n",
    "print(a)\n",
    "\n",
    "# ê´€ê´‘ê° ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "tour_sorted_df = df.sort_values(by=\"ê´€ê´‘ì…êµ­\", ascending=False).reset_index(drop=True)\n",
    "print(tour_sorted_df)\n",
    "\n",
    "# ê´€ê´‘ê° ìˆ˜ê°€ ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ë‚˜ë¼ì˜ ê³µë¬´ì…êµ­ ìˆ˜ êµ¬í•˜ê¸°\n",
    "b = tour_sorted_df.loc[1, 'ê³µë¬´ì…êµ­']\n",
    "print(b)\n",
    "\n",
    "answer = a + b\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 21 (24ë…„ 8íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Co` ì»¬ëŸ¼ê³¼ `Nmch` ì»¬ëŸ¼ì˜ Min-Max Scalerë¥¼ ì‹œí–‰í•œ ë‹¤ìŒ, ìŠ¤ì¼€ì¼ë§ í›„ì˜ `Co` ì»¬ëŸ¼ì˜ í‘œì¤€í¸ì°¨ë¥¼ `a`ë¼ í•˜ê³ , `Nmch` ì»¬ëŸ¼ì˜ í‘œì¤€í¸ì°¨ë¥¼ `b`ë¡œ í•œ í›„, a-bì˜ ê°’ êµ¬í•˜ê¸°\n",
    "\n",
    "$$X_{\\text{norm}} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004724214242981084\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "data = {\n",
    "    'Co': np.random.uniform(50, 300, 100), \n",
    "    'Nmch': np.random.uniform(20, 100, 100)  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ìµœì†Œ-ìµœëŒ€ ì •ê·œí™” ì‹œí–‰í•˜ê¸°\n",
    "## (1) Co ì»¬ëŸ¼\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "df['Co_scaled'] = mms.fit_transform(df[['Co']])\n",
    "# print(df)\n",
    "\n",
    "## (2) NMch ì»¬ëŸ¼\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "df['Nmch_scaled'] = mms.fit_transform(df[['Nmch']])\n",
    "# print(df)\n",
    "\n",
    "# í‘œì¤€í¸ì°¨ êµ¬í•˜ê¸°\n",
    "a = df['Co_scaled'].std()\n",
    "b = df['Nmch_scaled'].std()\n",
    "\n",
    "# ì •ë‹µ êµ¬í•˜ê¸°\n",
    "## ğŸ’¡ ë¬¸ì œì—ì„œ 'a-b' ë¼ê³  ì‹ì„ ì •ì˜í•´ì£¼ì—ˆìœ¼ë¯€ë¡œ ë§ˆì´ë„ˆìŠ¤ë¥¼ ê¼­ ë¶™ì—¬ì•¼ í•œë‹¤. \n",
    "answer = a - b\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 22 (ì‹œí—˜ì¥ í™˜ê²½ ì²´í—˜ ì˜ˆì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì œê³µëœ ë°ì´í„°(`data/mtcars`)ì˜ `qsec` ì»¬ëŸ¼ì„ ìµœì†Œ-ìµœëŒ€ ì²™ë„(Min-Max Scale)ë¡œ ë³€í™˜í•œ í›„, 0.5ë³´ë‹¤ í° ê°’ì„ ê°€ì§€ëŠ” ë ˆì½”ë“œ ìˆ˜ êµ¬í•˜ê¸°\n",
    "- ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ë°©ë²• 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "# qsec ì»¬ëŸ¼ì„ ìµœì†Œ-ìµœëŒ€ ì²™ë„ë¡œ ë³€í™˜í•˜ê¸°\n",
    "# min_max = (x - min(x)) / (max(x) - min(x))\n",
    "def min_max(column):\n",
    "\tmin_value = np.min(df[column])\n",
    "\tmax_value = np.max(df[column])\n",
    "\t\n",
    "\tmms = (df[column] - min_value) / (max_value - min_value)\n",
    "\t\n",
    "\treturn mms\n",
    "\n",
    "mms_value = min_max('qsec')\n",
    "df['mms_value'] = mms_value   # ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€\n",
    "\n",
    "# 0.5ë³´ë‹¤ í° ê°’ì„ ê°€ì§€ëŠ” ë ˆì½”ë“œ ìˆ˜ êµ¬í•˜ê¸°\n",
    "cond = df['mms_value'] > 0.5\n",
    "answer = len(df[cond])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ë°©ë²• 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "# qsec ì»¬ëŸ¼ì„ ìµœì†Œ-ìµœëŒ€ ì²™ë„ë¡œ ë³€í™˜í•˜ê¸°\n",
    "mms = MinMaxScaler()\n",
    "df['qsec'] = mms.fit_transform(df[['qsec']])    # 2ì°¨ì› ë°ì´í„°ë¥¼ ì¸ìˆ˜ë¡œ ë„£ì–´ì¤€ë‹¤! âœ…\n",
    "\n",
    "# 0.5ë³´ë‹¤ í° ê°’ì„ ê°€ì§€ëŠ” ë ˆì½”ë“œ ìˆ˜ êµ¬í•˜ê¸°\n",
    "cond = df['qsec'] > 0.5\n",
    "answer = len(df[cond])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 23 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `diamonds` ë°ì´í„°\n",
    "- ìˆœì„œëŒ€ë¡œ 70%ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ë§Œë“¤ê³ , `price` ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 5ê°œ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ê¹Šì´ ë¹„ìœ¨(`depth`)ì˜ ì¤‘ì•™ê°’ì„ ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-1.csv')\n",
    "\n",
    "# ìˆœì„œëŒ€ë¡œ 70%ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ë§Œë“¤ê¸°\n",
    "nrows = int(len(df) * 0.7)\n",
    "train_df = df[:nrows]\n",
    "\n",
    "# price ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 5ê°œ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ê¹Šì´(depth) ë¹„ìœ¨ì˜ ì¤‘ì•™ê°’ì„ ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "sorted_trained_df = train_df.sort_values(by='price', ascending=False)\n",
    "top5 = sorted_trained_df.head(5)\n",
    "median_value = top5['depth'].median()   # ì¤‘ì•™ê°’\n",
    "\n",
    "answer = int(median_value)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 24 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `telco-customer-churn` ë°ì´í„°\n",
    "- `TotalCharges` í•­ëª©ì—ì„œ ê²°ì¸¡ê°’ì„ ì œê±°í•˜ê³  ì´ìƒê°’ì„ ì œì™¸í•œ í‰ê· ì„ ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "    - ì´ìƒê°’ì€ í‰ê· ì—ì„œ 1.5 í‘œì¤€í¸ì°¨ ì´ìƒì¸ ê°’ìœ¼ë¡œ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-2.csv')\n",
    "\n",
    "target = df['TotalCharges']\n",
    "\n",
    "# ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "target = pd.to_numeric(target, errors='coerce')   # ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê°’ì„ NaNìœ¼ë¡œ ì²˜ë¦¬ (astype('float')ë¥¼ ì‚¬ìš©í•  ê²½ìš° ê³µë°±(' ') ì²˜ë¦¬ ë¶ˆê°€)\n",
    "\n",
    "# TotalCharges í•­ëª©ì—ì„œ ê²°ì¸¡ê°’ ì œê±°í•˜ê¸°\n",
    "target = target.dropna()\n",
    "\n",
    "# TotalCharges í•­ëª©ì—ì„œ ì´ìƒê°’ ì œì™¸í•˜ê¸°\n",
    "mean_value = target.mean()\n",
    "std_value = target.std()\n",
    "\n",
    "lower = mean_value - 1.5 * std_value\n",
    "upper = mean_value + 1.5 * std_value\n",
    "\n",
    "cond = (target <= upper) & (target >= lower)\n",
    "\n",
    "answer = int(target[cond].mean())\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 25 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32ê°œ ìë™ì°¨ ëª¨ë¸ì˜ ë””ìì¸ê³¼ ì„±ëŠ¥ì„ ë¹„êµí•œ `mtcars` ë°ì´í„°\n",
    "- ìˆ˜ë™(`am=1`) ì¤‘ì—ì„œ ê°€ì¥ ë§ˆë ¥(`hp`)ì´ ì‘ì€ 5ê°œì˜ ë°ì´í„°ì˜ í‰ê·  ì—°ë¹„(`mpg`)ì™€ ìë™(`am=0`) ì¤‘ì—ì„œ ê°€ì¥ ë§ˆë ¥(`hp`)ì´ ì‘ì€ 5ê°œ ë°ì´í„°ì˜ í‰ê·  ì—°ë¹„(`mpg`)ì˜ ì°¨ì´ êµ¬í•˜ê¸°\n",
    "- ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-3.csv')\n",
    "\n",
    "# ìˆ˜ë™(am=1) ì¤‘ì—ì„œ ê°€ì¥ ë§ˆë ¥(hp)ì´ ì‘ì€ 5ê°œì˜ ë°ì´í„°ì˜ í‰ê·  ì—°ë¹„(mpg) êµ¬í•˜ê¸°\n",
    "cond1 = df['am'] == 1\n",
    "target1 = df[cond1].sort_values(by='hp', ascending=True).head(5)\n",
    "\n",
    "manual_mean_mpg = target1['mpg'].mean()\n",
    "\n",
    "# ìë™(am=0) ì¤‘ì—ì„œ ê°€ì¥ ë§ˆë ¥(hp)ì´ ì‘ì€ 5ê°œ ë°ì´í„°ì˜ í‰ê·  ì—°ë¹„(mpg) êµ¬í•˜ê¸°\n",
    "cond2 = df['am'] == 0\n",
    "target2 = df[cond2].sort_values(by='hp', ascending=True).head(5)\n",
    "\n",
    "auto_mean_mpg = target2['mpg'].mean()\n",
    "\n",
    "# ë‘ ê°’ì˜ ì°¨ì´ êµ¬í•˜ê¸°\n",
    "answer = round(np.abs(manual_mean_mpg - auto_mean_mpg), 1)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 26 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë‰´ìš•ì˜ ê³µê¸° ì˜¤ì—¼ë„ë¥¼ ì¸¡ì •í•œ `airquality` ë°ì´í„°\n",
    "- ë°ì´í„°ì˜ ìˆœì„œëŒ€ë¡œ 70%ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí•˜ê³ , `Ozone` í•­ëª©ì˜ ê²°ì¸¡ê°’ì„ í‰ê· ìœ¼ë¡œ ë³€ê²½í•œ í›„ ë³€ê²½ ì „, í›„ì˜ ì¤‘ì•™ê°’ ì°¨ì´ êµ¬í•˜ê¸°\n",
    "- `Ozone` í•­ëª©ì˜ ê²°ì¸¡ê°’ê³¼ ë³€ê²½ ì „, í›„ì˜ ì¤‘ì•™ê°’, ì¤‘ì•™ê°’ì˜ ì°¨ì´ëŠ” ëª¨ë‘ ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ë¡œ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M2-1.csv')\n",
    "\n",
    "# ë°ì´í„°ì˜ ìˆœì„œëŒ€ë¡œ 70%ì˜ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí•˜ê¸°\n",
    "nrows = int(len(df) * 0.7)\n",
    "train_df = df[:nrows]\n",
    "\n",
    "# Ozone í•­ëª©ì˜ ê²°ì¸¡ê°’ì„ í‰ê· ìœ¼ë¡œ ë³€ê²½í•œ í›„ ë³€ê²½ ì „, í›„ì˜ ì¤‘ì•™ê°’ ì°¨ì´ êµ¬í•˜ê¸°\n",
    "target = train_df['Ozone']\n",
    "\n",
    "median_value1 = round(target.median(), 1)\n",
    "\n",
    "mean_value = round(target.mean(), 1)\n",
    "target = target.fillna(mean_value)\n",
    "\n",
    "median_value2 = round(target.median(), 1)\n",
    "\n",
    "answer = round(np.abs(median_value1 - median_value2), 1)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 27 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `marvel` ë°ì´í„°\n",
    "- `HAIR`ì™€ `EYE`ê°€ ê²°ì¸¡ê°’ì´ ì•„ë‹ˆë‹¤.\n",
    "- `HAIR`ê°€ `White Hair`ì´ê³ , `EYE`ê°€ `Blue Eyes`ì¸ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí–ˆì„ ë•Œ, `APPEARANCES`ì—ì„œ ì´ìƒê°’ì„ ì œì™¸í•œ í‰ê·  êµ¬í•˜ê¸°\n",
    "    - ì´ìƒê°’ì€ í‰ê· ì—ì„œ 1.5ë°° í‘œì¤€í¸ì°¨ë¥¼ ë²—ì–´ë‚˜ëŠ” ê°’ìœ¼ë¡œ í•˜ê¸°\n",
    "- í‰ê· , í‘œì¤€í¸ì°¨ëŠ” ì†Œìˆ˜ ë‘˜ì§¸ ìë¦¬ë¡œ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M2-2.csv')\n",
    "\n",
    "# Hairê°€ White Hairì´ê³  Eyeê°€ Blue Eyesì¸ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì¶”ì¶œí•˜ê¸°\n",
    "cond = (df['HAIR'] == 'White Hair') & (df['EYE'] == 'Blue Eyes')\n",
    "train_df = df[cond]\n",
    "\n",
    "# APPEARANCESì—ì„œ ì´ìƒê°’ì„ ì œì™¸í•œ í‰ê·  êµ¬í•˜ê¸°\n",
    "target = train_df['APPEARANCES']\n",
    "\n",
    "mean_value = round(target.mean(), 2)\n",
    "std_value = round(target.std(), 2)\n",
    "\n",
    "lower = mean_value - 1.5 * std_value\n",
    "upper = mean_value + 1.5 * std_value\n",
    "\n",
    "cond = (target >= lower) & ( target <= upper)\n",
    "result = target[cond].mean()\n",
    "\n",
    "answer = round(result, 2)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 28 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Carseats` ë°ì´í„°\n",
    "- ë§¤ì¶œ(`Sales`)ì˜ ì´ìƒê°’ì„ ì œì™¸í•œ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì„ ì •í•  ë–„, `Age`ì˜ í‘œì¤€í¸ì°¨ êµ¬í•˜ê¸°\n",
    "    - ì´ìƒê°’ì€ í‰ê· ë³´ë‹¤ 1.5 í‘œì¤€í¸ì°¨ ë¯¸ë§Œì´ê±°ë‚˜ ì´ˆê³¼ì¸ ê°’ìœ¼ë¡œ ì„ ì •í•˜ê¸°\n",
    "- ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ë¡œ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M2-3.csv')\n",
    "\n",
    "# ë§¤ì¶œ(Sales)ì˜ ì´ìƒê°’ì„ ì œì™¸í•œ ë°ì´í„°ë¥¼ í›ˆë ¨ ë°ì´í„°ë¡œ ì„ ì •í•˜ê¸°\n",
    "target = df['Sales']\n",
    "mean_value = target.mean()\n",
    "std_value = target.std()\n",
    "\n",
    "lower = mean_value - 1.5 * std_value\n",
    "upper = mean_value + 1.5 * std_value\n",
    "\n",
    "cond = (target > lower) & (target < upper)\n",
    "\n",
    "train_data = df[cond]\n",
    "\n",
    "# Ageì˜ í‘œì¤€í¸ì°¨ êµ¬í•˜ê¸°\n",
    "result = train_data['Age'].std()\n",
    "answer = round(result, 2)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì°¸ê³ ë¡œ, ë‹¤ìŒê³¼ ê°™ì´ Z-Scoreë¥¼ ì´ìš©í•˜ì—¬ ì´ìƒê°’ì„ ì œì™¸í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "```py\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(df['ì»¬ëŸ¼ëª…'])\n",
    "target_df = df[abs(z_scores) <= 1.5]   # z-score ì ˆëŒ“ê°’ì´ 1.5 ì´í•˜ì¸ ë°ì´í„° ì„ íƒ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# ë°ì´í„° ì½ê¸°\n",
    "df = pd.read_csv('./datasets/M2-3.csv')\n",
    "\n",
    "# Sales ì—´ì˜ z-score ê³„ì‚°\n",
    "z_scores = zscore(df['Sales'])\n",
    "\n",
    "# ì´ìƒê°’ ì œê±° (z-scoreì˜ ì ˆëŒ€ê°’ì´ 1.5 ì´í•˜ì¸ ë°ì´í„° ì„ íƒ)\n",
    "train_data = df[abs(z_scores) <= 1.5]\n",
    "\n",
    "# Age ì—´ì˜ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "answer = round(train_data['Age'].std(), 2)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì œ2ìœ í˜•\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 1 (21ë…„ 2íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì—…ì—ì„œ ìƒì„±ëœ ì£¼ë¬¸ ë°ì´í„°\n",
    "- `P210204-01.csv` íŒŒì¼ì˜ ë°ì´í„°ë¡œ ì •ì‹œ ë„ì°© ê°€ëŠ¥ ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ê³ , `P210204-02.csv` íŒŒì¼ì— ëŒ€í•˜ì—¬ ì •ì‹œ ë„ì°© ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•œ í™•ë¥ ì„ ê¸°ë¡í•œ CSV ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966 359]\n",
      " [232 446]]\n",
      "0.7049425861208187\n",
      "0.7290566037735849\n",
      "0.8063439065108514\n",
      "0.7657550535077289\n",
      "0.6934368564590639\n",
      "[[0.40666667 0.59333333]\n",
      " [0.29666667 0.70333333]\n",
      " [0.63333333 0.36666667]\n",
      " ...\n",
      " [0.30333333 0.69666667]\n",
      " [0.23       0.77      ]\n",
      " [0.33333333 0.66666667]]\n",
      "         ID      pred\n",
      "0      8010  0.593333\n",
      "1      8011  0.703333\n",
      "2      8012  0.366667\n",
      "3      8013  0.430000\n",
      "4      8014  0.513333\n",
      "...     ...       ...\n",
      "2985  10995  0.740000\n",
      "2986  10996  0.666667\n",
      "2987  10997  0.696667\n",
      "2988  10998  0.770000\n",
      "2989  10999  0.666667\n",
      "\n",
      "[2990 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P210204-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P210204-02.csv')\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "## ì •ìˆ˜í˜• -> ë²”ì£¼í˜•\n",
    "df1['Reached.on.Time_Y.N'] = df1['Reached.on.Time_Y.N'].astype('category')\n",
    "\n",
    "## ê²°ì¸¡ì¹˜ê°€ ìˆì„ ê²½ìš°, fillnaë¥¼ ì´ìš©í•˜ì—¬ ì¤‘ì•™ê°’ ë˜ëŠ” 0ìœ¼ë¡œ ëŒ€ì¹˜\n",
    "## Objectì¸ ì»¬ëŸ¼ì´ ì—¬ëŸ¬ê°œ ìˆì„ ê²½ìš°, Label Encoderë¥¼ ì´ìš©í•´ì„œ ì „ë¶€ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸°\n",
    "\n",
    "## ë…ë¦½ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ êµ¬ë¶„\n",
    "x = df1.drop('Reached.on.Time_Y.N', axis=1)   # ë…ë¦½ë³€ìˆ˜\n",
    "y = df1['Reached.on.Time_Y.N']   # ì¢…ì†ë³€ìˆ˜\n",
    "\n",
    "## ì›-í•« ì¸ì½”ë”©\n",
    "x = x.drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ëª¨ë¸ë§ ë° ì˜ˆì¸¡\n",
    "## ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "## ëª¨ë¸ë§\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "## ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "\n",
    "## ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(recall_score(y_valid, pred))\n",
    "print(precision_score(y_valid, pred))\n",
    "print(f1_score(y_valid, pred))\n",
    "print(roc_auc_score(y_valid, pred))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "## ì›-í•« ì¸ì½”ë”©\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "## ì˜ˆì¸¡\n",
    "pred = md.predict_proba(x_test_encoded) \n",
    "print(pred)\n",
    "\n",
    "# CSVë¡œ ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'pred': pred[:, 1]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ğŸ’¡ ë‚˜ë§Œì˜ ë°©ì‹ìœ¼ë¡œ í’€ì–´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 1]\n",
      "[[966 328]\n",
      " [249 460]]\n",
      "0.7119321018472291\n",
      "0.7465224111282844\n",
      "0.7950617283950617\n",
      "0.7700278995615784\n",
      "0.6976617697390364\n",
      "[[0.35 0.65]\n",
      " [0.24 0.76]\n",
      " [0.54 0.46]\n",
      " ...\n",
      " [0.43 0.57]\n",
      " [0.3  0.7 ]\n",
      " [0.24 0.76]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P210204-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P210204-02.csv')\n",
    "\n",
    "# print(df1.info())\n",
    "# print(df2.info())\n",
    "\n",
    "# (1) ë°ì´í„° ì „ì²˜ë¦¬\n",
    "## ì •ìˆ˜í˜• -> ë²”ì£¼í˜•\n",
    "df1['Reached.on.Time_Y.N'] = df1['Reached.on.Time_Y.N'].astype('category')\n",
    "\n",
    "## ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ êµ¬ë¶„\n",
    "x = df1.drop('Reached.on.Time_Y.N', axis=1)\n",
    "y = df1['Reached.on.Time_Y.N']\n",
    "\n",
    "## ì›-í•« ì¸ì½”ë”© (í›ˆë ¨ìš© ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„°)\n",
    "x = x.drop('ID', axis=1)\n",
    "x_test = df2.copy().drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)         # í›ˆë ¨ìš© ë°ì´í„°\n",
    "x_test_encoded = pd.get_dummies(x_test)  # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° (df2)\n",
    "\n",
    "# (2) ëª¨ë¸ë§ ë° ì˜ˆì¸¡\n",
    "## ë°ì´í„° ë¶„í• \n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "## ëª¨ë¸ë§\n",
    "md = RandomForestClassifier()\n",
    "md.fit(x_tr, y_tr)   # í›ˆë ¨ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ë§\n",
    "\n",
    "## ì˜ˆì¸¡\n",
    "pred = md.predict(x_val)   # ê²€ì¦ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "print(pred)\n",
    "\n",
    "## ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(y_val, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_val, pred))\n",
    "print(recall_score(y_val, pred))\n",
    "print(precision_score(y_val, pred))\n",
    "print(f1_score(y_val, pred))\n",
    "print(roc_auc_score(y_val, pred))\n",
    "\n",
    "## í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡\n",
    "pred = md.predict_proba(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# (3) CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'pred': pred[:, 1]   # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì˜ ê°’ë§Œ (ì •ì‹œ ë„ì°©í–ˆì„ ê²½ìš°)\n",
    "})\n",
    "result.to_csv('./outputs/20241112_Q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 2 (21ë…„ 3íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê³ ê°ì˜ ì˜ˆì•½ í˜„í™©ì„ ë‚˜íƒ€ë‚¸ ë°ì´í„°\n",
    "- `P210304-01.csv` íŒŒì¼ì— ì €ì¥ëœ í•™ìŠµ ë°ì´í„°ë¡œ ì—¬í–‰ ë³´í—˜ ê°€ì… ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ê³ , `P210304-02.csv` íŒŒì¼ì— ì €ì¥ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì—¬í–‰ ë³´í—˜ íŒ¨í‚¤ì§€ ê°€ì… ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²°ê³¼ ì˜ˆì‹œ íŒŒì¼ê³¼ ë™ì¼í•œ í˜•íƒœì˜ CSV íŒŒì¼ë¡œ ìƒì„±í•˜ì—¬ ì œì¶œí•˜ê¸°\n",
    "\n",
    "|index|y_pred|\n",
    "|:-:|:-:|\n",
    "|1|0.538132|\n",
    "|2|0.759230|\n",
    "|...|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83  46]\n",
      " [ 31 213]]\n",
      "0.7935656836461126\n",
      "0.6434108527131783\n",
      "0.7280701754385965\n",
      "0.6831275720164609\n",
      "0.7581808361926548\n",
      "[[1.26666667e-01 8.73333333e-01]\n",
      " [1.46666667e-01 8.53333333e-01]\n",
      " [8.51666667e-01 1.48333333e-01]\n",
      " [6.82777778e-01 3.17222222e-01]\n",
      " [9.66111111e-01 3.38888889e-02]\n",
      " [5.85531746e-01 4.14468254e-01]\n",
      " [1.40000000e-01 8.60000000e-01]\n",
      " [8.32222222e-01 1.67777778e-01]\n",
      " [5.16087302e-01 4.83912698e-01]\n",
      " [2.19825397e-01 7.80174603e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.89166667e-01 1.08333333e-02]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [8.00000000e-01 2.00000000e-01]\n",
      " [6.77235450e-01 3.22764550e-01]\n",
      " [9.98888889e-01 1.11111111e-03]\n",
      " [9.34884921e-01 6.51150794e-02]\n",
      " [1.60000000e-01 8.40000000e-01]\n",
      " [5.88833333e-01 4.11166667e-01]\n",
      " [9.95000000e-01 5.00000000e-03]\n",
      " [8.04666667e-01 1.95333333e-01]\n",
      " [9.81595238e-01 1.84047619e-02]\n",
      " [6.66666667e-03 9.93333333e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [8.50957672e-01 1.49042328e-01]\n",
      " [8.91255291e-01 1.08744709e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [8.62388889e-01 1.37611111e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.32000000e-01 1.68000000e-01]\n",
      " [1.33333333e-02 9.86666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.34884921e-01 6.51150794e-02]\n",
      " [4.00000000e-02 9.60000000e-01]\n",
      " [3.71935786e-01 6.28064214e-01]\n",
      " [8.52619048e-01 1.47380952e-01]\n",
      " [1.20000000e-01 8.80000000e-01]\n",
      " [1.05500000e-01 8.94500000e-01]\n",
      " [9.73333333e-01 2.66666667e-02]\n",
      " [9.87222222e-01 1.27777778e-02]\n",
      " [9.34884921e-01 6.51150794e-02]\n",
      " [9.04000000e-01 9.60000000e-02]\n",
      " [2.16666667e-01 7.83333333e-01]\n",
      " [4.46666667e-01 5.53333333e-01]\n",
      " [7.84166667e-01 2.15833333e-01]\n",
      " [5.42055556e-01 4.57944444e-01]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [4.41666667e-01 5.58333333e-01]\n",
      " [5.02348846e-01 4.97651154e-01]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [8.91177249e-01 1.08822751e-01]\n",
      " [9.56288360e-01 4.37116402e-02]\n",
      " [5.98333333e-01 4.01666667e-01]\n",
      " [2.26666667e-01 7.73333333e-01]\n",
      " [7.82888889e-01 2.17111111e-01]\n",
      " [8.47222222e-03 9.91527778e-01]\n",
      " [5.56907407e-01 4.43092593e-01]\n",
      " [4.96861241e-01 5.03138759e-01]\n",
      " [8.77388889e-01 1.22611111e-01]\n",
      " [1.74424603e-01 8.25575397e-01]\n",
      " [1.05500000e-01 8.94500000e-01]\n",
      " [1.66666667e-02 9.83333333e-01]\n",
      " [9.03333333e-01 9.66666667e-02]\n",
      " [4.33333333e-02 9.56666667e-01]\n",
      " [1.20000000e-01 8.80000000e-01]\n",
      " [7.67722222e-01 2.32277778e-01]\n",
      " [9.56055556e-01 4.39444444e-02]\n",
      " [9.68333333e-01 3.16666667e-02]\n",
      " [6.67925926e-01 3.32074074e-01]\n",
      " [9.38349206e-01 6.16507937e-02]\n",
      " [9.80888889e-01 1.91111111e-02]\n",
      " [7.15222222e-01 2.84777778e-01]\n",
      " [8.96230159e-01 1.03769841e-01]\n",
      " [1.25000000e-01 8.75000000e-01]\n",
      " [1.79166667e-02 9.82083333e-01]\n",
      " [1.86666667e-01 8.13333333e-01]\n",
      " [9.26666667e-01 7.33333333e-02]\n",
      " [6.71491582e-01 3.28508418e-01]\n",
      " [7.46666667e-01 2.53333333e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.35945767e-01 6.40542328e-02]\n",
      " [3.23333333e-01 6.76666667e-01]\n",
      " [6.76666667e-01 3.23333333e-01]\n",
      " [5.59071429e-01 4.40928571e-01]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [9.85194195e-01 1.48058053e-02]\n",
      " [9.69777778e-01 3.02222222e-02]\n",
      " [8.71388889e-01 1.28611111e-01]\n",
      " [9.63333333e-01 3.66666667e-02]\n",
      " [8.11984127e-02 9.18801587e-01]\n",
      " [9.44857143e-01 5.51428571e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.95916667e-01 4.08333333e-03]\n",
      " [6.00000000e-02 9.40000000e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [6.80613757e-01 3.19386243e-01]\n",
      " [8.76666667e-01 1.23333333e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [3.60000000e-01 6.40000000e-01]\n",
      " [9.95916667e-01 4.08333333e-03]\n",
      " [3.00000000e-02 9.70000000e-01]\n",
      " [9.50000000e-01 5.00000000e-02]\n",
      " [3.33333333e-02 9.66666667e-01]\n",
      " [9.33111111e-01 6.68888889e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.62388889e-01 1.37611111e-01]\n",
      " [3.20000000e-01 6.80000000e-01]\n",
      " [9.77936508e-01 2.20634921e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.57833333e-01 4.21666667e-02]\n",
      " [9.93194444e-01 6.80555556e-03]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [9.60166667e-01 3.98333333e-02]\n",
      " [9.03428571e-01 9.65714286e-02]\n",
      " [9.40000000e-01 6.00000000e-02]\n",
      " [7.70000000e-01 2.30000000e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [9.42182540e-01 5.78174603e-02]\n",
      " [8.56666667e-01 1.43333333e-01]\n",
      " [1.73333333e-01 8.26666667e-01]\n",
      " [6.66666667e-03 9.93333333e-01]\n",
      " [8.50000000e-01 1.50000000e-01]\n",
      " [7.69723184e-01 2.30276816e-01]\n",
      " [7.83555556e-01 2.16444444e-01]\n",
      " [6.30473545e-01 3.69526455e-01]\n",
      " [5.83333333e-01 4.16666667e-01]\n",
      " [8.91596504e-01 1.08403496e-01]\n",
      " [6.82777778e-01 3.17222222e-01]\n",
      " [9.54611111e-01 4.53888889e-02]\n",
      " [8.81666667e-01 1.18333333e-01]\n",
      " [7.46666667e-01 2.53333333e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [3.64329365e-01 6.35670635e-01]\n",
      " [9.93000000e-01 7.00000000e-03]\n",
      " [8.95358919e-01 1.04641081e-01]\n",
      " [9.35436508e-01 6.45634921e-02]\n",
      " [9.44825397e-01 5.51746032e-02]\n",
      " [6.78500000e-01 3.21500000e-01]\n",
      " [8.81666667e-01 1.18333333e-01]\n",
      " [5.06166667e-01 4.93833333e-01]\n",
      " [7.67722222e-01 2.32277778e-01]\n",
      " [8.34444444e-01 1.65555556e-01]\n",
      " [9.84103175e-01 1.58968254e-02]\n",
      " [1.20000000e-01 8.80000000e-01]\n",
      " [2.33333333e-02 9.76666667e-01]\n",
      " [8.70000000e-01 1.30000000e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [9.65222222e-01 3.47777778e-02]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [7.15222222e-01 2.84777778e-01]\n",
      " [9.40984127e-01 5.90158730e-02]\n",
      " [8.94952381e-01 1.05047619e-01]\n",
      " [8.34444444e-01 1.65555556e-01]\n",
      " [7.33904762e-01 2.66095238e-01]\n",
      " [7.51666667e-01 2.48333333e-01]\n",
      " [8.52785714e-01 1.47214286e-01]\n",
      " [9.43019841e-01 5.69801587e-02]\n",
      " [1.13333333e-01 8.86666667e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [2.88000000e-01 7.12000000e-01]\n",
      " [5.62150794e-01 4.37849206e-01]\n",
      " [8.00000000e-03 9.92000000e-01]\n",
      " [9.76666667e-01 2.33333333e-02]\n",
      " [8.95358919e-01 1.04641081e-01]\n",
      " [9.93666667e-01 6.33333333e-03]\n",
      " [4.66666667e-01 5.33333333e-01]\n",
      " [9.62222222e-01 3.77777778e-02]\n",
      " [9.76777778e-01 2.32222222e-02]\n",
      " [9.99166667e-01 8.33333333e-04]\n",
      " [9.63333333e-01 3.66666667e-02]\n",
      " [7.65595238e-01 2.34404762e-01]\n",
      " [8.91839947e-01 1.08160053e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [2.03333333e-01 7.96666667e-01]\n",
      " [9.49472222e-01 5.05277778e-02]\n",
      " [7.88888889e-01 2.11111111e-01]\n",
      " [5.62150794e-01 4.37849206e-01]\n",
      " [1.30000000e-01 8.70000000e-01]\n",
      " [5.66666667e-02 9.43333333e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [2.63986772e-01 7.36013228e-01]\n",
      " [3.86388889e-01 6.13611111e-01]\n",
      " [1.37777778e-01 8.62222222e-01]\n",
      " [9.59166667e-01 4.08333333e-02]\n",
      " [9.93000000e-01 7.00000000e-03]\n",
      " [7.27777778e-02 9.27222222e-01]\n",
      " [9.93666667e-01 6.33333333e-03]\n",
      " [4.87500000e-01 5.12500000e-01]\n",
      " [9.60166667e-01 3.98333333e-02]\n",
      " [9.59583333e-01 4.04166667e-02]\n",
      " [9.36666667e-01 6.33333333e-02]\n",
      " [1.73333333e-01 8.26666667e-01]\n",
      " [7.80000000e-01 2.20000000e-01]\n",
      " [3.68333333e-01 6.31666667e-01]\n",
      " [9.93333333e-01 6.66666667e-03]\n",
      " [6.66611111e-01 3.33388889e-01]\n",
      " [6.71491582e-01 3.28508418e-01]\n",
      " [2.40000000e-01 7.60000000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.00000000e-01 3.00000000e-01]\n",
      " [5.36666667e-01 4.63333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.27500000e-01 7.25000000e-02]\n",
      " [1.47769841e-01 8.52230159e-01]\n",
      " [8.80420635e-01 1.19579365e-01]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [2.63986772e-01 7.36013228e-01]\n",
      " [8.75833333e-01 1.24166667e-01]\n",
      " [8.62388889e-01 1.37611111e-01]\n",
      " [3.21666667e-01 6.78333333e-01]\n",
      " [7.75138889e-01 2.24861111e-01]\n",
      " [1.66666667e-03 9.98333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.40000000e-01 8.60000000e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.46880952e-01 1.53119048e-01]\n",
      " [9.85555556e-01 1.44444444e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.30473545e-01 3.69526455e-01]\n",
      " [8.75833333e-01 1.24166667e-01]\n",
      " [9.90000000e-01 1.00000000e-02]\n",
      " [3.02112434e-01 6.97887566e-01]\n",
      " [9.87777778e-01 1.22222222e-02]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [5.10000000e-01 4.90000000e-01]\n",
      " [1.06666667e-01 8.93333333e-01]\n",
      " [1.79166667e-02 9.82083333e-01]\n",
      " [9.08888889e-01 9.11111111e-02]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [2.63986772e-01 7.36013228e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [9.98888889e-01 1.11111111e-03]\n",
      " [2.18833333e-01 7.81166667e-01]\n",
      " [9.83222222e-01 1.67777778e-02]\n",
      " [5.29111111e-01 4.70888889e-01]\n",
      " [6.56666667e-01 3.43333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [5.02361111e-01 4.97638889e-01]\n",
      " [2.66111111e-02 9.73388889e-01]\n",
      " [1.99166667e-01 8.00833333e-01]\n",
      " [9.59166667e-01 4.08333333e-02]\n",
      " [6.76666667e-01 3.23333333e-01]\n",
      " [8.58095238e-01 1.41904762e-01]\n",
      " [9.57444444e-01 4.25555556e-02]\n",
      " [8.91177249e-01 1.08822751e-01]\n",
      " [8.91177249e-01 1.08822751e-01]\n",
      " [9.79166667e-01 2.08333333e-02]\n",
      " [4.70000000e-01 5.30000000e-01]\n",
      " [7.65833333e-01 2.34166667e-01]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [1.86666667e-01 8.13333333e-01]\n",
      " [7.80000000e-01 2.20000000e-01]\n",
      " [8.47777778e-01 1.52222222e-01]\n",
      " [9.93194444e-01 6.80555556e-03]\n",
      " [9.99666667e-01 3.33333333e-04]\n",
      " [8.03388889e-01 1.96611111e-01]\n",
      " [2.24166667e-01 7.75833333e-01]\n",
      " [1.13333333e-01 8.86666667e-01]\n",
      " [8.97500000e-01 1.02500000e-01]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [3.40000000e-01 6.60000000e-01]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [6.80000000e-01 3.20000000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.33888889e-01 2.66111111e-01]\n",
      " [8.21111111e-01 1.78888889e-01]\n",
      " [9.35436508e-01 6.45634921e-02]\n",
      " [9.83333333e-01 1.66666667e-02]\n",
      " [6.60000000e-01 3.40000000e-01]\n",
      " [6.80555556e-01 3.19444444e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.54872146e-01 3.45127854e-01]\n",
      " [8.80420635e-01 1.19579365e-01]\n",
      " [5.02361111e-01 4.97638889e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.10000000e-01 9.00000000e-02]\n",
      " [9.86388889e-01 1.36111111e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [7.33333333e-02 9.26666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.78000000e-01 3.22000000e-01]\n",
      " [9.46666667e-01 5.33333333e-02]\n",
      " [5.00000000e-02 9.50000000e-01]\n",
      " [9.66666667e-01 3.33333333e-02]\n",
      " [7.89055556e-01 2.10944444e-01]\n",
      " [3.10126984e-01 6.89873016e-01]\n",
      " [6.35817460e-01 3.64182540e-01]\n",
      " [8.42333333e-01 1.57666667e-01]\n",
      " [7.23944444e-01 2.76055556e-01]\n",
      " [9.41690476e-01 5.83095238e-02]\n",
      " [9.33111111e-01 6.68888889e-02]\n",
      " [7.98928571e-01 2.01071429e-01]\n",
      " [6.87190476e-01 3.12809524e-01]\n",
      " [3.26613757e-01 6.73386243e-01]\n",
      " [9.98571429e-01 1.42857143e-03]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.66666667e-03 9.93333333e-01]\n",
      " [9.03567460e-01 9.64325397e-02]\n",
      " [5.16087302e-01 4.83912698e-01]\n",
      " [7.01293651e-01 2.98706349e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.16666667e-01 8.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.93333333e-01 6.66666667e-03]\n",
      " [3.66666667e-02 9.63333333e-01]\n",
      " [8.52785714e-01 1.47214286e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.80555556e-01 3.19444444e-01]\n",
      " [8.95358919e-01 1.04641081e-01]\n",
      " [5.97716931e-01 4.02283069e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.41166667e-01 5.88333333e-02]\n",
      " [6.92940476e-01 3.07059524e-01]\n",
      " [3.68333333e-01 6.31666667e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.50000000e-01 3.50000000e-01]\n",
      " [3.11666667e-01 6.88333333e-01]\n",
      " [8.88333333e-01 1.11666667e-01]\n",
      " [8.66666667e-01 1.33333333e-01]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [2.92777056e-01 7.07222944e-01]\n",
      " [9.98750000e-01 1.25000000e-03]\n",
      " [8.66666667e-02 9.13333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.23333333e-01 8.76666667e-01]\n",
      " [3.70000000e-01 6.30000000e-01]\n",
      " [9.34888889e-01 6.51111111e-02]\n",
      " [8.98492063e-01 1.01507937e-01]\n",
      " [8.76666667e-01 1.23333333e-01]\n",
      " [9.95916667e-01 4.08333333e-03]\n",
      " [6.50000000e-01 3.50000000e-01]\n",
      " [5.00000000e-02 9.50000000e-01]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [8.80420635e-01 1.19579365e-01]\n",
      " [9.76777778e-01 2.32222222e-02]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.49015873e-01 1.50984127e-01]\n",
      " [6.49333333e-01 3.50666667e-01]\n",
      " [9.20685185e-01 7.93148148e-02]\n",
      " [6.64789683e-01 3.35210317e-01]\n",
      " [8.32500000e-01 1.67500000e-01]\n",
      " [6.64789683e-01 3.35210317e-01]\n",
      " [6.78000000e-01 3.22000000e-01]\n",
      " [6.67925926e-01 3.32074074e-01]\n",
      " [9.83055556e-01 1.69444444e-02]\n",
      " [9.99666667e-01 3.33333333e-04]\n",
      " [9.67222222e-01 3.27777778e-02]\n",
      " [9.50000000e-01 5.00000000e-02]\n",
      " [9.40000000e-01 6.00000000e-02]\n",
      " [9.54055556e-01 4.59444444e-02]\n",
      " [9.99666667e-01 3.33333333e-04]\n",
      " [2.03333333e-01 7.96666667e-01]\n",
      " [9.85555556e-01 1.44444444e-02]\n",
      " [5.58611111e-01 4.41388889e-01]\n",
      " [7.39870370e-01 2.60129630e-01]\n",
      " [2.00000000e-02 9.80000000e-01]\n",
      " [9.87416667e-01 1.25833333e-02]\n",
      " [8.65880952e-01 1.34119048e-01]\n",
      " [3.15238095e-01 6.84761905e-01]\n",
      " [7.62666667e-01 2.37333333e-01]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [6.41678571e-01 3.58321429e-01]\n",
      " [9.58416667e-01 4.15833333e-02]\n",
      " [9.33111111e-01 6.68888889e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.76666667e-01 2.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.16666667e-02 9.38333333e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [2.33333333e-02 9.76666667e-01]\n",
      " [9.60166667e-01 3.98333333e-02]\n",
      " [9.92777778e-01 7.22222222e-03]\n",
      " [9.62222222e-01 3.77777778e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [8.47222222e-03 9.91527778e-01]\n",
      " [9.43333333e-01 5.66666667e-02]\n",
      " [9.99166667e-01 8.33333333e-04]\n",
      " [9.01388889e-01 9.86111111e-02]\n",
      " [8.97388889e-01 1.02611111e-01]\n",
      " [9.91714286e-01 8.28571429e-03]\n",
      " [1.86666667e-01 8.13333333e-01]\n",
      " [6.77235450e-01 3.22764550e-01]\n",
      " [3.85555556e-01 6.14444444e-01]\n",
      " [2.34777778e-01 7.65222222e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.03000000e-01 9.70000000e-02]\n",
      " [8.72166667e-01 1.27833333e-01]\n",
      " [3.22000000e-01 6.78000000e-01]\n",
      " [9.04000000e-01 9.60000000e-02]\n",
      " [6.51357143e-01 3.48642857e-01]\n",
      " [9.93194444e-01 6.80555556e-03]\n",
      " [7.83333333e-01 2.16666667e-01]\n",
      " [4.96861241e-01 5.03138759e-01]\n",
      " [9.83888889e-01 1.61111111e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [5.73055556e-01 4.26944444e-01]\n",
      " [9.41333333e-01 5.86666667e-02]\n",
      " [9.31666667e-01 6.83333333e-02]\n",
      " [8.62579365e-01 1.37420635e-01]\n",
      " [8.32000000e-01 1.68000000e-01]\n",
      " [9.42648148e-01 5.73518519e-02]\n",
      " [7.13333333e-01 2.86666667e-01]\n",
      " [9.66666667e-01 3.33333333e-02]\n",
      " [9.41333333e-01 5.86666667e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.76666667e-01 2.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.97777778e-01 2.22222222e-03]\n",
      " [9.71187831e-01 2.88121693e-02]\n",
      " [3.06666667e-01 6.93333333e-01]\n",
      " [5.50579365e-01 4.49420635e-01]\n",
      " [9.65277778e-01 3.47222222e-02]\n",
      " [4.67619048e-01 5.32380952e-01]\n",
      " [9.98750000e-01 1.25000000e-03]\n",
      " [9.66666667e-01 3.33333333e-02]\n",
      " [9.99333333e-01 6.66666667e-04]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.56055556e-01 4.39444444e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [5.50579365e-01 4.49420635e-01]\n",
      " [9.12484127e-01 8.75158730e-02]\n",
      " [7.93333333e-01 2.06666667e-01]\n",
      " [9.93333333e-01 6.66666667e-03]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.54989418e-01 2.45010582e-01]\n",
      " [2.33333333e-02 9.76666667e-01]\n",
      " [9.85000000e-01 1.50000000e-02]\n",
      " [9.81944444e-01 1.80555556e-02]\n",
      " [2.93333333e-01 7.06666667e-01]\n",
      " [9.06666667e-01 9.33333333e-02]\n",
      " [6.84166667e-01 3.15833333e-01]\n",
      " [3.46666667e-01 6.53333333e-01]\n",
      " [5.16666667e-01 4.83333333e-01]\n",
      " [1.09166667e-01 8.90833333e-01]\n",
      " [4.76666667e-01 5.23333333e-01]\n",
      " [3.66666667e-02 9.63333333e-01]\n",
      " [9.45000000e-01 5.50000000e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [5.56907407e-01 4.43092593e-01]\n",
      " [6.56099206e-01 3.43900794e-01]\n",
      " [5.05714286e-01 4.94285714e-01]\n",
      " [8.47222222e-03 9.91527778e-01]\n",
      " [7.60000000e-01 2.40000000e-01]\n",
      " [6.74388889e-01 3.25611111e-01]\n",
      " [8.46666667e-01 1.53333333e-01]\n",
      " [1.12500000e-01 8.87500000e-01]\n",
      " [9.32777778e-02 9.06722222e-01]\n",
      " [6.69583333e-01 3.30416667e-01]\n",
      " [6.70997354e-01 3.29002646e-01]\n",
      " [6.00000000e-02 9.40000000e-01]\n",
      " [1.31190476e-01 8.68809524e-01]\n",
      " [4.24285714e-01 5.75714286e-01]\n",
      " [7.52161376e-01 2.47838624e-01]\n",
      " [7.86432540e-01 2.13567460e-01]\n",
      " [7.15222222e-01 2.84777778e-01]\n",
      " [2.13333333e-01 7.86666667e-01]\n",
      " [2.03333333e-01 7.96666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.83888889e-01 1.61111111e-02]\n",
      " [3.40000000e-01 6.60000000e-01]\n",
      " [5.23988095e-01 4.76011905e-01]\n",
      " [5.32083333e-01 4.67916667e-01]\n",
      " [5.59071429e-01 4.40928571e-01]\n",
      " [7.25000000e-01 2.75000000e-01]\n",
      " [9.43333333e-01 5.66666667e-02]\n",
      " [9.80555556e-01 1.94444444e-02]\n",
      " [1.57777778e-01 8.42222222e-01]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [8.96888889e-01 1.03111111e-01]\n",
      " [3.30000000e-01 6.70000000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [8.63333333e-01 1.36666667e-01]\n",
      " [6.66666667e-02 9.33333333e-01]\n",
      " [6.25059524e-01 3.74940476e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [5.58611111e-01 4.41388889e-01]\n",
      " [5.48686508e-01 4.51313492e-01]\n",
      " [6.83003968e-01 3.16996032e-01]\n",
      " [9.77936508e-01 2.20634921e-02]\n",
      " [1.93333333e-01 8.06666667e-01]\n",
      " [1.56666667e-01 8.43333333e-01]\n",
      " [9.98888889e-01 1.11111111e-03]\n",
      " [2.93333333e-01 7.06666667e-01]\n",
      " [5.50579365e-01 4.49420635e-01]]\n",
      "     index    y_pred\n",
      "0     1491  0.873333\n",
      "1     1492  0.853333\n",
      "2     1493  0.148333\n",
      "3     1494  0.317222\n",
      "4     1495  0.033889\n",
      "..     ...       ...\n",
      "491   1982  0.806667\n",
      "492   1983  0.843333\n",
      "493   1984  0.001111\n",
      "494   1985  0.706667\n",
      "495   1986  0.449421\n",
      "\n",
      "[496 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P210304-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P210304-02.csv')\n",
    "\n",
    "# ì¢…ì† ë³€ìˆ˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ë§Œë“¤ê¸°\n",
    "df1['TravelInsurance'] = df1['TravelInsurance'].astype('category')\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ êµ¬ë³„\n",
    "x = df1.drop('TravelInsurance', axis=1)    # ë…ë¦½ ë³€ìˆ˜\n",
    "y = df1['TravelInsurance']   # ì¢…ì† ë³€ìˆ˜\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x = x.drop('X', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(recall_score(y_valid, pred))\n",
    "print(precision_score(y_valid, pred))\n",
    "print(f1_score(y_valid, pred))\n",
    "print(roc_auc_score(y_valid, pred))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('X', axis=1)\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "# í‰ê°€\n",
    "pred = md.predict_proba(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'index': df2['X'],\n",
    "    'y_pred': pred[:, 1]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 3 (22ë…„ 4íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ìë™ì°¨ ë³´í—˜ íšŒì‚¬ëŠ” ìƒˆë¡œìš´ ì „ëµì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•´ ê³ ê°ì„ 4ê°€ì§€ë¡œ ë¶„ë¥˜(A, B, C, D)ë¡œ ì„¸ë¶„í™” í•˜ì˜€ë‹¤.\n",
    "- ê¸°ì¡´ ê³ ê°ì— ëŒ€í•œ ë¶„ë¥˜(`P220404-01.csv`)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ê·œ ê³ ê°(`P220404-02.csv`)ì´ ì–´ë–¤ ë¶„ë¥˜ì— ì†í• ì§€ ì˜ˆì¸¡í•˜ì—¬ ì œì¶œí•˜ê¸°\n",
    "\n",
    "```text\n",
    "í‰ê°€ : Macro F1-score\n",
    "ì˜ˆì¸¡í•  ê°’ : Segmentation\n",
    "ì œì¶œë˜ëŠ” íŒŒì¼ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í–‰ì˜ ìˆ˜ì™€ ê°™ì•„ì•¼ í•¨.\n",
    "```\n",
    "\n",
    "\n",
    "|ID|pred|\n",
    "|:-:|:-:|\n",
    "|1|A|\n",
    "|2|B|\n",
    "|3|C|\n",
    "|...|...|\n",
    "|1500|D|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'D' 'A' ... 'B' 'A' 'A']\n",
      "[[152 111  46  73]\n",
      " [ 91 120 113  42]\n",
      " [ 58 113 222  25]\n",
      " [ 87  56  48 310]]\n",
      "0.47106737801769927\n",
      "['B' 'C' 'C' ... 'B' 'C' 'D']\n",
      "          ID pred\n",
      "0     458989    B\n",
      "1     458994    C\n",
      "2     459000    C\n",
      "3     459003    C\n",
      "4     459005    A\n",
      "...      ...  ...\n",
      "2149  467950    A\n",
      "2150  467954    D\n",
      "2151  467958    B\n",
      "2152  467961    C\n",
      "2153  467968    D\n",
      "\n",
      "[2154 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P220404-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P220404-02.csv')\n",
    "\n",
    "# ìë£Œí˜• ë³€í™˜\n",
    "df1['Segmentation'] = df1['Segmentation'].astype('category')   # object -> category\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë‚˜ëˆ„ê¸°\n",
    "x = df1.drop('Segmentation', axis=1)   # ë…ë¦½ ë³€ìˆ˜\n",
    "y = df1['Segmentation']   # ì¢…ì† ë³€ìˆ˜\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x = x.drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(y_valid, pred, labels=['A', 'B', 'C', 'D'])\n",
    "print(cm)\n",
    "\n",
    "print(f1_score(y_valid, pred, average='macro'))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)   # ì›-í•« ì¸ì½”ë”©\n",
    "\n",
    "pred = md.predict(x_test_encoded)    # ì˜ˆì¸¡\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'pred': pred[:]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 4 (22ë…„ 5íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì£¼ì–´ì§„ í›ˆë ¨ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì¤‘ê³  ì°¨ëŸ‰ ê°€ê²©(`price`)ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨í˜•ì„ ë§Œë“¤ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì¤‘ê³  ì°¨ëŸ‰ ê°€ê²©ì„ ì˜ˆì¸¡í•˜ì—¬ ì œì¶œí•˜ê¸°\n",
    "\n",
    "```text\n",
    "í‰ê°€ : RMSE\n",
    "ì œì¶œë˜ëŠ” íŒŒì¼ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í–‰ì˜ ìˆ˜ì™€ ê°™ì•„ì•¼ í•¨.\n",
    "```\n",
    "\n",
    "|pred|\n",
    "|:-:|\n",
    "|1230|\n",
    "|2562|\n",
    "|...|\n",
    "|3761|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651.631597158918\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P220504-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P220504-02.csv')\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë‚˜ëˆ„ê¸°\n",
    "x = df1.drop('price', axis=1)  # ë…ë¦½ ë³€ìˆ˜\n",
    "y = df1['price']\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x_encoded = pd.get_dummies(x)\n",
    "x_test_encoded = pd.get_dummies(df2)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ ë° í‰ê°€\n",
    "pred_valid = md.predict(x_valid)\n",
    "rmse = root_mean_squared_error(y_valid, pred_valid)   # scikit-learn 1.4 ë²„ì „ ì´ìƒì—ì„œ ì‚¬ìš© ê°€ëŠ¥\n",
    "print(rmse)\n",
    "\n",
    "# ê³µí†µ í”¼ì³ ì²˜ë¦¬\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)   # ë¹ˆ ì»¬ëŸ¼ì˜ ê°’ì€ 0ìœ¼ë¡œ ë„£ê¸°\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "pred_test = md.predict(x_test_encoded)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred_test\n",
    "})\n",
    "result.to_csv('./outputs/20240615_Q4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 5 (23ë…„ 6íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ëª¨ë°”ì¼ ë°ì´í„° ì„¸íŠ¸\n",
    "- ë¶„ë¥˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ `price_range` ê°’ì„ ì˜ˆì¸¡í•˜ë ¤ê³  í•œë‹¤.\n",
    "- `P230604-01.csv` íŒŒì¼ì˜ í•™ìŠµ ë°ì´í„°ë¡œ ëª¨ë¸ì„ ìƒì„±í•˜ê³  `P230604-02.csv` íŒŒì¼ì˜ í‰ê°€ ë°ì´í„°ë¡œ í‰ê°€í•˜ì—¬ ì˜ˆì¸¡í•˜ê¸°\n",
    "\n",
    "```text\n",
    "Macro F1 Scoreë¡œ í‰ê°€\n",
    "feature engineering, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë“±ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ê³¼ëŒ€ì í•©ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.\n",
    "```\n",
    "\n",
    "|pred|\n",
    "|:-:|\n",
    "|2|\n",
    "|3|\n",
    "|0|\n",
    "|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 0 2 0 2 2 1 1 2 0 3 1 2 0 3 3 0 0 3 0 0 0 2 3 2 1 0 2 0 2 2 3 1\n",
      " 2 1 0 2 1 2 3 2 1 2 3 2 2 0 0 0 3 2 1 3 1 3 3 0 0 1 3 0 0 0 0 2 3 2 3 2 0\n",
      " 3 2 2 0 0 3 1 2 1 1 0 1 3 0 1 3 3 1 1 1 2 2 2 2 0 1 2 0 0 1 2 0 1 1 1 1 0\n",
      " 1 1 3 1 0 1 3 1 0 3 2 0 0 2 1 0 2 2 1 1 0 3 0 1 1 2 2 3 1 1 0 2 1 2 0 0 1\n",
      " 2 0 2 0 1 2 2 3 1 2 3 3 1 0 1 0 1 2 1 0 3 0 1 1 0 1 2 1 0 3 2 1 2 2 1 0 1\n",
      " 2 2 3 0 3 1 3 0 0 0 2 1 1 1 3 3 2 1 1 0 2 1 2 0 1 0 3 3 3 0 0 1 2 1 1 2 1\n",
      " 2 0 3 2 3 3 0 1 3 1 0 3 1 0 0 1 2 3 1 1 1 3 0 2 2 3 0 1 2 3 3 0 3 1 0 2 0\n",
      " 3 0 3 0 0 0 1 3 1 1 0 1 3 1 0 2 1 2 2 1 3 3 1 1 0 2 1 3 1 3 3 3 2 2 1 1 1\n",
      " 2 3 1 2 2 3 2 3 1 3 0 2 0 0 2 2 0 1 3 3 3 2 3 3 3 3 2 1 3 0 2 1 1 0 1 3 1\n",
      " 3 3 3 0 3 1 2 2 0 0 2 3 1 3 3 0 0 2 1 0 0 2 0 0 2 2 0 0 1 1 3 2 0 2 1 2 2\n",
      " 1 3 2 2 2 3 3 3 1 1 0 3 3 2 2 3 1 3 2 3 3 0 3 3 3 3 0 0 1 1 2 3 2 0 1 2 3\n",
      " 1 1 1 0 3 1 1 0 0 1 3 3 3 0 0 0 0 0 3 2 3 0 3 3 2 0 0 1 2 1 2 2 0 2 3 0 2\n",
      " 3 2 2 3 2 2 3 2 2 1 3 3 2 3 3 1 2 0 0 1 2 0 0 3 3 1 3 1 2 1 1 0 1 2 0 2 0\n",
      " 2 1 3 0 3 3 2 0 0 3 0 2 2 3 0 1 1 0 2]\n",
      "[[119   3   0   0]\n",
      " [  7 110  11   0]\n",
      " [  0  15 108   7]\n",
      " [  0   0   5 115]]\n",
      "0.9049648358206841\n",
      "[3 3 2 3 1 3 3 1 3 0 3 3 0 0 2 0 2 1 3 2 1 3 1 1 3 0 2 0 2 0 2 0 3 0 0 1 3\n",
      " 1 2 1 1 2 0 0 0 1 0 3 1 2 1 0 3 0 3 1 3 1 1 3 3 2 0 1 1 1 1 3 1 2 1 2 2 3\n",
      " 3 0 2 0 2 3 0 3 3 0 3 0 3 1 3 0 1 1 2 1 2 1 0 2 1 2 1 0 0 3 1 2 0 1 2 3 3\n",
      " 3 1 3 3 3 3 1 3 0 0 3 2 1 2 0 3 2 3 1 0 1 1 1 3 1 1 0 3 2 1 3 1 2 2 3 3 2\n",
      " 2 3 2 3 0 0 2 2 3 3 3 3 2 2 3 3 3 3 1 0 3 0 0 0 1 1 0 1 0 0 1 2 0 0 0 1 2\n",
      " 2 2 1 0 0 0 1 0 3 1 0 2 2 2 3 1 2 3 3 3 1 2 0 0 0 1 2 1 2 3 3 0 2 0 3 2 2\n",
      " 3 0 0 1 0 3 0 1 0 2 2 1 3 0 3 0 3 1 2 0 0 2 1 3 3 3 1 1 3 0 0 2 3 3 1 3 1\n",
      " 1 3 2 1 2 3 3 3 1 0 1 2 3 1 1 3 2 0 3 0 1 2 0 0 3 2 3 3 2 1 3 3 2 3 2 2 1\n",
      " 1 0 2 3 1 0 0 3 0 3 0 1 2 0 2 3 1 3 2 2 1 2 0 0 0 1 3 2 0 0 0 3 2 0 3 3 1\n",
      " 2 3 2 3 1 3 3 2 2 3 3 3 0 3 0 3 1 3 1 3 3 0 1 1 3 1 3 2 3 0 0 0 0 2 0 0 1\n",
      " 1 1 2 3 2 0 1 0 0 3 2 0 3 1 2 2 1 2 3 1 1 2 2 1 2 0 1 1 0 3 2 0 0 1 0 0 1\n",
      " 1 0 0 0 2 2 3 2 3 0 3 0 3 0 1 1 1 1 0 3 2 3 3 1 3 1 3 1 3 2 1 2 2 1 1 0 0\n",
      " 0 1 2 1 0 3 2 0 2 3 0 0 2 1 1 1 2 2 3 0 3 0 2 3 3 3 0 2 0 1 3 0 1 1 0 0 1\n",
      " 1 1 3 3 3 2 3 1 1 2 3 3 3 1 0 2 2 2 2 1 0 2 3 0 0 0 3 1 1 2 2 2 0 3 0 2 2\n",
      " 0 3 0 2 3 0 1 1 3 3 1 1 2 3 2 0 2 1 2 0 3 3 1 3 2 2 3 0 1 2 3 1 3 2 3 1 0\n",
      " 1 0 3 1 0 3 2 3 2 0 3 3 3 2 3 3 1 2 0 2 3 3 0 0 1 1 2 2 2 0 0 2 2 3 2 0 2\n",
      " 1 3 3 0 1 3 1 2 1 0 0 0 2 1 0 1 1 2 2 0 2 2 1 0 3 0 0 3 2 0 0 0 0 0 3 0 3\n",
      " 1 3 2 1 3 2 0 1 1 3 2 3 1 0 3 0 2 0 2 0 0 1 1 1 2 1 3 1 3 2 2 1 3 2 0 1 2\n",
      " 0 3 3 0 2 1 1 2 0 3 2 0 3 2 3 0 0 3 0 1 2 3 2 2 2 2 1 2 3 0 1 1 1 2 1 0 0\n",
      " 1 0 0 3 0 1 1 0 1 1 0 3 0 3 2 3 0 0 1 2 2 1 0 1 1 0 1 1 0 0 3 3 0 3 1 2 3\n",
      " 0 1 0 2 2 0 3 1 0 3 0 1 0 3 3 3 2 3 0 3 2 0 1 0 3 3 2 0 2 1 3 1 0 3 2 0 3\n",
      " 1 2 1 1 1 3 1 1 1 2 0 0 1 2 0 2 0 0 0 0 3 3 3 3 0 1 2 1 1 0 0 2 1 0 2 0 2\n",
      " 2 2 1 2 0 2 1 3 0 0 3 1 3 0 0 2 3 3 1 3 2 1 0 0 2 3 1 3 0 0 0 2 2 1 3 0 3\n",
      " 2 1 2 3 3 0 1 1 2 1 2 2 0 1 3 1 1 3 1 2 3 1 1 1 2 3 3 0 2 3 0 2 3 2 2 2 3\n",
      " 2 0 1 2 0 2 1 1 2 2 2 1 2 0 0 1 3 1 0 1 2 3 1 0 0 3 2 2 3 0 3 3 2 1 3 0 1\n",
      " 3 1 2 1 2 2 2 0 3 0 2 3 0 3 1 3 3 1 0 2 3 1 0 1 1 2 1 3 0 2 2 0 2 3 2 3 0\n",
      " 2 1 1 2 2 3 3 0 2 1 2 1 3 0 1 3 0 1 0 0 3 2 2 0 0 0 0 3 2 3 3 0 0 2 1 0 2\n",
      " 2]\n",
      "     pred\n",
      "0       3\n",
      "1       3\n",
      "2       2\n",
      "3       3\n",
      "4       1\n",
      "..    ...\n",
      "995     2\n",
      "996     1\n",
      "997     0\n",
      "998     2\n",
      "999     2\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P230604-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P230604-02.csv')\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬\n",
    "x = df1.drop('price_range', axis=1)\n",
    "y = df1['price_range']\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(y_valid, pred)\n",
    "print(cm)\n",
    "\n",
    "print(f1_score(y_valid, pred, average='macro'))  # Macro F1 Score\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('id', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)  # ì›-í•« ì¸ì½”ë”©\n",
    "\n",
    "pred = md.predict(x_test_encoded)   # ì˜ˆì¸¡\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 6 (23ë…„ 7íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì œì£¼ ì—…ì¢…ë³„ ì¹´ë“œ ì´ìš© ì •ë³´ ë°ì´í„°\n",
    "- ì¢…ì† ë³€ìˆ˜ : ì´ìš©ê¸ˆì•¡\n",
    "- í‰ê°€ ì§€í‘œ : RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.75328097e+06 9.88669042e+08 1.00307781e+09 3.46754489e+09\n",
      " 3.50359333e+05 2.47077573e+08 1.53050946e+06 2.02290687e+08\n",
      " 7.63515613e+06 4.14832637e+08 4.60308856e+07 8.03569754e+07\n",
      " 4.99999046e+08 1.08230370e+09 3.52369359e+09 4.28967358e+08\n",
      " 4.68753858e+08 2.45895745e+08 8.80266625e+08 7.94647044e+08\n",
      " 3.60605573e+08 6.66128622e+07 4.63779523e+08 4.53275136e+08\n",
      " 1.19942736e+08 1.32362557e+09 5.64756849e+07 7.38848675e+07\n",
      " 2.30393298e+08 7.38583838e+08 2.31588662e+08 2.81260002e+09\n",
      " 6.30175678e+07 4.54360437e+09 2.03543795e+08 4.22146487e+08\n",
      " 8.38410195e+09 2.29815648e+08 4.59020265e+08 1.58205648e+07\n",
      " 2.52170893e+07 2.12914215e+06 5.99647593e+06 2.84414939e+08\n",
      " 6.51855607e+07 5.22517574e+07 1.44985075e+06 2.07479952e+07\n",
      " 2.14828777e+06 2.55824658e+08 4.45256727e+08 3.82658173e+06\n",
      " 3.38981478e+08 5.61439118e+08 1.17094138e+09 1.83028991e+09\n",
      " 1.84607987e+08 3.70020675e+07 5.09377733e+05 2.57278429e+07\n",
      " 7.51352267e+05 1.31278954e+08 3.39226081e+08 4.49827141e+08\n",
      " 5.71685338e+07 1.03679745e+08 7.83088420e+06 2.42212811e+06\n",
      " 2.24704021e+08 5.55729851e+06 1.24833777e+09 3.55048302e+08\n",
      " 4.00108081e+07 4.91525791e+08 5.04156377e+07 1.14819927e+06\n",
      " 1.90065648e+07 9.00207447e+07 3.15116819e+06 8.31767783e+08\n",
      " 3.97118030e+06 6.94110580e+08 1.13913617e+06 9.54923006e+07\n",
      " 5.57375386e+08 3.42618888e+06 9.97042466e+07 3.34088482e+08\n",
      " 1.16337040e+08 1.36530691e+08 7.87395199e+07 1.93456524e+08\n",
      " 2.74389133e+06 8.70234070e+06 1.49829758e+08 2.85673745e+09\n",
      " 7.28303364e+06 3.36544208e+06 2.42874334e+08 1.46340538e+07\n",
      " 2.08858754e+08 3.32845857e+08 6.48842983e+07 3.03813932e+08\n",
      " 3.32069009e+08 1.56259385e+08 1.26036993e+08 1.75044450e+08\n",
      " 7.19270633e+08 1.02915968e+07 5.12599681e+07 4.36186100e+05\n",
      " 5.72908675e+08 5.31289751e+08 1.26259483e+07 4.15478675e+08\n",
      " 2.93605913e+06 2.39597095e+09 1.06948576e+09 3.90286278e+08\n",
      " 3.35987587e+09 6.56076437e+06 9.23519254e+09 5.00823926e+09\n",
      " 1.52381358e+08 1.06505464e+09 1.43834340e+08 2.71365600e+09\n",
      " 4.09596584e+09 9.01282800e+05 3.98505484e+07 5.33408628e+08\n",
      " 1.01291476e+10 1.75457629e+09 5.21591249e+09 1.93874440e+08\n",
      " 9.69794780e+07 2.70560684e+09 3.62995591e+08 3.30236322e+09\n",
      " 1.06316417e+08 2.76450870e+06 4.38149507e+05 4.14788124e+07\n",
      " 4.69788017e+06 3.67339144e+07 4.25649428e+08 3.48183007e+08\n",
      " 3.84322743e+08 1.09364245e+09 4.36159560e+09 3.44111393e+08\n",
      " 1.43980724e+08 3.42070358e+08 1.48020460e+09 3.60364613e+08\n",
      " 4.80629591e+09 1.25094248e+09 7.88713646e+07 6.16872313e+08\n",
      " 1.14075765e+09 1.60236675e+08 1.22403894e+09 4.68418353e+08\n",
      " 4.75809472e+08 9.91257054e+06 4.09660552e+08 2.33867300e+06\n",
      " 9.36647508e+08 2.27124500e+05 3.69660833e+05 5.08878969e+08\n",
      " 1.06824177e+07 6.21798488e+09 3.13767954e+08 1.22319638e+07\n",
      " 1.88706588e+09 6.12264295e+08 5.73791769e+07 2.66788770e+08\n",
      " 1.83341912e+09 2.42536493e+08 5.66435777e+07 3.54740106e+08\n",
      " 1.94805307e+08 8.33003500e+05 6.48866479e+07 3.86794933e+06\n",
      " 4.59759923e+08 1.65792604e+06 1.27206291e+09 6.71887392e+08\n",
      " 5.15509635e+08 7.18234453e+06 1.49320995e+06 1.02883826e+08\n",
      " 1.72438294e+08 5.72089249e+08 8.75676053e+07 6.46057148e+09\n",
      " 4.95907475e+06 7.56220087e+07 1.62551943e+07 5.89436091e+08\n",
      " 5.83907893e+08 3.64674950e+08 1.28335402e+08 4.82095465e+07\n",
      " 4.64395180e+08 4.44470826e+08 5.72333700e+05 3.60199000e+05\n",
      " 5.57335430e+08 1.38260160e+09 3.31457601e+09 6.31138202e+06\n",
      " 1.33332443e+08 2.14015741e+08 6.20715433e+05 4.22096823e+08\n",
      " 1.78445488e+08 2.76329255e+06 1.20953347e+08 4.77075037e+09\n",
      " 9.82216654e+08 1.68104809e+08 1.73172948e+09 3.08614996e+09\n",
      " 1.30924587e+09 1.62075018e+09 4.09726233e+05 4.67323133e+06\n",
      " 1.08208738e+07 1.96591982e+06 5.14605574e+09 4.57846900e+05\n",
      " 2.89778914e+08 1.20091754e+09 9.77735626e+08 1.01673104e+09\n",
      " 1.65222895e+09 1.35965830e+06 3.16303999e+06 1.16147282e+09\n",
      " 1.11180359e+09 3.37330362e+07 4.96868217e+07 2.33753891e+06\n",
      " 5.48467995e+08 9.96493498e+08 6.08536102e+07 4.14052776e+08\n",
      " 4.00325801e+06 9.82135839e+08 6.71828031e+07 9.54073773e+08\n",
      " 1.86382057e+08 5.64634558e+06 4.55788075e+06 6.44372315e+08\n",
      " 1.52262604e+08 3.42942220e+08 1.77476583e+09 2.13205525e+08\n",
      " 3.64828663e+08 3.49482721e+09 3.36402694e+08 3.03670083e+09\n",
      " 9.26876896e+08 8.09708307e+06 3.26848456e+09 8.91258891e+08\n",
      " 5.53276779e+07 2.71480313e+06 8.10643600e+05 4.30804220e+09\n",
      " 4.77444539e+07 2.01706459e+08 2.10104612e+09 4.27199185e+08\n",
      " 6.04613569e+08 3.31249267e+05 1.03588868e+08 2.14209360e+07\n",
      " 2.34523397e+08 4.27314578e+08 7.70795724e+08 4.58154636e+08\n",
      " 5.86199673e+08 1.46782459e+09 1.75667611e+09 9.28034868e+06\n",
      " 4.36720316e+06 4.28284772e+09 1.55724319e+09 3.31684034e+09\n",
      " 9.15074177e+07 6.07935116e+08 1.51200620e+09 7.46162506e+08\n",
      " 2.97635573e+07 1.22555619e+08 4.41705134e+08 3.71803262e+07\n",
      " 4.21475718e+08 4.25507250e+06 1.90229297e+06 4.19993310e+06\n",
      " 9.13594765e+08 1.16157945e+09 6.71121316e+08 4.40781208e+08\n",
      " 4.98549389e+09 1.79432740e+07 1.58916287e+09 1.50223951e+08\n",
      " 1.34106646e+08 8.83942484e+08 1.58314036e+09 9.83937906e+09\n",
      " 7.93980983e+09 4.13762794e+09 1.58766349e+07 4.86458042e+08\n",
      " 5.52328805e+08 9.95598608e+07 2.12305430e+06 4.59563769e+08\n",
      " 5.61347553e+08 4.82134809e+08 5.62209301e+09 1.57927570e+09\n",
      " 4.46923422e+09 3.19877423e+08 3.35271598e+06 2.93167930e+09\n",
      " 4.52006636e+08 7.14230473e+08 1.27200506e+09 4.19845463e+08\n",
      " 4.34336770e+08 3.65176645e+08 8.76886940e+05 3.24390893e+08\n",
      " 9.92668759e+07 1.55137795e+08 1.83257012e+08 2.15889416e+09\n",
      " 1.10986628e+08 5.93334017e+07 3.63785479e+08 1.15864563e+08\n",
      " 4.30144107e+08 1.32531229e+08 1.64236119e+09 2.81561210e+08\n",
      " 6.32799736e+09 1.42235612e+07 2.12806489e+09 4.76437415e+08\n",
      " 8.07936286e+08 3.24309458e+09 5.89375665e+08 7.96278052e+07\n",
      " 3.53489047e+08 4.97676833e+05 4.12904452e+09 4.37279138e+08\n",
      " 2.21669833e+08 1.30801409e+08 5.30813113e+09 3.76844123e+09\n",
      " 3.74024100e+06 9.94590795e+09 4.98411824e+07 1.66944265e+07\n",
      " 2.74085676e+08 1.30834966e+08 2.83727222e+09 1.83567813e+08\n",
      " 4.18986007e+08 3.89385418e+08 9.93428915e+07 8.34138814e+08\n",
      " 3.07438933e+05 8.36829046e+08 9.74816408e+08 9.54775658e+07\n",
      " 5.23320913e+08 8.09037326e+08 1.60649651e+09 1.04923012e+09\n",
      " 8.57465730e+09 7.82073357e+09 3.37899089e+08 2.76951019e+08\n",
      " 4.78110167e+05 2.63679474e+08 3.53539006e+07 4.54281426e+08\n",
      " 9.16177418e+06 4.10234284e+08 1.12144838e+09 4.68899660e+06\n",
      " 5.21060967e+05 7.97262119e+08 1.39008626e+06 1.88386516e+09\n",
      " 8.88762422e+07 4.77444764e+08 9.22392274e+08 7.03345718e+08\n",
      " 2.63164340e+09 4.98788420e+09 6.30283234e+07 1.23468700e+06\n",
      " 6.17546673e+05 2.98711803e+08 5.30643507e+09 5.29093743e+08\n",
      " 6.96365731e+08 1.54494976e+09 2.83395838e+07 5.23719622e+08\n",
      " 1.65344960e+09 3.63017094e+08 1.65318210e+09 3.52956764e+08\n",
      " 7.38943633e+05 4.63337750e+08 9.71627862e+08 1.86562659e+09\n",
      " 6.12535855e+07 9.97800855e+08 9.55807708e+09 9.63567594e+07\n",
      " 2.04405619e+09 1.63221394e+09 1.00524203e+06 2.42947860e+08\n",
      " 9.29369132e+06 1.59183994e+09 5.08313579e+09 1.73452533e+09\n",
      " 1.49984447e+08 2.76400375e+08 1.00741304e+08 2.55666032e+08\n",
      " 5.05117859e+07 5.04827065e+09 5.28139324e+07 4.46079536e+08\n",
      " 7.56834996e+07 4.04452930e+06 1.09817443e+09 1.49323362e+09\n",
      " 4.56040151e+08 3.50803682e+07 1.95717815e+08 3.98631258e+07\n",
      " 8.39666937e+08 1.87926949e+06 3.48656503e+09 3.59289016e+08\n",
      " 5.84388013e+05 4.62942355e+08 7.59119388e+08 8.73444837e+07\n",
      " 3.49863557e+08 9.85496659e+06 9.09086856e+09 3.42510586e+08\n",
      " 6.59524422e+09 4.06482230e+07 2.55260693e+08 3.40806318e+09\n",
      " 1.25127940e+09 9.53921332e+07 4.11734904e+08 2.77182157e+08\n",
      " 3.78029133e+08 3.48173084e+08 2.70118707e+08 2.96124608e+07\n",
      " 4.71070016e+07 1.01070716e+08 7.29171110e+07 1.92432168e+08\n",
      " 3.19885569e+08 1.58486195e+09 1.05215082e+09 1.80926170e+09\n",
      " 9.10351143e+06 1.75579780e+08 2.30001261e+08 3.66573567e+05\n",
      " 4.46627497e+07 9.35842012e+09 4.64582171e+08 1.53210448e+08\n",
      " 7.73582145e+07 5.91724467e+05 5.90128603e+07 1.48061110e+08\n",
      " 2.21134457e+08 9.87526882e+07 7.58739621e+07 1.60255142e+08\n",
      " 7.41529300e+05 2.70291486e+08 4.09426397e+08 5.06208102e+08\n",
      " 1.74127475e+09 1.98888947e+07 1.06419972e+09 4.95154547e+09\n",
      " 8.77163547e+05 4.26151147e+08 2.93618067e+05 3.71171155e+08\n",
      " 4.14244702e+09 1.94554306e+07 5.48087328e+09 1.12999209e+07\n",
      " 5.15658509e+08 3.47706678e+08 1.11990306e+07 4.33853931e+08\n",
      " 7.12995861e+08 8.89511985e+07 1.91192804e+07 3.69896600e+05\n",
      " 1.70350654e+09 2.54759618e+08 6.19962758e+08 5.16297667e+05\n",
      " 1.01634111e+09 3.80807933e+05 2.99713112e+07 3.52475501e+08\n",
      " 4.79426520e+08 3.44014991e+09 5.37407020e+05 4.45000315e+08\n",
      " 9.49937563e+08 1.04386739e+09 4.37649103e+08 1.34127720e+09\n",
      " 1.49853249e+08 2.62387692e+08 1.10087917e+09 3.61624842e+07\n",
      " 8.09879318e+07 1.00342734e+07 3.04010881e+08 2.95047504e+06\n",
      " 2.27769874e+07 2.98149651e+09 4.25080475e+08 1.25653292e+08\n",
      " 1.00465500e+06 4.68594580e+08]\n",
      "171673450.02128342\n",
      "[6.03154368e+09 4.06901901e+07 2.43867567e+06 ... 5.50099992e+09\n",
      " 9.76408876e+08 6.69997977e+08]\n",
      "           ID         price\n",
      "0     ID_2575  6.031544e+09\n",
      "1     ID_6637  4.069019e+07\n",
      "2     ID_5704  2.438676e+06\n",
      "3     ID_3606  1.516398e+06\n",
      "4     ID_6443  6.364775e+05\n",
      "...       ...           ...\n",
      "5015  ID_4523  4.680746e+08\n",
      "5016  ID_3483  1.051279e+08\n",
      "5017   ID_453  5.501000e+09\n",
      "5018   ID_998  9.764089e+08\n",
      "5019  ID_3237  6.699980e+08\n",
      "\n",
      "[5020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P230704-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P230704-02.csv')\n",
    "\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬\n",
    "x = df1.drop('ì´ìš©ê¸ˆì•¡', axis=1)\n",
    "y = df1['ì´ìš©ê¸ˆì•¡']\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x = x.drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "result = root_mean_squared_error(y_valid, pred)   # RMSE\n",
    "print(result)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "pred = md.predict(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'price': pred,\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>ê²°ì •ë‚˜ë¬´(Decision Tree)ê³„ì—´ì˜ ëª¨ë¸(ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë“±)ì€ <b>ë²”ì£¼í˜• ë°ì´í„°(Object)</b> ë¥¼ ë¼ë²¨ ì¸ì½”ë”©(Label Encoding)í•˜ë©´ ëœë‹¤. </p>\n",
    "    <p>ê·¸ë¦¬ê³  ë³€ìˆ˜ ìŠ¤ì¼€ì¼ ë³€í™˜ì„ í•˜ì§€ ì•Šì•„ë„ ëœë‹¤.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit   color  weight  fruit_encoded  color_encoded\n",
      "0   apple     red     1.2              0              1\n",
      "1  banana  yellow     2.5              1              2\n",
      "2   apple   green     1.3              0              0\n",
      "3  banana  yellow     2.4              1              2\n",
      "4  cherry     red     1.0              2              1\n",
      "5  cherry     red     1.2              2              1\n",
      "6   apple   green     1.1              0              0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "data = {\n",
    "    'fruit': ['apple', 'banana', 'apple', 'banana', 'cherry', 'cherry', 'apple'],\n",
    "    'color': ['red', 'yellow', 'green', 'yellow', 'red', 'red', 'green'],\n",
    "    'weight': [1.2, 2.5, 1.3, 2.4, 1.0, 1.2, 1.1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# LabelEncoder ê°ì²´ ìƒì„±\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fruit ì»¬ëŸ¼ì— LabelEncoder ì ìš©\n",
    "df['fruit_encoded'] = le.fit_transform(df['fruit'])\n",
    "\n",
    "# color ì»¬ëŸ¼ì— LabelEncoder ì ìš©\n",
    "df['color_encoded'] = le.fit_transform(df['color'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>ë¼ë²¨ ì¸ì½”ë”(Label Encoder)</b>ëŠ” ìˆœì„œí˜• ë°ì´í„°, íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸(Decision Tree, Random Forest, XGBoost ë“±), ë²”ì£¼ì˜ ê°œìˆ˜ê°€ ë§ê³  í¬ì†Œ í–‰ë ¬ì„ í”¼í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ë‹¤..</p>\n",
    "    <p><b>ì›í•« ì¸ì½”ë”(OneHot Encoder)</b>ëŠ” ìˆœì„œê°€ ì—†ëŠ” ë°ì´í„°, ì„ í˜• ëª¨ë¸(Logistic Regression, SVM ë“±), ì‹ ê²½ë§ ëª¨ë¸, ë²”ì£¼ì˜ ê°œìˆ˜ê°€ ì ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ë‹¤.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 7 (24ë…„ 8íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì¢…ì† ë³€ìˆ˜ : ì§€í•˜ì² ì—­ ì¸ì›ìˆ˜\n",
    "- í‰ê°€ì§€í‘œ : MAE(Mean Absolute Error)\n",
    "    - ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ì ˆëŒ€ ì˜¤ì°¨ì˜ í‰ê·  ê³„ì‚°\n",
    "        - $MAE = \\frac{1}{n} \\sum^{n}_{i=1} |y_i - \\hat{y_i}|$\n",
    "    - ê°’ì´ ì‘ì„ìˆ˜ë¡ ëª¨ë¸ ì„±ëŠ¥ì´ ì¢‹ë‹¤. (Error ì´ë¯€ë¡œ)\n",
    "    - íŠ¹ì§•\n",
    "        - ì§ê´€ì  í•´ì„ ê°€ëŠ¥\n",
    "        - ëª¨ë¸ì˜ ì´ìƒê°’ì— ë¯¼ê°í•˜ì§€ ì•ŠìŒ. (ì ˆëŒ“ê°’ ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p>ì¢…ì† ë³€ìˆ˜ê°€ ì¸ì›ìˆ˜ì´ë¯€ë¡œ íšŒê·€ ë¬¸ì œì˜€ê³ , ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤ì´ ìˆì–´ì„œ ì›-í•« ì¸ì½”ë”©ì„ ì‚¬ìš©í•œë‹¤. (MAE 104 ì •ë„) </p>\n",
    "    <p><code>name</code> ì»¬ëŸ¼ì„ ëº„ ê²½ìš°, <code>x_test</code> ê°œìˆ˜ê°€ ë§ì§€ ì•Šì•„ì„œ í¬í•¨ì‹œì¼œì„œ í•´ì•¼ í•œë‹¤. </p>\n",
    "    <p>ì°¸ê³  ì‚¬ì´íŠ¸ : <a href=\"https://data-fox.tistory.com/41\">Blog Post</a></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 8)\n",
      "(300, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           900 non-null    object \n",
      " 1   day_of_week    900 non-null    object \n",
      " 2   month          900 non-null    int64  \n",
      " 3   station_name   895 non-null    object \n",
      " 4   visibility     892 non-null    float64\n",
      " 5   precipitation  900 non-null    float64\n",
      " 6   temperature    900 non-null    float64\n",
      " 7   num_people     900 non-null    int64  \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 56.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           300 non-null    object \n",
      " 1   day_of_week    300 non-null    object \n",
      " 2   month          300 non-null    int64  \n",
      " 3   station_name   300 non-null    object \n",
      " 4   visibility     300 non-null    float64\n",
      " 5   precipitation  300 non-null    float64\n",
      " 6   temperature    300 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 16.5+ KB\n",
      "None\n",
      "            month  visibility  precipitation  temperature    num_people\n",
      "count  900.000000  892.000000     900.000000   900.000000    900.000000\n",
      "mean     6.122222    9.996512       9.339334    15.070645  12556.747778\n",
      "std      3.314202    2.039593       6.721645     9.914046   1827.065461\n",
      "min      1.000000    3.223144       0.008814   -17.394377   7261.000000\n",
      "25%      3.000000    8.627064       4.002631     8.513877  11314.500000\n",
      "50%      6.000000   10.043633       8.004760    14.994892  12558.000000\n",
      "75%      9.000000   11.427402      13.151872    21.865623  13766.000000\n",
      "max     12.000000   16.509295      37.604911    51.577018  18186.000000\n",
      "            month  visibility  precipitation  temperature\n",
      "count  300.000000  300.000000     300.000000   300.000000\n",
      "mean     6.486667   10.191748       9.098002    16.307271\n",
      "std      2.834892    2.032578       6.845629    10.172719\n",
      "min      2.000000    4.818908       0.030805   -11.267863\n",
      "25%      4.000000    8.598862       3.660717    10.510916\n",
      "50%      6.500000   10.301550       7.895151    16.573051\n",
      "75%      9.000000   11.575936      12.958960    23.227468\n",
      "max     11.000000   16.991756      29.344086    40.625277\n",
      "date             0\n",
      "day_of_week      0\n",
      "month            0\n",
      "station_name     5\n",
      "visibility       8\n",
      "precipitation    0\n",
      "temperature      0\n",
      "num_people       0\n",
      "dtype: int64\n",
      "date             0\n",
      "day_of_week      0\n",
      "month            0\n",
      "station_name     0\n",
      "visibility       0\n",
      "precipitation    0\n",
      "temperature      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Columns: 916 entries, month to station_name_Sillim Station\n",
      "dtypes: bool(912), float64(3), int64(1)\n",
      "memory usage: 829.8 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Columns: 916 entries, month to station_name_Sillim Station\n",
      "dtypes: bool(290), float64(3), int64(623)\n",
      "memory usage: 1.5 MB\n",
      "None\n",
      "(720, 916)\n",
      "(180, 916)\n",
      "(720,)\n",
      "(180,)\n",
      "[14232.57 13978.17 11011.84 12321.08 10767.14 11109.88 16614.31 14371.92\n",
      " 12598.59 13217.6  13909.38 12702.59 11140.38 11872.71 15622.69 16024.54\n",
      " 14873.63 13681.16 13741.79 13177.29 13009.42 12824.77 11313.05 13090.75\n",
      " 12911.33 13766.62 12646.44 10984.8  16765.5  11714.24 10776.76 10963.56\n",
      " 14127.24 12819.28 11123.7  13922.4  13941.56 14547.62 11074.68 15704.62\n",
      " 12035.55 10700.49 14308.19 12781.44 13111.84 14461.57 12498.9  11511.54\n",
      " 11077.72 12798.21  9980.75 12157.77 13489.23 13742.93 14882.52 14878.81\n",
      " 14984.74 12503.83 10134.75 14715.08 14269.71 15431.37 11385.63 12893.89\n",
      " 15263.07 12850.23 11410.9  15353.8  14682.32 10373.31 13818.83 14314.73\n",
      " 10685.39 12420.52  9099.23 12641.3  12910.03 11529.98 11947.39 11521.6\n",
      " 16266.04 13089.93 13818.61 12137.42 14165.51 12821.5  12737.36 12816.42\n",
      " 11225.31 13417.53 15032.44 14062.34 12393.39 13681.01 11433.57 13002.47\n",
      " 12770.02 11463.87 11797.31 12957.33 15065.42 12730.25  8765.32 12468.41\n",
      " 10999.1  12197.87 11640.58 15788.24 13612.48 10792.16 13528.32 11399.09\n",
      " 13529.94 10817.55 12735.2  14499.28 10820.69 12498.97 12228.97 13000.69\n",
      " 14334.86 16694.57 12080.73 14178.65 12092.13 10717.1  12654.27 11699.38\n",
      " 13018.58 12734.06 14405.09 13542.43 14551.73 13727.06 12607.68 11001.89\n",
      " 11885.21 13807.22 12432.6  13896.97 13322.06 12770.02 12807.71 12699.29\n",
      " 11243.88  9153.45  8712.12 12262.14  8618.14 12844.42 13956.41 11658.13\n",
      " 12394.65 14723.94 12797.61 11687.54 13675.34 11203.94 12420.97 14750.14\n",
      " 12746.05 13497.78 13934.83 11412.72 13378.23 12619.01 11935.05 14332.23\n",
      " 10170.07 12641.55 10857.88 12866.14 12294.97 10470.38 14105.1  10674.08\n",
      " 11023.8  11560.38 14408.89 14650.25]\n",
      "663.4968888888889\n",
      "[12038.28 11567.51 12736.87 13128.18 14093.14 12667.23 12480.88 12306.74\n",
      " 10386.68 14115.16 12668.05 13442.71 13590.23 13542.23 14019.22 11928.76\n",
      " 13341.61 12460.56 12854.29 11854.31 13132.62 13352.06 14257.04 13865.43\n",
      " 14263.42 12084.49 11445.96 11138.01 12190.98  9634.81 14147.48 12461.99\n",
      " 12623.21  9033.2  12700.98 13844.29 10539.79 12202.02 12454.7  10994.26\n",
      " 13492.56 11380.16 11974.01 14647.43 12238.54 13238.5  13137.7  14087.09\n",
      " 12349.45 11753.15 12995.83 11155.79 16215.01 13253.65 10561.46  9161.83\n",
      " 12410.47 11693.53 12567.85 13645.49 13152.5  12522.1  14954.85 11139.55\n",
      " 12814.75 11048.02 14846.69  8765.28  9103.21 12196.87 14995.07 14225.65\n",
      " 12896.97 14041.05 12236.53 14466.11 10679.4  12574.22 12745.92 10299.22\n",
      " 14664.27 12849.17 11802.13 14390.74 10305.61 15253.16 14708.03 12136.85\n",
      " 14503.04 10242.3  13023.3  10440.83 13245.34 15199.8  15443.24 14757.33\n",
      " 11424.5  10736.05 13317.45 14681.31 15250.75  8703.51 15571.22 13224.55\n",
      " 11168.93 13805.79 14733.33 12695.2  10448.52 11411.2  13928.94 12479.28\n",
      " 13749.31 14541.08 13770.87 13914.76 12650.12 13007.64 10672.95 11179.6\n",
      " 14324.19 12028.47 12580.8  14855.23 12582.86 13089.64 11737.9  12061.11\n",
      " 15524.15 12703.99 15159.34 11010.63 12822.03 12116.38 15067.51 14174.95\n",
      " 13703.9  14171.31 11317.73 12176.49  9847.34 11837.6  12364.41 12416.65\n",
      " 14141.8  12703.83 10938.56 13040.29 12790.92 12599.87 10469.61 11508.96\n",
      " 12423.39 11551.34 13792.44 11864.41  9922.48  8829.72 11595.49 11330.13\n",
      " 14084.84 15935.28 12979.52 10622.75 14021.45 12048.62 10922.96 10525.31\n",
      " 14879.2  15821.38  8226.27 12042.83 13715.56 11379.67 13811.48 11576.53\n",
      " 13794.04 11304.75 13754.99 13319.24 12535.24 13733.7  12026.22 11167.78\n",
      " 15188.74 12576.77 11627.29 13638.84 10458.04 15788.69 12396.34 10539.57\n",
      " 14745.23 12015.95 12686.23 12405.09 14236.19 12884.48 11648.32 13905.47\n",
      " 13439.61 12752.14 15108.2  13000.99 11644.47 14036.47 15160.62 11425.93\n",
      " 12582.2  15316.29 14466.31 11098.88 11200.1  13242.91 14494.12 14405.68\n",
      " 13423.54 12063.99 12433.96 11626.48 12745.46  9619.36 15492.42  9387.41\n",
      " 13801.22 12344.95 14631.73 12477.36 11333.87 12770.03 10764.15 12722.18\n",
      " 14557.61  8903.54 13485.93 11657.54 11678.76 14290.74 10690.24 11842.85\n",
      " 13866.59 14621.71 12701.58 10577.42 13051.27 14120.21 12176.15 12923.7\n",
      " 13917.54 11524.01 14837.87 11785.37 11773.66 10876.81 13317.62 10356.02\n",
      " 11954.39 12574.37 11902.87 12309.12 13625.93 12791.88  8668.88 15868.54\n",
      " 15054.62 15379.79 12770.27 14633.58 12292.44 11823.14 12110.   11317.7\n",
      " 12505.79  8051.22 13077.92 13910.58 12789.45 15381.01 12081.93 15512.24\n",
      " 11286.94 14213.88 13894.51 12589.24  9113.53 12504.75 12673.9  15460.93\n",
      " 14619.52 16339.42 14575.11 11202.31 11230.72 13962.82 12878.5  14236.13\n",
      " 16210.85 15626.88 13990.3  14403.18]\n",
      "         pred\n",
      "0    12038.28\n",
      "1    11567.51\n",
      "2    12736.87\n",
      "3    13128.18\n",
      "4    14093.14\n",
      "..        ...\n",
      "295  14236.13\n",
      "296  16210.85\n",
      "297  15626.88\n",
      "298  13990.30\n",
      "299  14403.18\n",
      "\n",
      "[300 rows x 1 columns]\n",
      "         date day_of_week  month     station_name  visibility  precipitation  \\\n",
      "0  2023-02-01   Wednesday      2  Hongdae Station    8.181270       8.811098   \n",
      "1  2023-02-02   Wednesday      2  Gangnam Station   10.057751      18.851489   \n",
      "2  2023-02-03      Friday      2   Jamsil Station    9.895961      11.771597   \n",
      "3  2023-02-04   Wednesday      2   Sillim Station   13.283054       1.346370   \n",
      "4  2023-02-05   Wednesday      2   Sillim Station    9.832798       4.033435   \n",
      "\n",
      "   temperature  \n",
      "0    11.411536  \n",
      "1    15.566285  \n",
      "2    16.331512  \n",
      "3    18.014205  \n",
      "4    22.576629  \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì„ì˜ ìƒì„±\n",
    "df1 = pd.read_csv('./datasets/P240622-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P240622-02.csv')\n",
    "\n",
    "# [í™•ì¸] í–‰, ì—´ ê°œìˆ˜ í™•ì¸\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "\n",
    "# [í™•ì¸] info() : categoryë‚˜ object ìˆëŠ”ì§€ í™•ì¸ => ìˆì„ ê²½ìš° ì›-í•« ì¸ì½”ë”©\n",
    "print(df1.info())\n",
    "print(df2.info())\n",
    "\n",
    "# [í™•ì¸] describe() : ì´ìƒì¹˜ í™•ì¸ => ìˆì„ ê²½ìš° ëŒ€ì²´(0, í‰ê· ê°’, ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ë“±)\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "# [í™•ì¸] isna().sum() : ê²°ì¸¡ì¹˜ í™•ì¸ => ìˆì„ ê²½ìš° ëŒ€ì²´ => fillna()\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "y = df1['num_people']   # ì¢…ì† ë³€ìˆ˜\n",
    "x = df1.drop('num_people', axis=1)    # ë…ë¦½ ë³€ìˆ˜\n",
    "\n",
    "x_test = df2.copy()   # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x_encoded = pd.get_dummies(x)\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì—´ì„ í•™ìŠµ ë°ì´í„°ì— ë§ì¶”ê¸°\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "# [í™•ì¸] ì›-í•« ì¸ì½”ë”© ì„±ê³µ ì—¬ë¶€\n",
    "print(x_encoded.info())\n",
    "print(x_test_encoded.info())\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.2)\n",
    "\n",
    "# [í™•ì¸] ë¶„í•  ì—¬ë¶€ í™•ì¸\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestRegressor()\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "result = mean_absolute_error(y_valid, pred)   # MAE\n",
    "print(result)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "pred = md.predict(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred\n",
    "})\n",
    "print(result)\n",
    "result.to_csv('./outputs/20241112_Q7.csv', index=False)\n",
    "\n",
    "# [í™•ì¸]\n",
    "print(df2.head())\n",
    "print(len(df2) == 2064)   # ìµœì¢… ì œì¶œ ì»¬ëŸ¼ í¬ê¸° í™•ì¸ (ë¬¸ì œ ì œì‹œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 8 (ì‹œí—˜ì¥ í™˜ê²½ ì²´í—˜ ì˜ˆì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë°±í™”ì  ê³ ê°ì´ 1ë…„ê°„ ìƒí’ˆì„ êµ¬ë§¤í•œ ì†ì„± ë°ì´í„°\n",
    "- ì œê³µëœ í•™ìŠµìš© ë°ì´í„°(`customer_train.csv`)ë¥¼ ì´ìš©í•˜ì—¬ ë°±í™”ì  êµ¬ë§¤ ê³ ê°ì˜ ì„±ë³„ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ê³ , ê°œë°œí•œ ëª¨ë¸ì— ê¸°ë°˜í•˜ì—¬ í‰ê°€ìš© ë°ì´í„°(`customer_test.csv`)ì— ì ìš©í•˜ì—¬ ì„±ë³„ ì˜ˆì¸¡í•˜ê¸°\n",
    "\n",
    "```text\n",
    "ì˜ˆì¸¡ ê²°ê³¼ëŠ” ROC-AUC í‰ê°€ ì§€í‘œì— ë”°ë¼ í‰ê°€\n",
    "ì˜ˆì¸¡ ì„±ë³„ ì»¬ëŸ¼ëª… : pred\n",
    "ì œì¶œ ì»¬ëŸ¼ ê°œìˆ˜ : 1ê°œ\n",
    "í‰ê°€ìš© ë°ì´í„° ê°œìˆ˜ì™€ ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„° ê°œìˆ˜ ì¼ì¹˜ : 2482ê°œ\n",
    "pred ì»¬ëŸ¼ ë°ì´í„° ê°œìˆ˜ : 2,482ê°œ\n",
    "í•™ìŠµìš© ë°ì´í„° : 3,500ê°œ\n",
    "í‰ê°€ìš© ë°ì´í„° : 2,482ê°œ\n",
    "```\n",
    "\n",
    "|pred|\n",
    "|:-:|\n",
    "|0|\n",
    "|1|\n",
    "|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv(\"./datasets/customer_train.csv\")\n",
    "df2 = pd.read_csv(\"./datasets/customer_test.csv\")\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”© (ê°ì²´ -> ìˆ˜ì¹˜í˜•)\n",
    "le_product = LabelEncoder()\n",
    "le_store = LabelEncoder()\n",
    "\n",
    "df1['ì£¼êµ¬ë§¤ìƒí’ˆ'] = le_product.fit_transform(df1['ì£¼êµ¬ë§¤ìƒí’ˆ'])  \n",
    "df2['ì£¼êµ¬ë§¤ìƒí’ˆ'] = le_product.transform(df2['ì£¼êµ¬ë§¤ìƒí’ˆ']) \n",
    "\n",
    "df1['ì£¼êµ¬ë§¤ì§€ì '] = le_store.fit_transform(df1['ì£¼êµ¬ë§¤ì§€ì ']) \n",
    "df2['ì£¼êµ¬ë§¤ì§€ì '] = le_store.transform(df2['ì£¼êµ¬ë§¤ì§€ì '])  \n",
    "\n",
    "# ê²°ì¸¡ê°’ ì²˜ë¦¬ (í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´)\n",
    "# print(\"ê²°ì¸¡ì¹˜ í™•ì¸ (df1\", df1.isnull().sum())\n",
    "# print(\"ê²°ì¸¡ì¹˜ í™•ì¸ (df2\", df2.isnull().sum())\n",
    "\n",
    "df1['í™˜ë¶ˆê¸ˆì•¡'] = df1['í™˜ë¶ˆê¸ˆì•¡'].fillna(df1['í™˜ë¶ˆê¸ˆì•¡'].mean())   # í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "df2['í™˜ë¶ˆê¸ˆì•¡'] = df2['í™˜ë¶ˆê¸ˆì•¡'].fillna(df2['í™˜ë¶ˆê¸ˆì•¡'].mean())   # í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "\n",
    "# ì¢…ì† ë³€ìˆ˜ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜\n",
    "df1['ì„±ë³„'] = df1['ì„±ë³„'].astype('category')\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬\n",
    "x = df1.drop('ì„±ë³„', axis=1)\n",
    "y = df1['ì„±ë³„']\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x = x.drop('íšŒì›ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.2)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred = md.predict(x_valid)\n",
    "proba = md.predict_proba(x_valid)[:, :1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_valid, proba)\n",
    "print(roc_auc)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('íšŒì›ID', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test) # ì›-í•« ì¸ì½”ë”©\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "pred = md.predict(x_test_encoded)   # ì˜ˆì¸¡\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "\t'pred': pred\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "train = pd.read_csv(\"./datasets/customer_train.csv\")\n",
    "test = pd.read_csv(\"./datasets/customer_test.csv\")\n",
    "\n",
    "train['í™˜ë¶ˆê¸ˆì•¡'] = train['í™˜ë¶ˆê¸ˆì•¡'].fillna(0)\n",
    "test['í™˜ë¶ˆê¸ˆì•¡'] = test['í™˜ë¶ˆê¸ˆì•¡'].fillna(0)\n",
    "\n",
    "### í•„ìš”ì—†ëŠ” ë³€ìˆ˜ ì œê±°\n",
    "train = train.drop('íšŒì›ID', axis=1)\n",
    "test = test.drop('íšŒì›ID', axis=1)\n",
    "\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "\n",
    "## (2) ë…ë¦½/ì¢…ì† ë³€ìˆ˜ ì„¤ì •\n",
    "x = train.drop('ì„±ë³„', axis=1)\n",
    "y = train['ì„±ë³„']\n",
    "\n",
    "## (2) ì›í•« ì¸ì½”ë”©\n",
    "x_encoded = pd.get_dummies(x)\n",
    "x_test_encoded = pd.get_dummies(test)\n",
    "\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "## (3) ë°ì´í„° ë¶„í• \n",
    "from sklearn.model_selection import *\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.2)\n",
    "\n",
    "## (4) ëª¨ë¸ë§\n",
    "from sklearn.ensemble import *\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "## (5) ì˜ˆì¸¡\n",
    "pred = model.predict(x_valid)\n",
    "print(pred[:10])\n",
    "\n",
    "## (6) í‰ê°€\n",
    "from sklearn.metrics import *\n",
    "roc_auc = roc_auc_score(y_valid, pred)\n",
    "print(roc_auc)\n",
    "\n",
    "## (7) í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "pred = model.predict(x_test_encoded)\n",
    "print(pred[:10])\n",
    "\n",
    "\n",
    "result = pd.DataFrame({\n",
    "\t'pred': pred\n",
    "})\n",
    "result.to_csv('result.csv', index=False)\n",
    "\n",
    "result = pd.read_csv('result.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 9 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê° ê³ ê°ì´ ê°€ì…í•œ ì„œë¹„ìŠ¤ì™€ ê³„ì • ì •ë³´, ì¸êµ¬ì— ëŒ€í•œ í†µê³„ ì •ë³´ê°€ ë“¤ì–´ ìˆëŠ” `telco-customer-churn` ë°ì´í„°\n",
    "- í›ˆë ¨ ë°ì´í„°(`M1-4-1.csv`)ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•œ í›„ í…ŒìŠ¤íŠ¸ ë°ì´í„°(`M1-4-2.csv`)ë¡œ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ê¸°\n",
    "    - ì´íƒˆ : `Yes`, ìœ ì§€ : `No`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[562 118]\n",
      " [ 53 111]]\n",
      "0.79739336492891\n",
      "0.4847161572052402\n",
      "0.676829268292683\n",
      "0.5648854961832062\n",
      "0.6992686477083111\n",
      "[0 0 1 ... 0 1 0]\n",
      "     pred\n",
      "0      No\n",
      "1      No\n",
      "2     Yes\n",
      "3     Yes\n",
      "4     Yes\n",
      "...   ...\n",
      "3652   No\n",
      "3653   No\n",
      "3654   No\n",
      "3655  Yes\n",
      "3656   No\n",
      "\n",
      "[3657 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/M1-4-1.csv')\n",
    "df2 = pd.read_csv('./datasets/M1-4-2.csv')\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”© (Object -> Int)\n",
    "columns_to_encode = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df1[col])\n",
    "\n",
    "    df1[col] = le.transform(df1[col])\n",
    "    df2[col] = le.transform(df2[col])\n",
    "\n",
    "# Churn ì»¬ëŸ¼ì˜ ê°’ì—ì„œ Yes -> 0, No -> 1ë¡œ ë§¤í•‘\n",
    "df1['Churn'] = df1['Churn'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "\n",
    "df2['Churn'] = df2['Churn'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "\n",
    "# ìë£Œí˜• ë³€í™˜\n",
    "df1['Churn'] = df1['Churn'].astype('category')\n",
    "\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë¶„ë¦¬\n",
    "x = df1.drop('Churn', axis=1)\n",
    "y = df1['Churn']\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„° í‰ê°€\n",
    "x_valid_encoded = pd.get_dummies(x_valid)\n",
    "x_valid_encoded = x_valid_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "pred_valid = md.predict(x_valid_encoded)\n",
    "\n",
    "# ì„±ëŠ¥ í‰ê°€\n",
    "cm = confusion_matrix(pred_valid, y_valid)\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred_valid))\n",
    "print(recall_score(y_valid, pred_valid))\n",
    "print(precision_score(y_valid, pred_valid))\n",
    "print(f1_score(y_valid, pred_valid))\n",
    "print(roc_auc_score(y_valid, pred_valid))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2.drop('Churn', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)   # ì›-í•« ì¸ì½”ë”©\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "pred_new = md.predict(x_test_encoded)   # ì˜ˆì¸¡\n",
    "pred_new_label = ['No' if pred == 0 else 'Yes' for pred in pred_new]\n",
    "print(pred_new)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred_new_label\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 10 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32ê°œ ìë™ì°¨ë“¤ì˜ ë””ìì¸ê³¼ ì„±ëŠ¥ì„ ë¹„êµí•œ `mtcars` ë°ì´í„°\n",
    "\n",
    "> (1) í›ˆë ¨ ë°ì´í„°ì™€ í‰ê°€ ë°ì´í„°ë¥¼ ìˆœì„œëŒ€ë¡œ 7.5 : 2.5ë¡œ ë¶„í• í•˜ê¸°\n",
    "\n",
    "> (2) ì¢…ì† ë³€ìˆ˜ëŠ” ì—°ë¹„(`mpg`), ë…ë¦½ ë³€ìˆ˜ë¥¼ ì°¨ì¸¡ ë¹„ìœ¨(`dart`), ë¬´ê²Œ(`wt`), ì „ì§„ ê¸°ì–´ ê°œìˆ˜(`gear`), ê¸°í™”ê¸° ê°œìˆ˜(`carb`)ë¡œ ì„ í˜• íšŒê·€ ëª¨í˜• ë§Œë“¤ê¸°\n",
    "\n",
    "> (3) ìƒì„±ëœ ëª¨ë¸ì„ RMSEë¡œ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ë‚˜íƒ€ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3530474509211956\n",
      "[14.67       32.376      30.40666667 33.82266667 21.58133333 15.57466667\n",
      " 18.66333333 18.1        14.303      24.384      22.80066667 19.17666667\n",
      " 17.8        16.392      17.3        15.221      10.4        10.4\n",
      " 14.67       32.376      30.40666667 33.82266667 21.58133333 15.57466667\n",
      " 18.66333333 18.1        14.303      24.384      22.80066667 19.17666667\n",
      " 17.8        16.392      17.3        15.221      10.4        10.4\n",
      " 14.67       32.376      30.40666667 33.82266667 21.58133333 15.57466667]\n",
      "         pred\n",
      "0   14.670000\n",
      "1   32.376000\n",
      "2   30.406667\n",
      "3   33.822667\n",
      "4   21.581333\n",
      "5   15.574667\n",
      "6   18.663333\n",
      "7   18.100000\n",
      "8   14.303000\n",
      "9   24.384000\n",
      "10  22.800667\n",
      "11  19.176667\n",
      "12  17.800000\n",
      "13  16.392000\n",
      "14  17.300000\n",
      "15  15.221000\n",
      "16  10.400000\n",
      "17  10.400000\n",
      "18  14.670000\n",
      "19  32.376000\n",
      "20  30.406667\n",
      "21  33.822667\n",
      "22  21.581333\n",
      "23  15.574667\n",
      "24  18.663333\n",
      "25  18.100000\n",
      "26  14.303000\n",
      "27  24.384000\n",
      "28  22.800667\n",
      "29  19.176667\n",
      "30  17.800000\n",
      "31  16.392000\n",
      "32  17.300000\n",
      "33  15.221000\n",
      "34  10.400000\n",
      "35  10.400000\n",
      "36  14.670000\n",
      "37  32.376000\n",
      "38  30.406667\n",
      "39  33.822667\n",
      "40  21.581333\n",
      "41  15.574667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/M2-4-1.csv')\n",
    "df2 = pd.read_csv('./datasets/M2-4-2.csv')\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜, ì¢…ì† ë³€ìˆ˜ ë¶„í• \n",
    "x = df1.drop('mpg', axis=1)\n",
    "y = df1['mpg']\n",
    "\n",
    "# ì›-í•« ì¸ì½”ë”©\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# ëª¨ë¸ë§\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# í‰ê°€\n",
    "pred = md.predict(x_valid)\n",
    "result = root_mean_squared_error(y_valid, pred)   # RMSE\n",
    "print(result)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "x_test = df2\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)   # ì›-í•« ì¸ì½”ë”©\n",
    "\n",
    "# ê³µí†µëœ ì—´ ì¶”ì¶œí•˜ê¸°\n",
    "common_features = list(set(x_encoded.columns).intersection(x_test_encoded.columns))\n",
    "\n",
    "x_train_common = x_encoded[common_features]\n",
    "x_test_common = x_test_encoded[common_features]\n",
    "\n",
    "# ëª¨ë¸ë§ (í•œë²ˆ ë”)\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train_common, y)\n",
    "\n",
    "# í‰ê°€\n",
    "pred = md.predict(x_test_common)\n",
    "print(pred)\n",
    "\n",
    "# CSV ë‚´ë³´ë‚´ê¸°\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì œ3ìœ í˜•\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 1 (23ë…„ 6íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê°ê¸°ì•½ì„ ë³µìš©í•  ë•Œ ë¶€ì‘ìš©ì— ëŒ€í•œ ë¶„ë¥˜ì™€ ë¹„ìœ¨ ë°ì´í„°\n",
    "- ìœ„ì•½ íš¨ê³¼ê°€ ìˆëŠ”ì§€ 253ê±´ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ê²€ì¦í•˜ë ¤ê³  í•œë‹¤.\n",
    "- ê°ê¸° ë¶€ì‘ìš©ì— ëŒ€í•œ ë¹„ìœ¨ì´ ìœ„ì•½ íš¨ê³¼ ë¶€ì‘ìš© ë¹„ìœ¨ê³¼ ê°™ì€ì§€ ì¹´ì´ì œê³± ê²€ì •í•˜ê¸°\n",
    "\n",
    "|ë¶€ì‘ìš© ìœ í˜•|ì½”ë“œ|ë¹„ìœ¨|\n",
    "|:-:|:-:|:-:|\n",
    "|ë‘í†µ|1|0.05|\n",
    "|ì¡¸ë¦¼|2|0.1|\n",
    "|ì†ì“°ë¦¼|3|0.05|\n",
    "|ë¶€ì‘ìš© ì—†ìŒ|4|0.8|\n",
    "|í•©ê³„| |1|\n",
    "\n",
    "> (1) ìœ„ì•½ ìƒ˜í”Œ ë°ì´í„°ê°€ `ë¶€ì‘ìš© ì—†ìŒ`ì¸ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ì¶œë ¥í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ì¶œë ¥)\n",
    "\n",
    "> (2) ì¹´ì´ì œê³± ê²€ì •ìœ¼ë¡œ ê²€ì • í†µê³„ëŸ‰ ì¶œë ¥í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ì¶œë ¥)\n",
    "\n",
    "> (3) ìœ ì˜í™•ë¥ (p-value) ì¶œë ¥í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ì¶œë ¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787\n",
      "Power_divergenceResult(statistic=0.9970355731225298, pvalue=0.801969260894451)\n",
      "0.997\n",
      "0.802\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "df = pd.read_csv('./datasets/P230605.csv', encoding='euckr')\n",
    "\n",
    "# ì½”ë“œë³„ë¡œ ê·¸ë£¹í™” ë° ë¹„ìœ¨ ê³„ì‚°í•˜ì—¬ ì»¬ëŸ¼ ì¶”ê°€\n",
    "df_placebo = df.groupby('ì½”ë“œ').size().reset_index(name='ê±´ìˆ˜')\n",
    "\n",
    "total_count = len(df)\n",
    "df_placebo['ë¹„ìœ¨'] = df_placebo['ê±´ìˆ˜'] / total_count\n",
    "\n",
    "# (1) ìœ„ì•½ ìƒ˜í”Œ ë°ì´í„°ê°€ 'ë¶€ì‘ìš© ì—†ìŒ'ì¸ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "answer1 = round(df_placebo['ë¹„ìœ¨'][3], 3)\n",
    "print(answer1)\n",
    "\n",
    "# (2) ì¹´ì´ì œê³± ê²€ì •ìœ¼ë¡œ ê²€ì • í†µê³„ëŸ‰ ì¶œë ¥í•˜ê¸°\n",
    "df_rate = pd.DataFrame({\n",
    "    'ì½”ë“œ': [1, 2, 3, 4],\n",
    "    'ë¹„ìœ¨' : [0.05, 0.1, 0.05, 0.8]\n",
    "})\n",
    "result_chisquare = chisquare(df_placebo['ê±´ìˆ˜'], f_exp=df_rate['ë¹„ìœ¨'] * total_count)\n",
    "print(result_chisquare)\n",
    "\n",
    "answer2 = round(result_chisquare.statistic, 3)\n",
    "print(answer2)\n",
    "\n",
    "# (3) ìœ ì˜ í™•ë¥ (p-value) êµ¬í•˜ê¸°\n",
    "answer3 = round(result_chisquare.pvalue, 3)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì¶œ ë³€í˜• ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ì½”ë“œ   ê±´ìˆ˜\n",
      "0   1   15\n",
      "1   2   25\n",
      "2   3   17\n",
      "3   4  196\n",
      "(1) ìœ„ì•½ ìƒ˜í”Œ ë°ì´í„° 'ë¶€ì‘ìš© ì—†ìŒ' í™•ë¥ : 0.775\n",
      "0     12.65\n",
      "1     25.30\n",
      "2     12.65\n",
      "3    202.40\n",
      "Name: ë¹„ìœ¨, dtype: float64\n",
      "(2) ì¹´ì´ì œê³± ê²€ì • í†µê³„ëŸ‰: 2.138\n",
      "(3) ìœ ì˜í™•ë¥ (p-value): 0.544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# ê°€ìƒ ë°ì´í„° ìƒì„± \n",
    "np.random.seed(42)\n",
    "sample_size = 253\n",
    "\n",
    "effect_rates = {\n",
    "    1: 0.05,  # ë‘í†µ\n",
    "    2: 0.1,   # ì¡¸ë¦¼\n",
    "    3: 0.05,  # ì†ì“°ë¦¼\n",
    "    4: 0.8    # ë¶€ì‘ìš© ì—†ìŒ\n",
    "}\n",
    "\n",
    "sample_data = np.random.choice(list(effect_rates.keys()), size=sample_size, p=list(effect_rates.values()))\n",
    "df = pd.DataFrame(sample_data, columns=['ì½”ë“œ'])\n",
    "\n",
    "# (1) ìœ„ì•½ ìƒ˜í”Œ ë°ì´í„°ê°€ 'ë¶€ì‘ìš© ì—†ìŒ'ì¸ ë°ì´í„°ë¥¼ 0~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ì¶œë ¥í•˜ê¸°\n",
    "df_placebo = df.groupby('ì½”ë“œ').size().reset_index(name='ê±´ìˆ˜')\n",
    "print(df_placebo)\n",
    "\n",
    "total_count = len(df)\n",
    "df_placebo['ë¹„ìœ¨'] = df_placebo['ê±´ìˆ˜'] / total_count\n",
    "\n",
    "# 'ë¶€ì‘ìš© ì—†ìŒ' ë¹„ìœ¨\n",
    "answer1 = round(df_placebo['ë¹„ìœ¨'][df_placebo['ì½”ë“œ'] == 4].values[0], 3)\n",
    "print(\"(1) ìœ„ì•½ ìƒ˜í”Œ ë°ì´í„° 'ë¶€ì‘ìš© ì—†ìŒ' í™•ë¥ :\", answer1)\n",
    "\n",
    "# (2) ì¹´ì´ì œê³± ê²€ì •ìœ¼ë¡œ ê²€ì • í†µê³„ëŸ‰ êµ¬í•˜ê¸°\n",
    "df_rate = pd.DataFrame({\n",
    "    'ì½”ë“œ': [1, 2, 3, 4],\n",
    "    'ë¹„ìœ¨' : [0.05, 0.1, 0.05, 0.8]\n",
    "})\n",
    "\n",
    "## ê¸°ëŒ€ê°’ ê³„ì‚°\n",
    "expected_counts = df_rate['ë¹„ìœ¨'] * total_count\n",
    "print(expected_counts)\n",
    "\n",
    "## ì¹´ì´ì œê³± ê²€ì •\n",
    "statistics, pvalue = chisquare(df_placebo['ê±´ìˆ˜'], f_exp=expected_counts)\n",
    "answer2 = round(statistics, 3)\n",
    "print(\"(2) ì¹´ì´ì œê³± ê²€ì • í†µê³„ëŸ‰:\", answer2)\n",
    "\n",
    "# (3) ìœ ì˜í™•ë¥ (p-value) êµ¬í•˜ê¸°\n",
    "answer3 = round(pvalue, 3)\n",
    "print(\"(3) ìœ ì˜í™•ë¥ (p-value):\", answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 2 (23ë…„ 6íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë‚ ì”¨ ë°ì´í„°\n",
    "- ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ì¡´(`O3`), ì¼ì‚¬ëŸ‰(`Solar`), í’ì†(`Wind`) ë³€ìˆ˜ì— ëŒ€í•œ ì˜¨ë„(`Temperature`)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„±í•˜ê¸°\n",
    "\n",
    "> (1) ì˜¤ì¡´ë†ë„ ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ê³„ìˆ˜ ì¶”ì •ê°’ ì¶œë ¥í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ì¶œë ¥)\n",
    "\n",
    "> (2) ì˜¤ì¡´ë†ë„, ì¼ì‚¬ëŸ‰ì´ ê³ ì •ì¼ ë•Œ í’ì†ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì˜¨ë„ê°€ ë‚®ì•„ì§„ë‹¤ëŠ” ê²ƒì„ ê²€ì¦í–ˆë‹¤. t-ê²€ì¦ ê°’ì˜ ìœ ì˜í™•ë¥ (p-value) êµ¬í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ì¶œë ¥)\n",
    "\n",
    "> (3) ì–´ë–¤ ë‚ ì´ ì˜¤ì¡´ë†ë„ 10, ì¼ì‚¬ëŸ‰ 90, í’ì† 20ì¼ ë•Œ ì˜¨ë„ì˜ ì˜ˆì¸¡ê°’ êµ¬í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ë¡œ ì¶œë ¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Coefficient\n",
      "0      O3     0.171966\n",
      "1   Solar     0.007276\n",
      "2    Wind    -0.322945\n",
      "0.172\n",
      "0.0\n",
      "68.334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('./datasets/P230606.csv', encoding='euckr')\n",
    "\n",
    "x = df[['O3', 'Solar', 'Wind']]\n",
    "y = df['Temperature']\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(x, y)\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': ['O3', 'Solar', 'Wind'],\n",
    "    'Coefficient': lm.coef_\n",
    "})\n",
    "print(coefs)\n",
    "    \n",
    "# (1) ì˜¤ì¡´ë†ë„ ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜ ì¶”ì •ê°’ êµ¬í•˜ê¸°\n",
    "answer1 = round(float(coefs[coefs['Feature'] == 'O3']['Coefficient'].iloc[0]), 3)\n",
    "print(answer1)\n",
    "\n",
    "# (2) ì˜¤ì¡´ë†ë„, ì¼ì‚¬ëŸ‰ì´ ê³ ì •ì¼ ë•Œ í’ì†ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì˜¨ë„ê°€ ë‚®ì•„ì§€ëŠ” ê²ƒì„ t-ê²€ì¦ì„ ì´ìš©í•˜ì—¬ ìœ ì˜ í™•ë¥ (p-value) êµ¬í•˜ê¸°\n",
    "[statistic, p_value] = ttest_ind(x['Wind'], y)\n",
    "answer2 = round(p_value, 3)\n",
    "print(answer2)\n",
    "\n",
    "# (3) ì–´ë–¤ ë‚ ì´ ì˜¤ì¡´ë†ë„ 10, ì¼ì‚¬ëŸ‰ 90, í’ì† 20ì¼ ë•Œ ì˜¨ë„ì˜ ì˜ˆì¸¡ê°’ êµ¬í•˜ê¸° \n",
    "df_oneday = pd.DataFrame({\n",
    "    'O3': [10],\n",
    "    'Solar': [90],\n",
    "    'Wind': [20]\n",
    "})\n",
    "answer3 = lm.predict(df_oneday)\n",
    "answer3 = np.round(answer3[0], 3)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì¶œ ë³€í˜• ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ë°©ë²• 1 : `sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Coefficient\n",
      "0      O3     0.060398\n",
      "1   Solar    -0.028957\n",
      "2    Wind    -0.117663\n",
      "(1) ì˜¤ì¡´ë†ë„ ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜: 0.06\n",
      "(2) t-ê²€ì¦ p-value: 0.026\n",
      "(3) ì˜ˆì¸¡ëœ ì˜¨ë„: 18.644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ê°€ìƒì˜ ë‚ ì”¨ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(42)  \n",
    "n_samples = 100\n",
    "\n",
    "O3 = np.random.uniform(0, 200, n_samples)   # ì˜¤ì¡´ ë†ë„ (0~200 ì‚¬ì´ì˜ ê°’)\n",
    "Solar = np.random.uniform(0, 1000, n_samples)  # ì¼ì‚¬ëŸ‰ (0~1000 ì‚¬ì´ì˜ ê°’)\n",
    "Wind = np.random.uniform(0, 20, n_samples)    # í’ì† (0~20 ì‚¬ì´ì˜ ê°’)\n",
    "Temperature = 25 + 0.05 * O3 - 0.03 * Solar - 0.2 * Wind + np.random.normal(0, 5, n_samples)  # ì˜¨ë„\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'O3': O3,\n",
    "    'Solar': Solar,\n",
    "    'Wind': Wind,\n",
    "    'Temperature': Temperature\n",
    "})\n",
    "\n",
    "# ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "X = df[['O3', 'Solar', 'Wind']]    # ë…ë¦½ ë³€ìˆ˜\n",
    "y = df['Temperature']              # ì¢…ì† ë³€ìˆ˜\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': ['O3', 'Solar', 'Wind'],\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "print(coefs)\n",
    "\n",
    "# (1) ì˜¤ì¡´ë†ë„ ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜ ì¶”ì •ê°’ êµ¬í•˜ê¸°\n",
    "answer1 = round(float(coefs[coefs['Feature'] == 'O3']['Coefficient'].iloc[0]), 3)\n",
    "print(\"(1) ì˜¤ì¡´ë†ë„ ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜:\", answer1)\n",
    "\n",
    "# (2) ì˜¤ì¡´ë†ë„, ì¼ì‚¬ëŸ‰ì´ ê³ ì •ì¼ ë•Œ í’ì†ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì˜¨ë„ê°€ ë‚®ì•„ì§€ëŠ” ê²ƒì„ t-ê²€ì¦ì„ ì´ìš©í•˜ì—¬ ìœ ì˜ í™•ë¥ (p-value) êµ¬í•˜ê¸°\n",
    "statistic, p_value = ttest_ind(x['Wind'], y)\n",
    "\n",
    "answer2 = round(p_value, 3)\n",
    "print(\"(2) t-ê²€ì¦ p-value:\", answer2)\n",
    "\n",
    "# (3) ì–´ë–¤ ë‚ ì´ ì˜¤ì¡´ë†ë„ 10, ì¼ì‚¬ëŸ‰ 90, í’ì† 20ì¼ ë•Œ ì˜¨ë„ì˜ ì˜ˆì¸¡ê°’ êµ¬í•˜ê¸°\n",
    "df_oneday = pd.DataFrame({\n",
    "    'O3': [10],\n",
    "    'Solar': [90],\n",
    "    'Wind': [20]\n",
    "})\n",
    "\n",
    "answer3 = model.predict(df_oneday)\n",
    "answer3 = np.round(answer3[0], 3)\n",
    "print(\"(3) ì˜ˆì¸¡ëœ ì˜¨ë„:\", answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ë°©ë²• 2 : `statsmodels.api.OLS()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            Temperature   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.779\n",
      "Method:                 Least Squares   F-statistic:                     117.4\n",
      "Date:                Sat, 16 Nov 2024   Prob (F-statistic):           5.35e-32\n",
      "Time:                        21:49:16   Log-Likelihood:                -299.12\n",
      "No. Observations:                 100   AIC:                             606.2\n",
      "Df Residuals:                      96   BIC:                             616.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         22.9999      1.639     14.032      0.000      19.746      26.253\n",
      "O3             0.0604      0.008      7.261      0.000       0.044       0.077\n",
      "Solar         -0.0290      0.002    -16.978      0.000      -0.032      -0.026\n",
      "Wind          -0.1177      0.085     -1.381      0.170      -0.287       0.051\n",
      "==============================================================================\n",
      "Omnibus:                        5.375   Durbin-Watson:                   2.376\n",
      "Prob(Omnibus):                  0.068   Jarque-Bera (JB):                4.964\n",
      "Skew:                          -0.402   Prob(JB):                       0.0836\n",
      "Kurtosis:                       3.738   Cond. No.                     1.94e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.94e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "(1) ì˜¤ì¡´ë†ë„(O3) ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜: 0.06\n",
      "(2) í’ì†(Wind)ì— ëŒ€í•œ t-ê²€ì¦ p-value: 0.17\n",
      "(3) ì˜ˆì¸¡ëœ ì˜¨ë„: 18.644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ê°€ìƒì˜ ë‚ ì”¨ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "O3 = np.random.uniform(0, 200, n_samples)   # ì˜¤ì¡´ ë†ë„ (0~200 ì‚¬ì´ì˜ ê°’)\n",
    "Solar = np.random.uniform(0, 1000, n_samples)  # ì¼ì‚¬ëŸ‰ (0~1000 ì‚¬ì´ì˜ ê°’)\n",
    "Wind = np.random.uniform(0, 20, n_samples)    # í’ì† (0~20 ì‚¬ì´ì˜ ê°’)\n",
    "Temperature = 25 + 0.05 * O3 - 0.03 * Solar - 0.2 * Wind + np.random.normal(0, 5, n_samples)  # ì˜¨ë„\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'O3': O3,\n",
    "    'Solar': Solar,\n",
    "    'Wind': Wind,\n",
    "    'Temperature': Temperature\n",
    "})\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜ì— ìƒìˆ˜í•­ ì¶”ê°€ (statsmodelsì—ì„œëŠ” ìƒìˆ˜í•­ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•´ì•¼ í•¨)\n",
    "X = df[['O3', 'Solar', 'Wind']]   # ë…ë¦½ ë³€ìˆ˜\n",
    "X = sm.add_constant(X)  # ìƒìˆ˜í•­ ì¶”ê°€\n",
    "\n",
    "y = df['Temperature']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "# (1) íšŒê·€ ê³„ìˆ˜ ì¶”ì •ê°’ ì¶œë ¥ (ì˜¤ì¡´ë†ë„ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜)\n",
    "answer1 = round(model.params['O3'], 3)\n",
    "\n",
    "print(\"(1) ì˜¤ì¡´ë†ë„(O3) ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜:\", answer1)\n",
    "\n",
    "# (2) t-ê²€ì¦ p-value ì¶œë ¥\n",
    "answer2 = round(model.pvalues['Wind'], 3)\n",
    "\n",
    "print(\"(2) í’ì†(Wind)ì— ëŒ€í•œ t-ê²€ì¦ p-value:\", answer2)\n",
    "\n",
    "# (3) ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
    "new_data = pd.DataFrame({\n",
    "    'const': [1],  # ìƒìˆ˜í•­\n",
    "    'O3': [10],\n",
    "    'Solar': [90],\n",
    "    'Wind': [20]\n",
    "})\n",
    "\n",
    "answer3 = model.predict(new_data)\n",
    "answer3 = np.round(answer3[0], 3)\n",
    "\n",
    "print(\"(3) ì˜ˆì¸¡ëœ ì˜¨ë„:\", answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 3 (23ë…„ 7íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì¢…ì† ë³€ìˆ˜ : `Target`\n",
    "\n",
    "> (1) ì„ í˜• ê´€ê³„ ê°€ì¥ í° ë³€ìˆ˜ ì°¾ì•„ ìƒê´€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "\n",
    "> (2) `Target` ë³€ìˆ˜ë¥¼ ì¢…ì† ë³€ìˆ˜ë¡œ í•˜ì—¬ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ë§ì„ ì§„í–‰í–ˆì„ ë•Œ `v2` ì»¬ëŸ¼ì˜ íšŒê·€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "\n",
    "> (3) íšŒê·€ ê³„ìˆ˜ë“¤ì´ ê°€ì§€ëŠ” p-ê°’ë“¤ ì¤‘ ìµœëŒ€ê°’ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6270251925517436\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 5.228e+04\n",
      "Date:                Sat, 16 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        19:37:44   Log-Likelihood:                -707.67\n",
      "No. Observations:                1000   AIC:                             1459.\n",
      "Df Residuals:                     978   BIC:                             1567.\n",
      "Df Model:                          21                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0118      0.016      0.739      0.460      -0.019       0.043\n",
      "v1             5.5360      0.016    353.805      0.000       5.505       5.567\n",
      "v2             6.4403      0.016    410.550      0.000       6.410       6.471\n",
      "v3             9.6506      0.016    614.757      0.000       9.620       9.681\n",
      "v4             8.9758      0.016    576.776      0.000       8.945       9.006\n",
      "v5             1.9523      0.016    124.711      0.000       1.922       1.983\n",
      "v6             0.0145      0.016      0.899      0.369      -0.017       0.046\n",
      "v7            -0.0023      0.016     -0.140      0.888      -0.034       0.029\n",
      "v8             0.0173      0.016      1.096      0.274      -0.014       0.048\n",
      "v9            -0.0123      0.016     -0.781      0.435      -0.043       0.019\n",
      "v10           -0.0019      0.016     -0.117      0.906      -0.033       0.030\n",
      "v11            0.0171      0.016      1.099      0.272      -0.013       0.048\n",
      "v12            0.0161      0.016      1.018      0.309      -0.015       0.047\n",
      "v13           -0.0167      0.016     -1.058      0.290      -0.048       0.014\n",
      "v14            0.0068      0.016      0.412      0.681      -0.026       0.039\n",
      "v15           -0.0432      0.017     -2.605      0.009      -0.076      -0.011\n",
      "v16            0.0117      0.016      0.749      0.454      -0.019       0.043\n",
      "v17            0.0156      0.015      1.012      0.312      -0.015       0.046\n",
      "v18            0.0100      0.016      0.628      0.530      -0.021       0.041\n",
      "v19           -0.0174      0.016     -1.119      0.263      -0.048       0.013\n",
      "v20            0.0098      0.015      0.637      0.524      -0.020       0.040\n",
      "v21            0.0015      0.016      0.092      0.927      -0.030       0.033\n",
      "==============================================================================\n",
      "Omnibus:                        4.701   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.095   Jarque-Bera (JB):                4.745\n",
      "Skew:                          -0.167   Prob(JB):                       0.0932\n",
      "Kurtosis:                       2.955   Cond. No.                         1.32\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "6.440301364843059\n",
      "0.9265545986907169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kss34\\AppData\\Local\\Temp\\ipykernel_8816\\1785163409.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer1 = target.sort_values(ascending=False)[1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import *\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('./datasets/P230705.csv')\n",
    "\n",
    "# (1) ì„ í˜• ê´€ê³„ ê°€ì¥ í° ë³€ìˆ˜ ì°¾ì•„ ìƒê´€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "corr_df = df.corr()\n",
    "target = corr_df['Target']\n",
    "answer1 = target.sort_values(ascending=False)[1]\n",
    "print(answer1)\n",
    "\n",
    "# (2) Target ë³€ìˆ˜ë¥¼ ì¢…ì† ë³€ìˆ˜ë¡œ í•˜ì—¬ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ë§ì„ ì§„í–‰í–ˆì„ ë•Œ v2 ì»¬ëŸ¼ì˜ íšŒê·€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "\n",
    "x = df.drop('Target', axis=1)   # ë…ë¦½ ë³€ìˆ˜\n",
    "x = sm.add_constant(x)   # ìƒìˆ˜í•­ ì¶”ê°€\n",
    "y = df['Target']   # ì¢…ì† ë³€ìˆ˜\n",
    "\n",
    "## OLSëŠ” \"Ordinary Least Squares\"ì˜ ì•½ìë¡œ, ì„ í˜• íšŒê·€ ë¶„ì„ ë°©ë²• ì¤‘ í•˜ë‚˜ì´ë‹¤. statsmodels.apiì˜ ì¼ë¶€ë¡œì„œ, OLS í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤.\n",
    "md = sm.OLS(y, x).fit()\n",
    "summary = md.summary()\n",
    "print(summary)\n",
    "\n",
    "answer2 = md.params['v2']\n",
    "print(answer2)\n",
    "\n",
    "# (3) íšŒê·€ ê³„ìˆ˜ë“¤ì´ ê°€ì§€ëŠ” p-ê°’ë“¤ ì¤‘ ìµœëŒ€ê°’ êµ¬í•˜ê¸°\n",
    "answer3 = md.pvalues.max()\n",
    "print(answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì¶œ ë³€í˜• ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              v1        v2        v3        v4        v5    Target\n",
      "v1      1.000000 -0.066107 -0.036512  0.021895 -0.005389  0.872265\n",
      "v2     -0.066107  1.000000 -0.124047 -0.061987 -0.114401 -0.383313\n",
      "v3     -0.036512 -0.124047  1.000000 -0.115117  0.062719  0.310146\n",
      "v4      0.021895 -0.061987 -0.115117  1.000000  0.033356 -0.011590\n",
      "v5     -0.005389 -0.114401  0.062719  0.033356  1.000000  0.036221\n",
      "Target  0.872265 -0.383313  0.310146 -0.011590  0.036221  1.000000\n",
      "(1) ì„ í˜• ê´€ê³„ ê°€ì¥ í° ë³€ìˆ˜ì˜ ìƒê´€ ê³„ìˆ˜: 0.8723\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.960\n",
      "Model:                            OLS   Adj. R-squared:                  0.957\n",
      "Method:                 Least Squares   F-statistic:                     447.0\n",
      "Date:                Sat, 16 Nov 2024   Prob (F-statistic):           7.20e-64\n",
      "Time:                        19:52:55   Log-Likelihood:                -443.47\n",
      "No. Observations:                 100   AIC:                             898.9\n",
      "Df Residuals:                      94   BIC:                             914.6\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2852      9.174      0.358      0.721     -14.929      21.500\n",
      "v1             3.0453      0.073     41.575      0.000       2.900       3.191\n",
      "v2            -2.1320      0.155    -13.754      0.000      -2.440      -1.824\n",
      "v3             0.5132      0.036     14.452      0.000       0.443       0.584\n",
      "v4            -0.0582      0.093     -0.624      0.534      -0.244       0.127\n",
      "v5            -0.3720      0.705     -0.528      0.599      -1.771       1.027\n",
      "==============================================================================\n",
      "Omnibus:                        2.625   Durbin-Watson:                   1.810\n",
      "Prob(Omnibus):                  0.269   Jarque-Bera (JB):                2.212\n",
      "Skew:                          -0.361   Prob(JB):                        0.331\n",
      "Kurtosis:                       3.101   Cond. No.                         577.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(2) v2 ë³€ìˆ˜ì˜ íšŒê·€ ê³„ìˆ˜: -2.1320\n",
      "(3) íšŒê·€ ê³„ìˆ˜ì˜ p-ê°’ ì¤‘ ìµœëŒ€ê°’: 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kss34\\AppData\\Local\\Temp\\ipykernel_8816\\3716619668.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  most_correlated_variable = target_corr.sort_values(ascending=False)[1]  # 'Target' ì œì™¸í•œ ê°€ì¥ ë†’ì€ ìƒê´€ ë³€ìˆ˜\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ê°€ìƒ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(0)  # ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ì„¤ì •\n",
    "n_samples = 100\n",
    "\n",
    "# ë…ë¦½ ë³€ìˆ˜(v1 ~ v5) ë° ì¢…ì† ë³€ìˆ˜(Target) ìƒì„±\n",
    "data = {\n",
    "    'v1': np.random.rand(n_samples) * 100,\n",
    "    'v2': np.random.rand(n_samples) * 50,\n",
    "    'v3': np.random.rand(n_samples) * 200,\n",
    "    'v4': np.random.rand(n_samples) * 80,\n",
    "    'v5': np.random.rand(n_samples) * 10,\n",
    "}\n",
    "\n",
    "# Target ë³€ìˆ˜ëŠ” v1, v2, v3ì— ì˜í–¥ì„ ë°›ë„ë¡ ìƒì„±\n",
    "data['Target'] = (\n",
    "    3 * data['v1'] - 2 * data['v2'] + 0.5 * data['v3'] +\n",
    "    np.random.randn(n_samples) * 20  # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    ")\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# (1) ì„ í˜• ê´€ê³„ ê°€ì¥ í° ë³€ìˆ˜ ì°¾ì•„ ìƒê´€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "corr_df = df.corr()\n",
    "print(corr_df)\n",
    "\n",
    "target_corr = corr_df['Target']\n",
    "most_correlated_variable = target_corr.sort_values(ascending=False)[1]  # 'Target' ì œì™¸í•œ ê°€ì¥ ë†’ì€ ìƒê´€ ë³€ìˆ˜\n",
    "\n",
    "print(f\"(1) ì„ í˜• ê´€ê³„ ê°€ì¥ í° ë³€ìˆ˜ì˜ ìƒê´€ ê³„ìˆ˜: {most_correlated_variable:.4f}\")\n",
    "\n",
    "# (2) Target ë³€ìˆ˜ë¥¼ ì¢…ì† ë³€ìˆ˜ë¡œ í•˜ì—¬ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ë§ì„ ì§„í–‰í–ˆì„ ë•Œ v2 ì»¬ëŸ¼ì˜ íšŒê·€ ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "x = df.drop('Target', axis=1)\n",
    "x = sm.add_constant(x)  # ìƒìˆ˜í•­ ì¶”ê°€\n",
    "y = df['Target']\n",
    "\n",
    "# ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ë¶„ì„ ëª¨ë¸ ìƒì„±\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "v2_coef = model.params['v2']\n",
    "print(f\"(2) v2 ë³€ìˆ˜ì˜ íšŒê·€ ê³„ìˆ˜: {v2_coef:.4f}\")\n",
    "\n",
    "# (3) íšŒê·€ ê³„ìˆ˜ë“¤ì´ ê°€ì§€ëŠ” p-ê°’ë“¤ ì¤‘ ìµœëŒ€ê°’ êµ¬í•˜ê¸°\n",
    "max_pvalue = model.pvalues.max()\n",
    "print(f\"(3) íšŒê·€ ê³„ìˆ˜ì˜ p-ê°’ ì¤‘ ìµœëŒ€ê°’: {max_pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 4 (23ë…„ 7íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì‹¬ì¥ë³‘ ë°œë³‘ ì˜ˆì¸¡\n",
    "- ì¢…ì† ë³€ìˆ˜ : `target 1` (ë°œë³‘)\n",
    "- train ë°ì´í„°ëŠ” ì•ì˜ 210ê°œ í–‰ì„, test ë°ì´í„°ëŠ” ë‚˜ë¨¸ì§€ ë¶€ë¶„ì„ ì‚¬ìš©\n",
    "\n",
    "> (1) train ë°ì´í„°ë¡œ `target`ì„ ì¢…ì† ë³€ìˆ˜ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì§„í–‰í•  ë•Œ, `age` ì»¬ëŸ¼ì˜ ì˜¤ì¦ˆë¹„ êµ¬í•˜ê¸°\n",
    "\n",
    "> (2) train ë°ì´í„°ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì§„í–‰í–ˆì„ ê²½ìš° ì”ì°¨ ì´íƒˆë„(Residual Deviance) ê³„ì‚°í•˜ê¸°\n",
    "\n",
    "> (3) train ë°ì´í„°ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì§„í–‰í–ˆì„ ê²½ìš° ë¡œì§“ ìš°ë„ê°’ ë„ì¶œí•˜ê¸°\n",
    "\n",
    "> (4) test ë°ì´í„°ì˜ ë…ë¦½ ë³€ìˆ˜ë¡œ `target` ì˜ˆì¸¡ í›„ ì˜¤ë¥˜ìœ¨ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343347\n",
      "         Iterations 7\n",
      "0.9562078844664191\n",
      "144.205620063278\n",
      "-72.102810031639\n",
      "0.1954022988505747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('./datasets/P230706.csv')\n",
    "\n",
    "train_data = df[:210].reset_index(drop=True)\n",
    "test_data = df[210:].reset_index(drop=True)\n",
    "\n",
    "# (1) train ë°ì´í„°ë¡œ targetì„ ì¢…ì† ë³€ìˆ˜ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì§„í–‰í•  ë•Œ, age ì»¬ëŸ¼ì˜ ì˜¤ì¦ˆë¹„ êµ¬í•˜ê¸°\n",
    "x = train_data.drop('target', axis=1)   # ë…ë¦½ ë³€ìˆ˜\n",
    "y = train_data['target']   # ì¢…ì† ë³€ìˆ˜\n",
    "\n",
    "model1 = sm.Logit(y, x).fit()\n",
    "\n",
    "answer1 = np.exp(model1.params['age'])\n",
    "print(answer1)\n",
    "\n",
    "# (2) train ë°ì´í„°ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì§„í–‰í–ˆì„ ê²½ìš° ì”ì°¨ ì´íƒˆë„ ê³„ì‚°í•˜ê¸°\n",
    "model2 = sm.GLM(y, x, family=sm.families.Binomial()).fit()\n",
    "\n",
    "answer2 = model2.deviance\n",
    "print(answer2)\n",
    "\n",
    "# (3) train ë°ì´í„°ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì§„í–‰í–ˆì„ ê²½ìš° ë¡œì§“ ìš°ë„ê°’ ë„ì¶œí•˜ê¸°\n",
    "answer3 = model1.llf\n",
    "print(answer3)\n",
    "\n",
    "# (4) test ë°ì´í„°ì˜ ë…ë¦½ë³€ìˆ˜ë¡œ target ì˜ˆì¸¡ í›„ ì˜¤ë¥˜ìœ¨ êµ¬í•˜ê¸°\n",
    "data = test_data.drop('target', axis=1)\n",
    "pred = model1.predict(data)\n",
    "\n",
    "pred = (pred > 0.5).astype('int')\n",
    "target = test_data['target']\n",
    "answer3 = 1 - accuracy_score(target, pred)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì¶œ ë³€í˜• ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.676137\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      194\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sat, 16 Nov 2024   Pseudo R-squ.:                0.003669\n",
      "Time:                        21:15:27   Log-Likelihood:                -135.23\n",
      "converged:                       True   LL-Null:                       -135.73\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9629\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9495      1.424     -0.667      0.505      -3.740       1.841\n",
      "age            0.0011      0.010      0.107      0.915      -0.019       0.021\n",
      "chol           0.0012      0.003      0.370      0.712      -0.005       0.008\n",
      "trestbps       0.0029      0.006      0.470      0.638      -0.009       0.015\n",
      "thalach       -0.0019      0.005     -0.376      0.707      -0.012       0.008\n",
      "oldpeak        0.0549      0.102      0.537      0.591      -0.145       0.255\n",
      "==============================================================================\n",
      "(1) ì˜¤ì¦ˆë¹„ (age): 1.001112327790342\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  200\n",
      "Model:                            GLM   Df Residuals:                      194\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -135.23\n",
      "Date:                Sat, 16 Nov 2024   Deviance:                       270.45\n",
      "Time:                        21:15:27   Pearson chi2:                     200.\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.004967\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9495      1.424     -0.667      0.505      -3.740       1.841\n",
      "age            0.0011      0.010      0.107      0.915      -0.019       0.021\n",
      "chol           0.0012      0.003      0.370      0.712      -0.005       0.008\n",
      "trestbps       0.0029      0.006      0.470      0.638      -0.009       0.015\n",
      "thalach       -0.0019      0.005     -0.376      0.707      -0.012       0.008\n",
      "oldpeak        0.0549      0.102      0.537      0.591      -0.145       0.255\n",
      "==============================================================================\n",
      "(2) ì”ì°¨ ì´íƒˆë„: 270.45483621802725\n",
      "(3) ë¡œì§“ ìš°ë„ê°’: -135.22741810901363\n",
      "(4) ì˜¤ë¥˜ìœ¨: 0.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ê°€ìƒì˜ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 300\n",
    "data = {\n",
    "    'age': np.random.randint(30, 80, n_samples),               # ë‚˜ì´ (30~80ì„¸)\n",
    "    'chol': np.random.randint(150, 300, n_samples),            # ì½œë ˆìŠ¤í…Œë¡¤ ìˆ˜ì¹˜ (150~300)\n",
    "    'trestbps': np.random.randint(100, 180, n_samples),        # ì•ˆì • ì‹œ í˜ˆì•• (100~180)\n",
    "    'thalach': np.random.randint(100, 200, n_samples),         # ìµœëŒ€ ì‹¬ë°•ìˆ˜ (100~200)\n",
    "    'oldpeak': np.random.uniform(0, 5, n_samples),             # ST depression induced by exercise\n",
    "    'target': np.random.binomial(1, 0.4, n_samples)            # ì‹¬ì¥ë³‘ ë°œë³‘ ì—¬ë¶€ (0 ë˜ëŠ” 1, 40% í™•ë¥ )\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# train/test ë°ì´í„° ë¶„í• \n",
    "train_data = df[:200].reset_index(drop=True)\n",
    "test_data = df[200:].reset_index(drop=True)\n",
    "\n",
    "# [1] train ë°ì´í„°ë¡œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ì„ ìˆ˜í–‰\n",
    "X = train_data.drop('target', axis=1)   # ë…ë¦½ ë³€ìˆ˜\n",
    "X = sm.add_constant(X)                  # ìƒìˆ˜í•­ ì¶”ê°€\n",
    "y = train_data['target']               # ì¢…ì† ë³€ìˆ˜\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„±\n",
    "model1 = sm.Logit(y, X).fit()\n",
    "\n",
    "summary1 = model1.summary()\n",
    "print(summary1)\n",
    "\n",
    "# (1) ì˜¤ì¦ˆë¹„ ê³„ì‚° (age)|\n",
    "answer1 = np.exp(model1.params['age'])\n",
    "print(\"(1) ì˜¤ì¦ˆë¹„ (age):\", answer1)\n",
    "\n",
    "# (2) ì”ì°¨ ì´íƒˆë„ ê³„ì‚°\n",
    "model2 = sm.GLM(y, X, family=sm.families.Binomial()).fit()    # GLM(Generalized Linear Models) ëª¨ë¸ë§, Bionomial : ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "\n",
    "summary2 = model2.summary()\n",
    "print(summary2)\n",
    "\n",
    "answer2 = model2.deviance\n",
    "print(\"(2) ì”ì°¨ ì´íƒˆë„:\", answer2)\n",
    "\n",
    "# (3) ë¡œì§“ ìš°ë„ê°’(Log-Likelihood) ê³„ì‚°\n",
    "answer3 = model1.llf\n",
    "print(\"(3) ë¡œì§“ ìš°ë„ê°’:\", answer3)\n",
    "\n",
    "# (4) test ë°ì´í„°ë¡œ target ì˜ˆì¸¡ í›„ ì˜¤ë¥˜ìœ¨(Error Rate) ê³„ì‚°\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "X_test = sm.add_constant(X_test)    # ìƒìˆ˜í•­ ì¶”ê°€\n",
    "y_test = test_data['target']\n",
    "\n",
    "pred = model1.predict(X_test)\n",
    "\n",
    "## ë°©ë²• 1 (1 - Accuracy êµ¬í•˜ê¸°)\n",
    "pred = (pred > 0.5).astype(int)    # ì˜ˆì¸¡ëœ í™•ë¥ ê°’ì„ 0.5 ê¸°ì¤€ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜í•˜ì—¬ ë³€í™˜ (0.5 ì´ˆê³¼ : 1, 0.5 ì´í•˜ : 0)\n",
    "\n",
    "error_rate = 1 - accuracy_score(y_test, pred)   # Error Rate = 1 - Accuracy\n",
    "# print(\"(4) ì˜¤ë¥˜ìœ¨:\", error_rate)\n",
    "\n",
    "## ë°©ë²• 2 (í˜¼ë™ í–‰ë ¬ ì´ìš©í•˜ê¸°)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "# ì˜¤ë¥˜ìœ¨ ê³„ì‚°\n",
    "error_rate = (cm[0, 1] + cm[1, 0]) / cm.sum()   # ì˜¤ì°¨ í–‰ë ¬ì—ì„œ ì˜¤ë‹µì˜ í•©ì„ ì „ì²´ë¡œ ë‚˜ëˆ„ê¸°\n",
    "print(\"(4) ì˜¤ë¥˜ìœ¨:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 5 (24ë…„ 8íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì ìš©í•˜ì—¬ ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì˜ ê°œìˆ˜ êµ¬í•˜ê¸°\n",
    "    - ìƒìˆ˜í•­ì„ ì¶”ê°€í•´ì•¼ í•œë‹¤.\n",
    "    - ì¢…ì† ë³€ìˆ˜ : ê³ ê°ì´íƒˆì§€ìˆ˜\n",
    "\n",
    "> statsmodels ë°©ì‹ìœ¼ë¡œ í’€ì–´ì„œ 0.05ë³´ë‹¤ í° ê°’ì„ ê³ ë¥´ë©´ ë˜ëŠ” ë¬¸ì œì˜€ìŠµë‹ˆë‹¤. íšŒê·€ì‹ì—ì„œëŠ” ê·€ë¬´ê°€ì„¤:íšŒê·€ì‹ì˜ í•´ë‹¹ ë³€ìˆ˜ê°€ ì˜í–¥ë ¥ì´ ì—†ë‹¤ vs ëŒ€ë¦½ê°€ì„¤:íšŒê·€ì‹ì˜ í•´ë‹¹ë³€ìˆ˜ê°€ ì˜í–¥ë ¥ì´ ìˆë‹¤ ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ 0.05 ë³´ë‹¤ ì‘ìœ¼ë©´ ëŒ€ë¦½ê°€ì„¤ ì±„íƒ, 0.05ë³´ë‹¤ í¬ë©´ ê·€ë¬´ê°€ì„¤ ì±„íƒ(=í•´ë‹¹ ë³€ìˆ˜ê°€ ì˜í–¥ë ¥ì´ ì—†ë‹¤=ìœ ì˜í•˜ì§€ ì•Šë‹¤) ì…ë‹ˆë‹¤.\n",
    "\n",
    "- (2) ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë§Œì„ ë…ë¦½ ë³€ìˆ˜ë¡œ í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ ë‹¤ì‹œ ì ìš©í•œ í›„, íšŒê·€ ê³„ìˆ˜ì˜ í‰ê·  êµ¬í•˜ê¸°\n",
    "\n",
    "> ë‹¤ì‹œ ìƒê°ë‚¬ëŠ”ë° íšŒê·€ê³„ìˆ˜ í‰ê· ì„ êµ¬í• ë•Œ ì €ëŠ” ìƒìˆ˜í•­ì„ ë¹¼ê³  êµ¬í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤ b1+b2+b3 ì˜ í‰ê· . ê·¼ë° bo+b1+b2+b3 ê¹Œì§€ í•´ì„œ êµ¬í•´ì•¼ í•´ì„œ -0.456ì´ ë§ì„ ê²ë‹ˆë‹¤\n",
    "\n",
    "- (3) (2)ì—ì„œ ì ìš©í•œ íšŒê·€ì‹ì—ì„œ calls ë³€ìˆ˜ê°€ 5ì¦ê°€í•˜ë©´ ì˜¤ì¦ˆë¹„ëŠ” ëª‡ë°° ì¦ê°€í•˜ëŠ”ê°€?\n",
    "\n",
    "> ```text \n",
    "> np.exp(5*call ë³€ìˆ˜ì˜ íšŒê·€ê³„ìˆ˜ ê°’) =7.919= ì •ë‹µ\n",
    "> 5 * np.exp(call ë³€ìˆ˜ì˜ íšŒê·€ê³„ìˆ˜ê°’) =7.563= ì˜¤ë‹µ\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "x = df.drop(columns=['ì´íƒˆì§€ìˆ˜'])\n",
    "y = df['ì´íƒˆì§€ìˆ˜']\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜• ì í•©\n",
    "x = sm.add_constant(x)\n",
    "model = sm.Logit(y, x).fit()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ageì˜ weight ì˜¤ì¦ˆë¹„ ê³„ì‚°\n",
    "odds_ratios = np.exp((model.params['calls']) * 5)\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì¶œ ë³€í˜• ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630233\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  churn   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       96\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 16 Nov 2024   Pseudo R-squ.:                 0.09077\n",
      "Time:                        09:45:55   Log-Likelihood:                -63.023\n",
      "converged:                       True   LL-Null:                       -69.315\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.005632\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2608      1.060      3.075      0.002       1.182       5.339\n",
      "age           -0.0345      0.019     -1.792      0.073      -0.072       0.003\n",
      "salary     -1.611e-05   8.89e-06     -1.812      0.070   -3.35e-05    1.32e-06\n",
      "calls         -0.0301      0.015     -2.026      0.043      -0.059      -0.001\n",
      "==============================================================================\n",
      "ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì˜ ê°œìˆ˜: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669250\n",
      "         Iterations 4\n",
      "ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë“¤ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜ í‰ê· : 0.35029495471365896\n",
      "calls ë³€ìˆ˜ê°€ 5 ì¦ê°€í•˜ë©´ ì˜¤ì¦ˆë¹„ëŠ” 0.8589494047822301ë°° ì¦ê°€í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ì˜ˆì‹œ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(23123123)\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 60, 100),\n",
    "    'salary': np.random.randint(30000, 120000, 100),\n",
    "    'calls': np.random.randint(0, 50, 100),\n",
    "    'churn': np.random.randint(0, 2, 100)  # ê³ ê°ì´íƒˆì§€ìˆ˜ (ì¢…ì†ë³€ìˆ˜)\n",
    "})\n",
    "\n",
    "# (1) ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ ê°œìˆ˜ êµ¬í•˜ê¸°\n",
    "\n",
    "# ìƒìˆ˜í•­ ì¶”ê°€\n",
    "X = data[['age', 'salary', 'calls']]\n",
    "X = sm.add_constant(X)  # ìƒìˆ˜í•­ ì¶”ê°€\n",
    "y = data['churn']\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ì í•©\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "summary = result.summary()\n",
    "print(summary)\n",
    "\n",
    "# p-value í™•ì¸\n",
    "p_values = result.pvalues\n",
    "\n",
    "# ìœ ì˜ë¯¸í•˜ì§€ ì•Šì€ ë³€ìˆ˜ (p-value > 0.05)\n",
    "insignificant_vars = p_values[p_values > 0.05]\n",
    "print(f\"ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì˜ ê°œìˆ˜: {len(insignificant_vars)}\")\n",
    "\n",
    "# (2) ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë§Œì„ ë…ë¦½ ë³€ìˆ˜ë¡œ í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ë‹¤ì‹œ ì ìš©í•˜ê³  íšŒê·€ ê³„ìˆ˜ì˜ í‰ê·  êµ¬í•˜ê¸°\n",
    "significant_vars = p_values[p_values <= 0.05].index  # ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ ì¶”ì¶œ (p-value <= ìœ ì˜ìˆ˜ì¤€)\n",
    "\n",
    "# ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "if len(significant_vars) > 0:\n",
    "    X_significant = X[significant_vars]\n",
    "    logit_model_significant = sm.Logit(y, X_significant)\n",
    "    result_significant = logit_model_significant.fit()\n",
    "\n",
    "    # íšŒê·€ ê³„ìˆ˜ì˜ í‰ê·  êµ¬í•˜ê¸°\n",
    "    coefficients = result_significant.params\n",
    "    mean_coefficient = coefficients.mean()\n",
    "    print(f\"ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë“¤ì— ëŒ€í•œ íšŒê·€ ê³„ìˆ˜ í‰ê· : {mean_coefficient}\")\n",
    "else:\n",
    "    print(\"ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# (3) 'calls' ë³€ìˆ˜ê°€ 5 ì¦ê°€í•  ë•Œ ì˜¤ì¦ˆë¹„ ì¦ê°€ ë°°ìˆ˜ ê³„ì‚°\n",
    "if 'calls' in significant_vars:\n",
    "    call_coeff = result_significant.params['calls']\n",
    "    odds_ratio_increase = np.exp(5 * call_coeff)\n",
    "    print(f\"calls ë³€ìˆ˜ê°€ 5 ì¦ê°€í•˜ë©´ ì˜¤ì¦ˆë¹„ëŠ” {odds_ratio_increase}ë°° ì¦ê°€í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"'calls' ë³€ìˆ˜ëŠ” ìœ ì˜ë¯¸í•˜ì§€ ì•Šê±°ë‚˜ ëª¨ë¸ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 6 (24ë…„ 8íšŒ ê¸°ì¶œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) ë‹¤ì¤‘ì„ í˜• íšŒê·€ë¥¼ ì ìš©í•˜ì—¬ ê°€ì¥ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ íšŒê·€ê³„ìˆ˜ë¥¼ ì“°ì‹œì˜¤\n",
    "    - ì¢…ì† ë³€ìˆ˜ : `piq`\n",
    "    - ë…ë¦½ ë³€ìˆ˜ : `brain`. `height`, `weight`\n",
    "- (2) ê²°ì • ê³„ìˆ˜ ê°’ êµ¬í•˜ê¸°\n",
    "- (3) ìœ„ì—ì„œ ì í•©í•˜ì—¬ ë‚˜ì˜¨ ë‹¤ì¤‘ì„ í˜•íšŒê·€ì‹ì—ì„œ í‚¤:70, ëª¸ë¬´ê²Œ:150, ë‡Œí¬ê¸°:90 ì¼ë•Œì˜ piq ê°’ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# (1) ìœ ì˜ë¯¸í•œ íšŒê·€ ê³„ìˆ˜ ì“°ê¸°\n",
    "x = df.drop(columns=['PIQ'])\n",
    "y = df['PIQ']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "# 2.129\n",
    "# brainì˜ íšŒê·€ê³„ìˆ˜ì˜ p-valueê°’ì´ ê°€ì¥ ì‘ì•˜ë‹¤. \n",
    "# p-value > 0.5ì´ë©´ ê·€ë¬´ê°€ì„¤ ê¸°ê°, ëŒ€ë¦½ê°€ì„¤ ì±„íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) ê²°ì • ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "## ìƒìˆ˜í•¨ í¬í•¨í•´ì„œ ê²°ì •ê³„ìˆ˜ êµ¬í•œë‹¤.\n",
    "r_squared = model.rsquared\n",
    "print(r_squared)\n",
    "\n",
    "# 0.313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) PIQ ê°’ êµ¬í•˜ê¸°\n",
    "PIQ = (brain * 90) + (height * 70) + (weight * 150)\n",
    "\n",
    "# 104.873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ì¶œ ë³€í˜• ë¬¸ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íšŒê·€ ê²°ê³¼ ìš”ì•½:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            house_price   R-squared:                       0.047\n",
      "Model:                            OLS   Adj. R-squared:                  0.017\n",
      "Method:                 Least Squares   F-statistic:                     1.574\n",
      "Date:                Fri, 15 Nov 2024   Prob (F-statistic):              0.201\n",
      "Time:                        02:03:29   Log-Likelihood:                -1377.9\n",
      "No. Observations:                 100   AIC:                             2764.\n",
      "Df Residuals:                      96   BIC:                             2774.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       7.002e+05   8.77e+04      7.988      0.000    5.26e+05    8.74e+05\n",
      "size        -676.8792    319.354     -2.120      0.037   -1310.792     -42.967\n",
      "location   -3044.8104   8910.179     -0.342      0.733   -2.07e+04    1.46e+04\n",
      "age          216.6799   1701.382      0.127      0.899   -3160.536    3593.895\n",
      "==============================================================================\n",
      "Omnibus:                        9.060   Durbin-Watson:                   2.075\n",
      "Prob(Omnibus):                  0.011   Jarque-Bera (JB):                3.390\n",
      "Skew:                           0.038   Prob(JB):                        0.184\n",
      "Kurtosis:                       2.101   Cond. No.                         703.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "ê²°ì • ê³„ìˆ˜ (R-squared): 0.046868286704138895\n",
      "ì˜ˆì¸¡ëœ house_price: 551755.6794774851\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# ì˜ˆì‹œ ë°ì´í„° ìƒì„±\n",
    "np.random.seed(123123)\n",
    "data = pd.DataFrame({\n",
    "    'size': np.random.randint(50, 300, 100),  # ì£¼íƒ í¬ê¸° (í‰ìˆ˜)\n",
    "    'location': np.random.randint(1, 10, 100),  # ìœ„ì¹˜ (1~10)\n",
    "    'age': np.random.randint(1, 50, 100),  # ë‚˜ì´ (ë…„)\n",
    "    'house_price': np.random.randint(100000, 1000000, 100)  # ì£¼íƒ ê°€ê²©\n",
    "})\n",
    "\n",
    "# (1) ë‹¤ì¤‘ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ê°€ì¥ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ì˜ íšŒê·€ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "x = data[['size', 'location', 'age']]\n",
    "y = data['house_price']\n",
    "\n",
    "# ìƒìˆ˜í•­ ì¶”ê°€\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# ë‹¤ì¤‘ì„ í˜• íšŒê·€ ëª¨ë¸ ì í•©\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# íšŒê·€ ê²°ê³¼ ì¶œë ¥\n",
    "summary = model.summary()\n",
    "print(\"íšŒê·€ ê²°ê³¼ ìš”ì•½:\")\n",
    "print(summary)\n",
    "\n",
    "# (2) ê²°ì • ê³„ìˆ˜ êµ¬í•˜ê¸°\n",
    "r_squared = model.rsquared\n",
    "print(f\"ê²°ì • ê³„ìˆ˜ (R-squared): {r_squared}\")\n",
    "\n",
    "# (3) size=200, location=5, age=10 ì¼ ë•Œ house_price ê°’ ì˜ˆì¸¡\n",
    "predicted_price = model.predict([1, 200, 5, 10])  # ìƒìˆ˜í•­ì„ í¬í•¨í•˜ì—¬ ì˜ˆì¸¡\n",
    "print(f\"ì˜ˆì¸¡ëœ house_price: {predicted_price[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1) ë‹¤ì¤‘ì„ í˜• íšŒê·€ë¥¼ ì í•©í•œ í›„, summary()ë¥¼ í†µí•´ íšŒê·€ ê³„ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. size ë³€ìˆ˜ì˜ p-valueê°€ ìœ ì˜ìˆ˜ì¤€(0.05)ë³´ë‹¤ í¬ë¯€ë¡œ, ê·€ë¬´ê°€ì„¤(í•´ë‹¹ ë³€ìˆ˜ëŠ” ì¢…ì† ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤)ë¥¼ ê¸°ê°í•˜ê²Œ ëœë‹¤. ë”°ë¼ì„œ ê°€ì¥ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ëŠ” sizeì´ë©°, ì´ë•Œ íšŒê·€ ê³„ìˆ˜ëŠ” -676.8792ì´ë‹¤.\n",
    ">\n",
    "> (2) model.rsquaredë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ì • ê³„ìˆ˜ ê°’ì„ êµ¬í•©ë‹ˆë‹¤.\n",
    ">\n",
    "> (3) ì˜ˆì¸¡ëœ house_price ê°’ì„ êµ¬í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. model.predict()ì— ìƒìˆ˜í•­ì„ í¬í•¨í•œ ê°’ì„ ë„£ì–´ì„œ ì˜ˆì¸¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 7 (ì‹œí—˜ì¥ í™˜ê²½ ì²´í—˜ ì˜ˆì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- íƒ€ì´íƒ€ë‹‰í˜¸ì˜ ì¹¨ëª° ì‚¬ê±´ì—ì„œ ìƒì¡´í•œ ìŠ¹ê° ë° ì‚¬ë§í•œ ìŠ¹ê°ì˜ ì •ë³´ë¥¼ ë‹´ì€ ë°ì´í„°\n",
    "- ìƒì¡´ ì—¬ë¶€(`Survibed`) ì˜ˆì¸¡\n",
    "\n",
    "> (1) `Gender`ì™€ `Survived` ë³€ìˆ˜ ê°„ì˜ ë…ë¦½ì„± ê²€ì •ì„ ì‹¤ì‹œí•˜ì˜€ì„ ë•Œ, ì¹´ì´ì œê³± í†µê³„ëŸ‰ êµ¬í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)\n",
    "\n",
    "> (2) `Gender`, `SibSp`, `Parch`, `Fare`ë¥¼ ë…ë¦½ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨í˜•ì„ ì‹¤ì‹œí•˜ì˜€ì„ ë•Œ, `Parch` ë³€ìˆ˜ì˜ ê³„ìˆ˜ê°’ êµ¬í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)\n",
    "\n",
    "> (3) (2)ì—ì„œ ì¶”ì •ëœ ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì—ì„œ `SibSp` ë³€ìˆ˜ê°€ í•œ ë‹¨ìœ„ ì¦ê°€í•  ë•Œ ìƒì¡´í•  ì˜¤ì¦ˆë¹„(Odds Ratio) ê°’ êµ¬í•˜ê¸° (ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.717 / p-value 1.1973570627755645e-58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482065\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                          Logit   Df Residuals:                      886\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 17 Jun 2024   Pseudo R-squ.:                  0.2761\n",
      "Time:                        13:44:18   Log-Likelihood:                -429.52\n",
      "converged:                       True   LL-Null:                       -593.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.192e-69\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.9466      0.169      5.590      0.000       0.615       1.279\n",
      "Gender[T.male]    -2.6422      0.186    -14.197      0.000      -3.007      -2.277\n",
      "SibSp             -0.3539      0.098     -3.604      0.000      -0.546      -0.161\n",
      "Parch             -0.2007      0.112     -1.792      0.073      -0.420       0.019\n",
      "Fare               0.0147      0.003      5.553      0.000       0.010       0.020\n",
      "==================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482065\n",
      "         Iterations 6\n",
      "Intercept         0.946635\n",
      "Gender[T.male]   -2.642219\n",
      "SibSp            -0.353892\n",
      "Parch            -0.200724\n",
      "Fare              0.014685\n",
      "dtype: float64\n",
      "0.702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import *\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "df = pd.read_csv('./datasets/titanic.csv')\n",
    "\n",
    "# (1) Genderì™€ Survived ë³€ìˆ˜ ê°„ì˜ ë…ë¦½ì„± ê²€ì •ì„ ì‹¤ì‹œí•˜ì˜€ì„ ë•Œ, ì¹´ì´ì œê³± í†µê³„ëŸ‰ êµ¬í•˜ê¸°\n",
    "table =pd.crosstab(df['Gender'], df['Survived'])\n",
    "chi2, pvalue, dof, exp = chi2_contingency(table)   # ë…ë¦½ì„± ê²€ì •\n",
    "answer1 = round(chi2, 3)\n",
    "print(answer1, \"/ p-value\", pvalue)   # ìœ ì˜ ìˆ˜ì¤€(0.5)ë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ ëŒ€ë¦½ê°€ì„¤ ì±„íƒ (ì„œë¡œ ë…ë¦½)\n",
    "\n",
    "# (2) Gender, SibSp, Parch, Fareë¥¼ ë…ë¦½ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨í˜•ì„ ì‹¤ì‹œí•˜ì˜€ì„ ë•Œ, Parch ë³€ìˆ˜ì˜ ê³„ìˆ˜ê°’ êµ¬í•˜ê¸°\n",
    "answer2 = logit('Survived ~ Gender+SibSp+Parch+Fare', data=df).fit().summary()\n",
    "print(answer2)   # Parch ë³€ìˆ˜ì˜ coef ê°’ í™•ì¸ (-0.2007)\n",
    "\n",
    "# (3) SibSp ë³€ìˆ˜ê°€ í•œ ë‹¨ìœ„ ì¦ê°€í•  ë•Œ ìƒì¡´í•  ì˜¤ì¦ˆë¹„ ê°’ êµ¬í•˜ê¸°\n",
    "result = logit('Survived ~ Gender+SibSp+Parch+Fare', data=df).fit().params\n",
    "print(result)\n",
    "answer3 = round(np.exp(result['SibSp']), 3)\n",
    "print(answer3)   # 0.702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 8 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5ëª…ì˜ í™˜ìë¥¼ ëŒ€ìƒìœ¼ë¡œ ì¹˜ë£Œì œë¥¼ ë³µìš©í•˜ê¸° ì „ê³¼ í›„ì˜ í˜ˆì••ì„ ì¸¡ì •í•˜ì˜€ë‹¤.\n",
    "- ì¹˜ë£Œì œê°€ íš¨ê³¼ê°€ ìˆëŠ”ì§€ ìŒì²´ í‘œë³¸ T-ê²€ì •ì„ í†µí•´ ë‹µí•˜ê³ ì í•œë‹¤.\n",
    "    - ë‹¨, í‘œë³¸ì´ ì •ê·œì„±ì„ ë§Œì¡±í•œë‹¤ëŠ” ê°€ì •í•˜ì— ë‹¨ì¸¡ ê²€ì • ìˆ˜í–‰\n",
    "\n",
    "```text\n",
    "Î¼d : (ì¹˜ë£Œ í›„ í˜ˆì•• - ì¹˜ë£Œ ì „ í˜ˆì••)ì˜ í‰ê· \n",
    "H0 : Î¼d â‰¥ 0 (ì¹˜ë£Œ í›„ í˜ˆì••ê³¼ ì¹˜ë£Œ ì „ í˜ˆì••ì˜ ì°¨ì´ì— ëŒ€í•œ í‰ê· ì€ 0ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ë‹¤.)\n",
    "H1 : Î¼d â‰¤ 0 (ì¹˜ë£Œ í›„ì— í˜ˆì••ì´ ë” ë‚®ì•„ì¡Œìœ¼ë¯€ë¡œ ì¹˜ë£Œì œì˜ íš¨ê³¼ê°€ ìˆë‹¤.)\n",
    "```\n",
    "\n",
    "```text\n",
    "ì¹˜ë£Œì œ ë³µìš© ì „ 5ëª…ì˜ í™˜ìë“¤ì˜ í˜ˆì•• : 200, 210, 190, 180, 175\n",
    "ì¹˜ë£Œì œ ë³µìš© í›„ 5ëª…ì˜ í™˜ìë“¤ì˜ í˜ˆì•• : 180, 175, 160, 150, 160\n",
    "\n",
    "```\n",
    "\n",
    "> (1) ìœ„ì˜ ê°€ì„¤ì„ ê²€ì •í•˜ê¸° ìœ„í•œ ê²€ì • í†µê³„ëŸ‰ êµ¬í•˜ê¸° (ì†Œìˆ˜ ë‹¤ì„¯ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)\n",
    "\n",
    "> (2) ìœ„ì˜ í†µê³„ëŸ‰ì— ëŒ€í•œ p-ê°’ êµ¬í•˜ê¸° (ì†Œìˆ˜ ë‹¤ì„¯ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)\n",
    "\n",
    "> (3) ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê°€ì„¤ ê²€ì •ì˜ ê²°ê³¼ë¥¼ (ì±„íƒ/ê¸°ê°) ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=-7.076303701373625, pvalue=0.0010523957839292206, df=4)\n",
      "-7.0763\n",
      "0.00105\n",
      "ê¸°ê°\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'before': [200, 210, 190, 180, 175],\n",
    "    'after': [180, 175, 160, 150, 160]\n",
    "})\n",
    "\n",
    "result = ttest_rel(df['after'], df['before'], alternative='less')   # less : afterì˜ í‰ê· ì´ beforeì˜ í‰ê·  ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ë‹¤.\n",
    "print(result)\n",
    "\n",
    "# (1) ê²€ì • í†µê³„ëŸ‰ êµ¬í•˜ê¸°\n",
    "answer1 = round(result.statistic, 4)\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-ê°’ êµ¬í•˜ê¸°\n",
    "answer2 = round(result.pvalue, 5)\n",
    "print(answer2)\n",
    "\n",
    "# (3) ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê°€ì„¤ ê²€ì •ì˜ ê²°ê³¼ ì¶œë ¥í•˜ê¸°\n",
    "answer3 = 'ê¸°ê°' if answer2 < 0.05 else 'ì±„íƒ'\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 9 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë‰´ìš•ì˜ ê³µê¸° ì˜¤ì—¼ë„ë¥¼ ì¸¡ì •í•œ `airqty` ë°ì´í„°\n",
    "- `Temp` ë°ì´í„°ëŠ” ì˜¨ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "- `airqty` ë°ì´í„°ì—ì„œ ë‹¤ìŒ ê°€ì„¤ì— ëŒ€í•œ í†µê³„ì  ê²€ì • ìˆ˜í–‰í•˜ê¸° (ì–‘ì¸¡ ê²€ì • ìˆ˜í–‰)\n",
    "\n",
    "```text\n",
    "H0 : ë‰´ìš•ì˜ í‰ê·  ì˜¨ë„(Temp ë³€ìˆ˜ ê°’ì˜ í‰ê· )ëŠ” 75ì´ë‹¤.\n",
    "H1 : ë‰´ìš•ì˜ í‰ê·  ì˜¨ë„(Temp ë³€ìˆ˜ ê°’ì˜ í‰ê· )ëŠ” 75ê°€ ì•„ë‹ˆë‹¤.\n",
    "```\n",
    "\n",
    "> (1) ìœ„ì˜ ê°€ì„¤ì„ ê²€ì •í•˜ê¸° ìœ„í•œ ê²€ì • í†µê³„ëŸ‰ êµ¬í•˜ê¸° (ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)\n",
    "\n",
    "> (2) ìœ„ì˜ í†µê³„ëŸ‰ì— ëŒ€í•œ p-ê°’ êµ¬í•˜ê¸° (ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ê³„ì‚°)\n",
    "\n",
    "> (3) ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê°€ì„¤ ê²€ì •ì˜ ê²°ê³¼ë¥¼ (ì±„íƒ/ê¸°ê°) ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9761729640090072, pvalue=0.009319356335949125)\n",
      "WilcoxonResult(statistic=0.0, pvalue=7.24267495195268e-27)\n",
      "0.0\n",
      "0.0\n",
      "ê¸°ê°\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import shapiro, wilcoxon\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-6.csv')\n",
    "\n",
    "# ì •ê·œì„± ê²€ì •\n",
    "result = shapiro(df['Temp'])\n",
    "print(result)   # p-ê°’ì´ ìœ ì˜ìˆ˜ì¤€ 0.05ë³´ë‹¤ ì‘ìœ¼ë¯€ë¡œ ëŒ€ë¦½ê°€ì„¤ ì±„íƒ (ì •ê·œì„± ë§Œì¡± X)\n",
    "\n",
    "# ìœŒì½•ìŠ¨ ê²€ì •\n",
    "result = wilcoxon(df['Temp'], alternative='two-sided', zero_method='wilcox', correction=False)   # ì–‘ì¸¡ ê²€ì •\n",
    "print(result)\n",
    "\n",
    "# (1) ê²€ì • í†µê³„ëŸ‰ êµ¬í•˜ê¸°\n",
    "answer1 = round(result.statistic, 3)\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-ê°’ êµ¬í•˜ê¸°\n",
    "answer2 = round(result.pvalue, 4)\n",
    "print(answer2)\n",
    "\n",
    "# (3) ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê°€ì„¤ ê²€ì •ì˜ ê²°ê³¼ ì¶œë ¥í•˜ê¸°\n",
    "answer3 = 'ê¸°ê°' if answer2 < 0.05 else 'ì±„íƒ'\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 10 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë¬´ì‘ìœ„ë¡œ 100ê°œì˜ ê°’ì„ ìƒì„±í•œ ë‘ ê·¸ë£¹(A, B)ì˜ ë¶„ì‚°ì´ ê°™ì€ì§€ì— ëŒ€í•´ F-ê²€ì • ìˆ˜í–‰í•˜ê¸°\n",
    "    - A ê·¸ë£¹ : 1, 2, 3, 4, 6\n",
    "    - B ê·¸ë£¹ : 4, 5, 6, 7, 8\n",
    "\n",
    "```text\n",
    "H0 : ë‘ ê·¸ë£¹ì˜ ë¶„ì‚°ì€ ê°™ë‹¤.\n",
    "H1 : ë‘ ê·¸ë£¹ì˜ ë¶„ì‚°ì€ ê°™ì§€ ì•Šë‹¤.\n",
    "```\n",
    "\n",
    "> (1) ê²€ì • í†µê³„ëŸ‰ì„ ì†Œìˆ˜ 2ë²ˆì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "> (2) p-ê°’ì„ ì†Œìˆ˜ 4ë²ˆì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "> (3) ìœ ì˜ìˆ˜ì¤€ 0.05ì—ì„œ ê·€ë¬´ê°€ì„¤ì˜ 'ì±„íƒ', 'ê¸°ê°' ì—¬ë¶€ ì¶œë ¥í•˜ê¸°\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n",
      "2.5\n",
      "1.48\n",
      "0.7133\n",
      "ì±„íƒ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "df1 = np.array([1, 2, 3, 4, 6])\n",
    "df2 = np.array([4, 5, 6, 7, 8])\n",
    "\n",
    "print(np.var(df1, ddof=1))   # ë¶„ì‚° êµ¬í•˜ê¸° (í‘œë³¸)\n",
    "print(np.var(df2, ddof=1))   # ë¶„ì‚° êµ¬í•˜ê¸° (í‘œë³¸)\n",
    "\n",
    "# F-ê²€ì • ìˆ˜í–‰í•˜ê¸°\n",
    "def f_test(x, y):\n",
    "    var_x = np.var(x, ddof=1)\n",
    "    var_y = np.var(y, ddof=1)\n",
    "\n",
    "    if var_x < var_y:\n",
    "        var_x, var_y = var_y, var_x\n",
    "    \n",
    "    f_value = var_x / var_y\n",
    "    x_dof = x.size - 1\n",
    "    y_dof = y.size - 1\n",
    "    p_value = round((1 - f.cdf(f_value, x_dof, y_dof)) * 2, 4)   # ì–‘ì¸¡ ê²€ì •\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        result = 'ê¸°ê°'\n",
    "    else:\n",
    "        result = 'ì±„íƒ'\n",
    "    \n",
    "    return f_value, p_value, result\n",
    "\n",
    "\n",
    "result = f_test(df1, df2)\n",
    "\n",
    "# (1) ê²€ì • í†µê³„ëŸ‰ ì¶œë ¥í•˜ê¸°\n",
    "answer1 = result[0]\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-ê°’ ì¶œë ¥í•˜ê¸°\n",
    "answer2 = result[1]\n",
    "print(answer2)\n",
    "\n",
    "# (3) ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê°€ì„¤ ê²€ì •ì˜ ê²°ê³¼ ì¶œë ¥í•˜ê¸°\n",
    "answer3 = result[2]\n",
    "print(answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 11 (ì—°ìŠµ ë¬¸ì œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì½˜ì„œíŠ¸ì¥ì—ì„œ ë‚¨ì„±ì´ 340ëª…, ì—¬ì„±ì´ 540ëª…ì´ ìˆì„ ë•Œ ë‚¨ì„±, ì—¬ì„± ë¹„ìœ¨ì´ 35%ì™€ 65%ì¸ì§€ë¥¼ ì¹´ì´ì œê³± ê²€ì •ì„ ì´ìš©í•˜ì—¬ ë¶„ì„í•˜ëŠ”ë°, ì í•©ë„ ê²€ì • ì‹¤ì‹œí•˜ê¸°\n",
    "\n",
    "```text\n",
    "H0 : ì½˜ì„œíŠ¸ì¥ì—ì„œ ë‚¨ì„±, ì—¬ì„±ì˜ ë¹„ìœ¨ì€ 35%ì™€ 65%\n",
    "H1 : ì½˜ì„œíŠ¸ì¥ì—ì„œ ë‚¨ì„±, ì—¬ì„±ì˜ ë¹„ìœ¨ì€ 35%ì™€ 65%ê°€ ì•„ë‹˜.\n",
    "```\n",
    "\n",
    "> (1) ê²€ì • í†µê³„ëŸ‰ì„ ì†Œìˆ˜ 5ë²ˆì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "> (2) p-ê°’ì„ ì†Œìˆ˜ 5ë²ˆì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ê¸°\n",
    "\n",
    "> (3) ìœ ì˜ìˆ˜ì¤€ 0.05ì—ì„œ ê·€ë¬´ê°€ì„¤ì˜ 'ì±„íƒ', 'ê¸°ê°' ì—¬ë¶€ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=5.114885114885115, pvalue=0.023721436858355486)\n",
      "5.11489\n",
      "0.02372\n",
      "ê¸°ê°\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "num = np.array([340, 540])\n",
    "expected = np.array([0.35, 0.65]) * np.sum(num)\n",
    "\n",
    "result = chisquare(f_obs=num, f_exp=expected)\n",
    "print(result)\n",
    "\n",
    "# (1) ê²€ì • í†µê³„ëŸ‰ êµ¬í•˜ê¸°\n",
    "answer1 = round(result.statistic, 5)\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-ê°’ êµ¬í•˜ê¸°\n",
    "answer2 = round(result.pvalue, 5)\n",
    "print(answer2)\n",
    "\n",
    "# (3) ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê°€ì„¤ ê²€ì • ê²°ê³¼ ì¶œë ¥í•˜ê¸°\n",
    "answer3 = 'ê¸°ê°' if answer2 < 0.05 else 'ì±„íƒ'\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹¨ì¼ í‘œë³¸ T-ê²€ì • (One Sample T-Test)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•œ í•™êµì—ì„œ 10ëª…ì˜ í•™ìƒë“¤ì˜ í‰ê·  í‚¤ê°€ 160cmì¸ì§€ ì•„ë‹Œì§€ ê²€ì •í•˜ë ¤ê³  í•œë‹¤. í•™ìƒë“¤ì˜ í‚¤ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "\n",
    "```text\n",
    "í•™ìƒë“¤ì˜ í‚¤ (cm): [162, 159, 158, 160, 165, 163, 157, 161, 159, 160]\n",
    "```\n",
    "\n",
    "ìœ ì˜ìˆ˜ì¤€ 0.05ì¼ ë•Œ, ì´ í•™ìƒë“¤ì˜ í‰ê·  í‚¤ê°€ 160cmì¸ì§€ ì•„ë‹Œì§€ ê²€ì •í•˜ë¼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ê·œì„± ë§Œì¡±\n",
      "ê·€ë¬´ ê°€ì„¤ ì±„íƒ\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp, shapiro, wilcoxon\n",
    "\n",
    "# í•™ìƒë“¤ì˜ í‚¤\n",
    "data = [162, 159, 158, 160, 165, 163, 157, 161, 159, 160]\n",
    "\n",
    "# í‰ê· ê°’\n",
    "avg_value = 160\n",
    "\n",
    "# [1] ì •ê·œì„± ê²€ì • (í‘œë³¸ì˜ ê°œìˆ˜ê°€ 30ê°œ ë¯¸ë§Œì¸ ê²½ìš°)\n",
    "stat, pvalue = shapiro(data)\n",
    "\n",
    "alpha = 0.05   # ìœ ì˜ìˆ˜ì¤€\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print(\"ì •ê·œì„± ë§Œì¡±\")\n",
    "\n",
    "    # [2] ë‹¨ì¼ í‘œë³¸ T-ê²€ì •\n",
    "    stats, pvalue = ttest_1samp(data, avg_value)\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ì±„íƒ\")\n",
    "    else:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ê¸°ê°\")\n",
    "    \n",
    "else:\n",
    "    print(\"ì •ê·œì„± ë¶ˆë§Œì¡±\")\n",
    "\n",
    "    # [3] ìœŒì½•ìŠ¨ ë¶€í˜¸ ìˆœìœ„ ê²€ì •\n",
    "    stats, pvalue = wilcoxon(data - avg_value, alternative=\"two-sided\")   # ì–‘ì¸¡ ê²€ì •\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ì±„íƒ\")\n",
    "    else:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ê¸°ê°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¬¸ì œ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•œ íšŒì‚¬ì—ì„œ ìµœê·¼ 10ëª…ì˜ ì§ì›ë“¤ì˜ ì—°ë´‰ì„ ì¡°ì‚¬í•œ ê²°ê³¼, ì§ì›ë“¤ì˜ ì—°ë´‰ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤(ë‹¨ìœ„: ë§Œì›).\n",
    "\n",
    "```text\n",
    "ì§ì›ë“¤ì˜ ì—°ë´‰(ë§Œì›): [4500, 4800, 4700, 5000, 4600, 4900, 4850, 4700, 4550, 4800]\n",
    "```\n",
    "\n",
    "ìœ ì˜ìˆ˜ì¤€ 0.05ì¼ ë•Œ, ì´ íšŒì‚¬ì˜ ì§ì›ë“¤ì˜ í‰ê·  ì—°ë´‰ì´ 4700ë§Œì›ì¸ì§€ ì•„ë‹Œì§€ ê²€ì •í•˜ë¼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ê·œì„± ë§Œì¡±\n",
      "ê·€ë¬´ ê°€ì„¤ ì±„íƒ\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp, shapiro, wilcoxon\n",
    "\n",
    "# í•™ìƒë“¤ì˜ í‚¤\n",
    "data = [4500, 4800, 4700, 5000, 4600, 4900, 4850, 4700, 4550, 4800]\n",
    "\n",
    "# í‰ê· ê°’\n",
    "avg_value = 4700\n",
    "\n",
    "# [1] ì •ê·œì„± ê²€ì • (í‘œë³¸ì˜ ê°œìˆ˜ê°€ 30ê°œ ë¯¸ë§Œì¸ ê²½ìš°)\n",
    "stat, pvalue = shapiro(data)\n",
    "\n",
    "alpha = 0.05   # ìœ ì˜ìˆ˜ì¤€\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print(\"ì •ê·œì„± ë§Œì¡±\")\n",
    "\n",
    "    # [2] ë‹¨ì¼ í‘œë³¸ T-ê²€ì •\n",
    "    stats, pvalue = ttest_1samp(data, avg_value)\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ì±„íƒ\")\n",
    "    else:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ê¸°ê°\")\n",
    "    \n",
    "else:\n",
    "    print(\"ì •ê·œì„± ë¶ˆë§Œì¡±\")\n",
    "\n",
    "    # [3] ìœŒì½•ìŠ¨ ë¶€í˜¸ ìˆœìœ„ ê²€ì •\n",
    "    stats, pvalue = wilcoxon(data - avg_value, alternative=\"two-sided\")   # ì–‘ì¸¡ ê²€ì •\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ì±„íƒ\")\n",
    "    else:\n",
    "        print(\"ê·€ë¬´ ê°€ì„¤ ê¸°ê°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ê³¼ëª©  ë‚¨í•™ìƒ  ì—¬í•™ìƒ\n",
      "0  ìˆ˜í•™   30   35\n",
      "1  ì˜ì–´   40   30\n",
      "2  ê³¼í•™   20   35\n",
      "    ë‚¨í•™ìƒ  ì—¬í•™ìƒ\n",
      "ê³¼ëª©          \n",
      "ìˆ˜í•™   30   35\n",
      "ì˜ì–´   40   30\n",
      "ê³¼í•™   20   35\n",
      "ê·€ë¬´ ê°€ì„¤ ì±„íƒ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data = {\n",
    "    'ê³¼ëª©': ['ìˆ˜í•™', 'ì˜ì–´', 'ê³¼í•™'],\n",
    "    'ë‚¨í•™ìƒ': [30, 40, 20],\n",
    "    'ì—¬í•™ìƒ': [35, 30, 35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\"\"\" ì¶œë ¥ ê²°ê³¼\n",
    "   ê³¼ëª©  ë‚¨í•™ìƒ  ì—¬í•™ìƒ\n",
    "0  ìˆ˜í•™   30   35\n",
    "1  ì˜ì–´   40   30\n",
    "2  ê³¼í•™   20   35\n",
    "\"\"\"\n",
    "\n",
    "table = df.set_index('ê³¼ëª©')   # <ê³¼ëª©> ì»¬ëŸ¼ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •\n",
    "print(table)\n",
    "\n",
    "\"\"\" ì¶œë ¥ ê²°ê³¼\n",
    "    ë‚¨í•™ìƒ  ì—¬í•™ìƒ\n",
    "ê³¼ëª©          \n",
    "ìˆ˜í•™   30   35\n",
    "ì˜ì–´   40   30\n",
    "ê³¼í•™   20   35\n",
    "\"\"\"\n",
    "\n",
    "stat, pvalue, dof, expected = chi2_contingency(table)\n",
    "\n",
    "alpha = 0.05   # ìœ ì˜ìˆ˜ì¤€\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print(\"ê·€ë¬´ ê°€ì„¤ ì±„íƒ\")\n",
    "else:\n",
    "    print(\"ê·€ë¬´ ê°€ì„¤ ê¸°ê°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
