{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20241112\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제1유형\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1 (21년 2회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BostonHousing 데이터\n",
    "- `crim` 항목의 상위에서 10번째 값(상위 10개의 값 중에서 가장 적은 값)으로 상위 10개의 값을 변환하고, `age`가 80 이상인 값에 대하여 `crim`의 평균 구하기\n",
    "- 소수점 셋째 자리에서 반올림해서 소수점 2째 자리로 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모범 답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.76\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210201.csv')\n",
    "\n",
    "# crim 항목의 상위에서 10번째 값 뽑기\n",
    "new_df = df.sort_values(by='crim', ascending=False)   # 내림차순 정렬\n",
    "top10 = new_df.head(10)\n",
    "top10_value = top10['crim'].iloc[9]\n",
    "\n",
    "# 상위 10개의 값 변환하기\n",
    "df['crim'] = np.where(df['crim'] >= top10_value, top10_value, df['crim'])\n",
    "\n",
    "# age가 80 이상인 값에 대하여 crim의 평균 구하기\n",
    "mean_value = df['crim'][df['age'] >= 80].mean()\n",
    "answer = round(mean_value, 2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gpt 답안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 `n`번째 값 뽑기 : `df['col'].nlargest(n).iloc[-1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.76\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210201.csv')\n",
    "\n",
    "# 'crim' 항목의 상위 10번째 값 뽑기\n",
    "top10_value = df['crim'].nlargest(10).iloc[-1]\n",
    "\n",
    "# 상위 10개의 값을 변환하기\n",
    "df['crim'] = np.where(df['crim'] >= top10_value, top10_value, df['crim'])\n",
    "\n",
    "# 'age'가 80 이상인 값에 대해 'crim'의 평균 구하기\n",
    "answer = round(df.loc[df['age'] >= 80, 'crim'].mean(), 2)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2 (21년 2회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- housing 데이터\n",
    "- 데이터의 첫 번째 행부터 순서대로 80%까지의 데이터를 훈련 데이터로 추출한 후, `total_bedrooms` 변수의 결측값(NA)을 `total_bedrooms` 변수의 중앙값으로 대체하고 대체 전의 `total_bedrooms` 변수 표준편차 값과 대체 후의 `total_bedrooms` 변수 표준편차 값의 차이의 절댓값 구하기\n",
    "- 소수점 둘째 자리로 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모범 답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kss34\\AppData\\Local\\Temp\\ipykernel_29564\\3535471237.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['total_bedrooms'] = train_df['total_bedrooms'].fillna(train_df['total_bedrooms'].median())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210202.csv')\n",
    "\n",
    "# 상위 80%까지의 데이터를 훈련 데이터로 추출하기\n",
    "nrow = int(len(df) * 0.8)\n",
    "train_df = df[:nrow]\n",
    "\n",
    "a = train_df['total_bedrooms'].std()\n",
    "\n",
    "# total_bedrooms 변수의 결측값을 total_bedrooms 변수의 중앙값으로 대체\n",
    "train_df['total_bedrooms'] = train_df['total_bedrooms'].fillna(train_df['total_bedrooms'].median())\n",
    "\n",
    "b = train_df['total_bedrooms'].std()\n",
    "\n",
    "# 대체 전의 total_bedrooms 변수 표준편차 값과 대체 후의 total_bedrooms 변수 표준편차 값의 차이의 절댓값 구하기\n",
    "answer = round(abs(a - b), 2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gpt 답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임 불러오기\n",
    "df = pd.read_csv('./datasets/P210202.csv')\n",
    "\n",
    "# 상위 80%까지의 데이터를 훈련 데이터로 추출하기\n",
    "train_df = df.iloc[:int(len(df) * 0.8)]\n",
    "\n",
    "# total_bedrooms 변수의 결측값을 중앙값으로 대체하고, 표준편차 차이의 절댓값 계산하기\n",
    "answer = round(abs(train_df['total_bedrooms'].std() - train_df['total_bedrooms'].fillna(train_df['total_bedrooms'].median()).std()), 2)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 3 (21년 2회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Insurance 데이터\n",
    "- `charges` 항목에서 이상값의 합 구하기\n",
    "- 이상값은 평균에서 1.5 표준편차 이상인 값으로 하고, 정수로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6421430\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210203.csv')\n",
    "\n",
    "# 이상값 -> x > upper or x < lower\n",
    "# upper = 평균 + 1.5 * 표준편차\n",
    "# lower = 평균 - 1.5 * 표준편차\n",
    "\n",
    "target = df['charges']\n",
    "\n",
    "mean_value = target.mean()\n",
    "std_value = target.std()\n",
    "\n",
    "upper = mean_value + 1.5 * std_value\n",
    "lower = mean_value - 1.5 * std_value\n",
    "\n",
    "cond = (target < lower) | (target > upper)\n",
    "answer = int(target[cond].sum())\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 4 (21년 3회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- housing 데이터\n",
    "- 결측값이 있는 모든 행을 제거한 후 데이터의 순서대로 상위 70%의 데이터를 학습 데이터로 만들고, 훈련 데이터의 `housing_median_age` 컬럼의 제1사분위수(Q1) 구하기\n",
    "- 정수로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210301.csv')\n",
    "\n",
    "# 결측값이 있는 모든 행 제거하기\n",
    "# print(np.sum(df.isna().any(axis=1)))  # 결측값 개수 출력해보기\n",
    "df = df.dropna()\n",
    "\n",
    "# 데이터의 순서대로 상위 70%의 데이터를 훈련 데이터로 만들기\n",
    "nrow = int(len(df) * 0.7)\n",
    "train_df = df[:nrow]\n",
    "\n",
    "# 훈련 데이터의 house_median_age 컬럼의 Q1 구하기\n",
    "answer = int(train_df['housing_median_age'].quantile(0.25))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 5 (21년 3회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 타이타닉 데이터\n",
    "- 데이터가 없는 것을 결측값으로 하여 결측값의 비율을 구하고, 결측값 비율이 가장 높은 컬럼 이름 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "Age          0.198653\n",
      "Embarked     0.002245\n",
      "PassengerId  0.000000\n",
      "Survived     0.000000\n",
      "Pclass       0.000000\n",
      "Name         0.000000\n",
      "Sex          0.000000\n",
      "SibSp        0.000000\n",
      "Parch        0.000000\n",
      "Ticket       0.000000\n",
      "Fare         0.000000 \n",
      "\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210302.csv')\n",
    "\n",
    "# 데이터가 없는 것을 결측값으로 하여 결측값의 비율 구하기\n",
    "total_count = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "\n",
    "ratio = missing_count / total_count\n",
    "\n",
    "# 결측값의 비율이 가장 높은 컬럼 이름 구하기\n",
    "ratio = pd.DataFrame(ratio)\n",
    "\n",
    "sorted_ratio = ratio.sort_values(by=0, ascending=False)\n",
    "print(sorted_ratio, '\\n')\n",
    "\n",
    "answer = sorted_ratio.index[0]   # index[n]는 컬럼 이름을 반환한다.\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 6 (21년 3회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연도별 각 국가의 결핵 감염에 대한 유병률 데이터\n",
    "- `country`, `year`, `new_sp` 컬럼에 결측값이 있을 경우 제거하고 2000년도에 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수를 구하고, 2000년도의 결핵 발생 건수가 2000년도 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수보다 결핵 발생 건수가 높은 국가의 개수 구하기\n",
    "- 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수를 출력할 때, 소수점 둘째 자리로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7865.34\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P210303.csv')\n",
    "\n",
    "# country, year, new_sp 컬럼에서 결측값 제거하기\n",
    "df['country'] = df['country'].dropna()\n",
    "df['year'] = df['year'].dropna()\n",
    "df['new_sp'] = df['new_sp'].dropna()\n",
    "\n",
    "# 2000년도에 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수 구하기\n",
    "cond = df['year'] == 2000\n",
    "target_df = df[cond]\n",
    "\n",
    "mean_count = round(target_df['new_sp'].mean(), 2)\n",
    "print(mean_count)\n",
    "\n",
    "# 2000년도의 결핵 발생 건수가 2000년도 국가별 결핵 발생 건수에 대한 평균 결핵 발생 건수보다 결핵 발생 건수가 높은 국가의 개수 구하기\n",
    "cond = target_df['new_sp'] >= mean_count\n",
    "answer = len(target_df[cond])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 7 (22년 4회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순서대로 처리하고 결과를 정수로 출력하기\n",
    "    - (1) y 변수의 1사분위와 3사분위 값 구하기\n",
    "    - (2) 3사분위수에서 1사분위수를 뺀 값 구하기\n",
    "    - (3) 소수점 이하는 버리고 정수로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 40.25, Q3: 77.0\n",
      "Q3-Q1(IQR): 36.75\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220401.csv')\n",
    "\n",
    "# (1) y 변수의 1사분위와 3사분위 값 구하기\n",
    "target = df['y']\n",
    "\n",
    "q1 = target.quantile(0.25)\n",
    "q3 = target.quantile(0.75)\n",
    "\n",
    "print(f\"Q1: {q1}, Q3: {q3}\")\n",
    "\n",
    "# (2) 3사분위수에서 1사분위수를 뺀 값 구하기\n",
    "diff_value = q3 - q1\n",
    "\n",
    "print(f\"Q3-Q1(IQR): {diff_value}\") \n",
    "\n",
    "# (3) 소수점 이하는 버리고 정수로 출력하기\n",
    "answer = int(diff_value)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 8 (22년 4회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 페이스북 평가 데이터\n",
    "- '좋아요' 수(`num_loves`)와 '놀랐어요'(`num_wows`)를 긍정의 평가로 보고 전체 반응(`num_reactions`)에서 긍정인 비율이 0.4보다 크고 0.5보다 작은 비디오 개수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220402.csv')\n",
    "\n",
    "# 좋아요 수와 놀랐어요 수를 긍정의 평가로 보고 전체 중에서 비율 구하기\n",
    "df['positive_ratio'] = (df['num_loves'] + df['num_wows']) / df['num_reactions']\n",
    "\n",
    "# 전체 반응에서 긍정인 비율이 0.4보다 크고 0.5보다 작은 비디오 개수 구하기\n",
    "cond = (df['status_type'] == 'video') & ((df['positive_ratio'] > 0.4) & (df['positive_ratio'] < 0.5))\n",
    "answer = len(df[cond])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 9 (22년 4회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 넷플릭스에서 사용된 작품들의 목록 데이터\n",
    "- 2018년 1월에 넷플릭스에서 추가한 작품 중 'United Kingdom'에서 단독으로 제작된 작품의 개수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220403.csv')\n",
    "\n",
    "# 날짜 항목을 datetime64 형식으로 변환하기\n",
    "df['date_added'] = pd.to_datetime(df['date_added'])\n",
    "\n",
    "# 2018년 1월에 추가한 작품 중, 'United Kingdom'에서 단독으로 제작된 작품의 개수 구하기\n",
    "cond1 = (df['date_added'].dt.year == 2018) & (df['date_added'].dt.month == 1)\n",
    "cond2 = df['country'] == 'United Kingdom'\n",
    "\n",
    "answer = len(df[cond1 & cond2])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 10 (22년 5회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 종량제 쓰레기 데이터\n",
    "- 쓰레기 데이터에서 다음 기준에 따른 데이터를 추출하고, 평균 가격을 제출 형식에 따라 제출하기\n",
    "    - 종량제봉투종류 : 규격봉투\n",
    "    - 종량제봉투용도 : 음식물쓰레기\n",
    "    - 종량제봉투용량 : 2L\n",
    "    - 가격이 0인 것은 구매하지 않은 것으로, 평균 계산할 때 제외한다.\n",
    "- 정수형으로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220501.csv', encoding='euckr')\n",
    "\n",
    "# 종량제봉투종류 : 규격봉투, 종량제봉투용도 : 음식물쓰레기, 종량제봉투용량 : 2L (가격이 0인 것은 제외하기)\n",
    "cond = (df['종량제봉투종류'] == '규격봉투') & (df['종량제봉투용도'] == '음식물쓰레기') & (df['2L가격'] != 0)\n",
    "new_df = df[cond]\n",
    "\n",
    "# 평균 가격 구하기\n",
    "mean_price = new_df['2L가격'].mean()\n",
    "answer = int(mean_price)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 11 (22년 5회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Body 데이터\n",
    "- 다음 기준에 의해 BMI를 계산하여 분류하고, 정상 체중 범위의 구간에 있는 인원과 위험 체중 범위의 구간에 있는 인원의 차이를 절댓값으로 구하기\n",
    "    - BMI = Weight / Height² (weight : kg, height : m)\n",
    "    - 저체중 :  BMI < 18.5\n",
    "    - 정상체중 : 18.5 ≤ BMI < 23\n",
    "    - 위험체중 : 23 ≤ BMI < 25\n",
    "    - 비만 : 25 ≤ BMI\n",
    "- BMI 계산시 단위에 유의하고, 정수로 출력하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220502.csv')\n",
    "\n",
    "# BMI 계산하기\n",
    "df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)    # ✅ 단위에 주의할 것!\n",
    "\n",
    "# 정상 체중 범위 구간의 인원 수와 위험 체중 범위 구간의 인원 수 구하기\n",
    "cond1 = (18.5 <= df['BMI']) & (df['BMI'] < 23)\n",
    "healthy = len(df[cond1])\n",
    "\n",
    "cond2 = (23 <= df['BMI']) & (df['BMI'] < 25)\n",
    "danger = len(df[cond2])\n",
    "\n",
    "answer = int(abs(healthy - danger))\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 12 (22년 5회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순전입학생수가 가장 큰 학교의 전체 학생수 구하기\n",
    "    - 순전입학생수 = 총전입학생수 - 총전출학생수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P220503.csv', encoding='euckr')\n",
    "\n",
    "# 순전입학생수 구하기 (순전입학생수 = 총전입학생수 - 총전출학생수)\n",
    "df['순전입학생수'] = df['전입학생수(계)'] - df['전출학생수(계)']\n",
    "\n",
    "# 순전입학생수가 가장 큰 학교의 전체 학생수 구하기\n",
    "new_df = df.sort_values(by='순전입학생수', ascending=False).reset_index(drop=True)\n",
    "answer = new_df['전체학생수(계)'].iloc[0]\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 13 (23년 6회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출동소방서별로 주민으로부터 연락받은 신고일시와 출동한 출동일시를 기록한 데이터\n",
    "- 출동소방서별 신고일시로부터 출동일시까지의 연도별 월평균을 구하고, 가장 늦게 출동한 출동소방서의 월평균 시간을 분단위로 제출 형식에 맞게 제출하기\n",
    "- 시간은 30초 단위로 반올림하여 제출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230601.csv')\n",
    "\n",
    "# 신고일시, 출동일시 컬럼을 datetime64 형식으로 변환하기\n",
    "df['신고일시'] = pd.to_datetime(df['신고일시'])\n",
    "df['출동일시'] = pd.to_datetime(df['출동일시'])\n",
    "\n",
    "# 출동소방서별 신고일시로부터 출동일시까지 연도별 월평균 구하기\n",
    "df['시간차이'] = (df['출동일시'] - df['신고일시']).dt.total_seconds()\n",
    "\n",
    "df = df.groupby([df['출동소방서'], df['신고일시'].dt.year, df['신고일시'].dt.month]).mean('시간차이')\n",
    "df = df.sort_values(by='시간차이', ascending=False)\n",
    "\n",
    "# 가장 늦게 출동한 출동소방서의 월평균 시간을 분단위로 나타내기\n",
    "result_date = df['시간차이'].head(1)\n",
    "result_num = float(result_date.iloc[0]) / 60    # 분단위\n",
    "answer = int(result_num)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 14 (23년 6회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초등학교의 학년별 학생 수와 교사 수를 기록한 데이터\n",
    "- 교사 1인당 학생 수가 가장 많은 학교를 선정하고, 선정된 학교의 교사 수를 제출 형식에 맞게 제출하기\n",
    "- 학교명 중복은 없고, 단일 학교의 학생 수, 교사 수 데이터만 있는 것으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230602.csv')\n",
    "\n",
    "# 교사 1인당 학생수가 가장 많은 학교 선정하기\n",
    "df['student_number_per_teacher'] = (df['student_1'] + df['student_2'] + df['student_3'] + df['student_4'] + df['student_5'] + df['student_6']) / df['teacher']\n",
    "df_sorted = df.sort_values(by='student_number_per_teacher', ascending=False)\n",
    "\n",
    "target_df = df_sorted.head(1)\n",
    "\n",
    "# 선정된 학교의 교사수 구하기\n",
    "answer = target_df['teacher'].iloc[0]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 15 (23년 6회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월별 범죄를 기록한 데이터\n",
    "- 연도별 월평균 범죄 건수를 구하고, 가장 범죄가 많이 발생한 연도의 월평균 범죄 건수 구하기\n",
    "- 파이썬의 경우 CSV 파일을 읽을 때 `index_col=0` 옵션을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19329\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230603.csv')\n",
    "\n",
    "# 년월 컬럼을 datetime64 컬럼으로 바꾸기\n",
    "df['년월'] = pd.to_datetime(df['년월'])\n",
    "\n",
    "# 연도별 월평균 범죄 건수 구하기\n",
    "df['발생연도'] = df['년월'].dt.year\n",
    "df['발생월'] = df['년월'].dt.month\n",
    "df['총범죄건수'] = df['강력범'] + df['절도범'] + df['폭력범'] + df['지능범'] + df['풍속범'] + df['기타형사범']\n",
    "\n",
    "df = df.groupby(by=['발생연도']).mean()   # 월평균 범죄 건수\n",
    "\n",
    "# 가장 범죄가 많이 발생한 연도의 월평균 범죄 건수 구하기\n",
    "df = df.sort_values(by='총범죄건수', ascending=False).head(1)\n",
    "answer = int(df['총범죄건수'].iloc[0])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 16 (23년 7회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학생 15명의 국어, 수학, 영어, 과학 시험 점수 (각 학생은 4과목 중 3과목을 선택해서 시험봤다.)\n",
    "- 국어, 수학, 영어, 과학 과목 중 가장 많은 학생들이 응시한 시험을 선택하고, 해당 과목의 점수를 표준화 했을 때 가장 큰 표준화 점수 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 표준화(Standardization)\n",
    "> - 어떤 특정의 값들이 **정규 분포**를 따른다고 가정하고 값들을 `0`의 **평균,** `1`의 **표준편차**를 갖도록 해주는 기법\n",
    "\n",
    "> **Z-점수(Z-Score)**\n",
    "> \n",
    "> - 이상값(Outlier) 문제를 피하는 기법\n",
    "> - 데이터들의 평균과 표준편차를 구하고, 평균 대비 몇 표준편차만큼 데이터가 떨어져 있는지를 점수화한다.\n",
    "> - `X`의 값이 평균과 일치하면 `0`, 평균보다 작으면 **음수**, 평균보다 크면 **양수**가 되며, 표준편차가 크면 Z-스코어는 `0`에 가까워진다.\n",
    "\n",
    "> $$Z = \\frac{X - \\overline{X}}{s}$$\n",
    "\n",
    "> $$X: 데이터 \\quad \\overline{X}: 표본평균 \\quad s: 표본표준편차 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 12 11 9\n",
      "1.713855688712825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "df = pd.read_csv('./datasets/P230701.csv')\n",
    "\n",
    "# 각 과목별 결측치 제거 후 개수 파악하기\n",
    "count_korean = df['국어'].dropna().count()\n",
    "count_math = df['수학'].dropna().count()\n",
    "count_english = df['영어'].dropna().count()\n",
    "count_science = df['과학'].dropna().count()\n",
    "\n",
    "print(count_korean, count_math, count_english, count_science)\n",
    "\n",
    "target = df['국어']\n",
    "\n",
    "# 표준화 (Z-점수 표준화 = X-평균 / 표준편차) 후 가장 큰 점수 구하기\n",
    "target = target.dropna()   # 결측치 제거\n",
    "\n",
    "answer = zscore(target).max()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 17 (23년 7회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32개 변수간 상관 관계를 확인했을 때, `var_11` 컬럼과 상관 계수의 절댓값이 가장 큰 변수를 찾아 해당 변수의 평균값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_44\n",
      "0.22367215340392685\n",
      "0.06404313251242914\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230702.csv')\n",
    "\n",
    "# var_11 컬럼과 상관 계수의 절댓값이 가장 큰 변수 찾기\n",
    "df_corr = df.corr(numeric_only=True)   # 상관 계수 구하기\n",
    "\n",
    "target = df_corr['var_11']\n",
    "\n",
    "abs_target = np.abs(target)   # 절댓값 씌우기\n",
    "sorted_target = abs_target.sort_values(ascending=False)   # 내림차순 정렬\n",
    "\n",
    "result_variable = sorted_target.index[1]\n",
    "print(result_variable)    # 변수명\n",
    "print(sorted_target['var_44'])   # 변수값\n",
    "\n",
    "# 찾은 변수의 평균값 구하기\n",
    "answer = df[result_variable].mean()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 18 (23년 7회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `var_6` 컬럼의 1, 3사분위수 각각 IQR의 1.5배 벗어난 이상치의 숫자 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5939812454434104 0.6428288851668509 1.2368101306102612\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P230703.csv')\n",
    "\n",
    "# var_6 컬럼의 1, 3사분위수를 구하고, IQR 구하기\n",
    "target = df['var_6']\n",
    "\n",
    "q1 = target.quantile(0.25)\n",
    "q3 = target.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "print(q1, q3, iqr)\n",
    "\n",
    "# IQR의 1.5배 벗어난 이상치 숫자 구하기\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "cond = (target < lower) | (target > upper)\n",
    "\n",
    "answer = len(df[cond]['var_6'])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 19 (24년 8회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대륙별 평균 맥주 소비량이 많은 곳을 고르고, 해당 대륙에서 다섯번째로 맥주 소비량이 많은 나라 구하기\n",
    "- 정수로 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/P240801.csv')\n",
    "# print(df.info())\n",
    "\n",
    "# 대륙별 평균 맥주 소비량 가장 많은 곳 구하기\n",
    "new_df = df.groupby(by='continent')['beer_servings'].mean()\n",
    "new_df = new_df.sort_values(ascending=False)\n",
    "# print(new_df)\n",
    "\n",
    "continent = new_df.index[0]\n",
    "print(continent)   # Europe\n",
    "\n",
    "# 해당 대륙에서 다섯번째로 맥주 소비량이 많은 나라 구하기\n",
    "cond = df['continent'] == 'Europe'\n",
    "df_europe = df[cond]\n",
    "# print(df_europe)\n",
    "\n",
    "sorted_df_europe = df_europe.sort_values(by=\"beer_servings\", ascending=False).reset_index()   # 인덱스 초기화\n",
    "# print(sorted_df_europe.head(5))\n",
    "\n",
    "answer = sorted_df_europe.iloc[4]['beer_servings']   # 맥주 소비량 다섯번째로 큰 나라의 맥주 소비량 구하기\n",
    "print(answer)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 20 (24년 8회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 관광객 비율이 두 번째로 높은 나라의 `관광` 수를 `a`라고 정의하고, 관광객 수가 두 번째로 높은 나라의 `공무` 수를 `b`라고 정의한 후, a+b의 값 구하기\n",
    "- 관광객 비율 - 관광 입국 인원 / (관광 입국 인원 + 공무 입국 인원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   국가  관광입국  공무입국     관광객비율\n",
      "0  중국   120    60  0.666667\n",
      "1  홍콩    74    38  0.660714\n",
      "2  독일    50    26  0.657895\n",
      "3  미국    60    90  0.400000\n",
      "4  일본   100   165  0.377358\n",
      "74\n",
      "   국가  관광입국  공무입국     관광객비율\n",
      "0  중국   120    60  0.666667\n",
      "1  일본   100   165  0.377358\n",
      "2  홍콩    74    38  0.660714\n",
      "3  미국    60    90  0.400000\n",
      "4  독일    50    26  0.657895\n",
      "165\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 가상의 데이터프레임 생성 (데이터셋 확인 불가)\n",
    "data = {\n",
    "    '국가': ['홍콩', '독일', '일본', '중국', '미국'],\n",
    "    '관광입국': [74, 50, 100, 120, 60], \n",
    "    '공무입국': [38, 26, 165, 60, 90],  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 관광객 비율 구하기\n",
    "df['관광객비율'] = df['관광입국'] / (df['관광입국'] + df['공무입국'])\n",
    "\n",
    "# 관광객 비율 기준 내림차순 정렬\n",
    "ratio_sorted_df = df.sort_values(by=\"관광객비율\", ascending=False).reset_index(drop=True)\n",
    "print(ratio_sorted_df)\n",
    "\n",
    "# 관광객 비율이 두 번째로 높은 나라의 관광입국 수 구하기\n",
    "a = ratio_sorted_df.loc[1, '관광입국']\n",
    "print(a)\n",
    "\n",
    "# 관광객 수 기준 내림차순 정렬\n",
    "tour_sorted_df = df.sort_values(by=\"관광입국\", ascending=False).reset_index(drop=True)\n",
    "print(tour_sorted_df)\n",
    "\n",
    "# 관광객 수가 두 번째로 높은 나라의 공무입국 수 구하기\n",
    "b = tour_sorted_df.loc[1, '공무입국']\n",
    "print(b)\n",
    "\n",
    "answer = a + b\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 21 (24년 8회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Co` 컬럼과 `Nmch` 컬럼의 Min-Max Scaler를 시행한 다음, 스케일링 후의 `Co` 컬럼의 표준편차를 `a`라 하고, `Nmch` 컬럼의 표준편차를 `b`로 한 후, a-b의 값 구하기\n",
    "\n",
    "$$X_{\\text{norm}} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004724214242981084\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "data = {\n",
    "    'Co': np.random.uniform(50, 300, 100), \n",
    "    'Nmch': np.random.uniform(20, 100, 100)  \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 최소-최대 정규화 시행하기\n",
    "## (1) Co 컬럼\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "df['Co_scaled'] = mms.fit_transform(df[['Co']])\n",
    "# print(df)\n",
    "\n",
    "## (2) NMch 컬럼\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "df['Nmch_scaled'] = mms.fit_transform(df[['Nmch']])\n",
    "# print(df)\n",
    "\n",
    "# 표준편차 구하기\n",
    "a = df['Co_scaled'].std()\n",
    "b = df['Nmch_scaled'].std()\n",
    "\n",
    "# 정답 구하기\n",
    "## 💡 문제에서 'a-b' 라고 식을 정의해주었으므로 마이너스를 꼭 붙여야 한다. \n",
    "answer = a - b\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 22 (시험장 환경 체험 예제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 제공된 데이터(`data/mtcars`)의 `qsec` 컬럼을 최소-최대 척도(Min-Max Scale)로 변환한 후, 0.5보다 큰 값을 가지는 레코드 수 구하기\n",
    "- 정수로 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 방법 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "# qsec 컬럼을 최소-최대 척도로 변환하기\n",
    "# min_max = (x - min(x)) / (max(x) - min(x))\n",
    "def min_max(column):\n",
    "\tmin_value = np.min(df[column])\n",
    "\tmax_value = np.max(df[column])\n",
    "\t\n",
    "\tmms = (df[column] - min_value) / (max_value - min_value)\n",
    "\t\n",
    "\treturn mms\n",
    "\n",
    "mms_value = min_max('qsec')\n",
    "df['mms_value'] = mms_value   # 새로운 컬럼으로 추가\n",
    "\n",
    "# 0.5보다 큰 값을 가지는 레코드 수 구하기\n",
    "cond = df['mms_value'] > 0.5\n",
    "answer = len(df[cond])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 방법 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('./datasets/mtcars.csv')\n",
    "\n",
    "# qsec 컬럼을 최소-최대 척도로 변환하기\n",
    "mms = MinMaxScaler()\n",
    "df['qsec'] = mms.fit_transform(df[['qsec']])    # 2차원 데이터를 인수로 넣어준다! ✅\n",
    "\n",
    "# 0.5보다 큰 값을 가지는 레코드 수 구하기\n",
    "cond = df['qsec'] > 0.5\n",
    "answer = len(df[cond])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 23 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `diamonds` 데이터\n",
    "- 순서대로 70%의 데이터를 훈련 데이터로 만들고, `price` 기준으로 상위 5개 데이터에 대하여 깊이 비율(`depth`)의 중앙값을 정수로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-1.csv')\n",
    "\n",
    "# 순서대로 70%의 데이터를 훈련 데이터로 만들기\n",
    "nrows = int(len(df) * 0.7)\n",
    "train_df = df[:nrows]\n",
    "\n",
    "# price 기준으로 상위 5개 데이터에 대하여 깊이(depth) 비율의 중앙값을 정수로 출력하기\n",
    "sorted_trained_df = train_df.sort_values(by='price', ascending=False)\n",
    "top5 = sorted_trained_df.head(5)\n",
    "median_value = top5['depth'].median()   # 중앙값\n",
    "\n",
    "answer = int(median_value)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 24 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `telco-customer-churn` 데이터\n",
    "- `TotalCharges` 항목에서 결측값을 제거하고 이상값을 제외한 평균을 정수로 출력하기\n",
    "    - 이상값은 평균에서 1.5 표준편차 이상인 값으로 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-2.csv')\n",
    "\n",
    "target = df['TotalCharges']\n",
    "\n",
    "# 수치형으로 변환\n",
    "target = pd.to_numeric(target, errors='coerce')   # 변환할 수 없는 값을 NaN으로 처리 (astype('float')를 사용할 경우 공백(' ') 처리 불가)\n",
    "\n",
    "# TotalCharges 항목에서 결측값 제거하기\n",
    "target = target.dropna()\n",
    "\n",
    "# TotalCharges 항목에서 이상값 제외하기\n",
    "mean_value = target.mean()\n",
    "std_value = target.std()\n",
    "\n",
    "lower = mean_value - 1.5 * std_value\n",
    "upper = mean_value + 1.5 * std_value\n",
    "\n",
    "cond = (target <= upper) & (target >= lower)\n",
    "\n",
    "answer = int(target[cond].mean())\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 25 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32개 자동차 모델의 디자인과 성능을 비교한 `mtcars` 데이터\n",
    "- 수동(`am=1`) 중에서 가장 마력(`hp`)이 작은 5개의 데이터의 평균 연비(`mpg`)와 자동(`am=0`) 중에서 가장 마력(`hp`)이 작은 5개 데이터의 평균 연비(`mpg`)의 차이 구하기\n",
    "- 소수점 첫째 자리로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-3.csv')\n",
    "\n",
    "# 수동(am=1) 중에서 가장 마력(hp)이 작은 5개의 데이터의 평균 연비(mpg) 구하기\n",
    "cond1 = df['am'] == 1\n",
    "target1 = df[cond1].sort_values(by='hp', ascending=True).head(5)\n",
    "\n",
    "manual_mean_mpg = target1['mpg'].mean()\n",
    "\n",
    "# 자동(am=0) 중에서 가장 마력(hp)이 작은 5개 데이터의 평균 연비(mpg) 구하기\n",
    "cond2 = df['am'] == 0\n",
    "target2 = df[cond2].sort_values(by='hp', ascending=True).head(5)\n",
    "\n",
    "auto_mean_mpg = target2['mpg'].mean()\n",
    "\n",
    "# 두 값의 차이 구하기\n",
    "answer = round(np.abs(manual_mean_mpg - auto_mean_mpg), 1)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 26 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 뉴욕의 공기 오염도를 측정한 `airquality` 데이터\n",
    "- 데이터의 순서대로 70%의 데이터를 훈련 데이터로 추출하고, `Ozone` 항목의 결측값을 평균으로 변경한 후 변경 전, 후의 중앙값 차이 구하기\n",
    "- `Ozone` 항목의 결측값과 변경 전, 후의 중앙값, 중앙값의 차이는 모두 소수점 첫째 자리로 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M2-1.csv')\n",
    "\n",
    "# 데이터의 순서대로 70%의 데이터를 훈련 데이터로 추출하기\n",
    "nrows = int(len(df) * 0.7)\n",
    "train_df = df[:nrows]\n",
    "\n",
    "# Ozone 항목의 결측값을 평균으로 변경한 후 변경 전, 후의 중앙값 차이 구하기\n",
    "target = train_df['Ozone']\n",
    "\n",
    "median_value1 = round(target.median(), 1)\n",
    "\n",
    "mean_value = round(target.mean(), 1)\n",
    "target = target.fillna(mean_value)\n",
    "\n",
    "median_value2 = round(target.median(), 1)\n",
    "\n",
    "answer = round(np.abs(median_value1 - median_value2), 1)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 27 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `marvel` 데이터\n",
    "- `HAIR`와 `EYE`가 결측값이 아니다.\n",
    "- `HAIR`가 `White Hair`이고, `EYE`가 `Blue Eyes`인 데이터를 훈련 데이터로 추출했을 때, `APPEARANCES`에서 이상값을 제외한 평균 구하기\n",
    "    - 이상값은 평균에서 1.5배 표준편차를 벗어나는 값으로 하기\n",
    "- 평균, 표준편차는 소수 둘째 자리로 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M2-2.csv')\n",
    "\n",
    "# Hair가 White Hair이고 Eye가 Blue Eyes인 데이터를 훈련 데이터로 추출하기\n",
    "cond = (df['HAIR'] == 'White Hair') & (df['EYE'] == 'Blue Eyes')\n",
    "train_df = df[cond]\n",
    "\n",
    "# APPEARANCES에서 이상값을 제외한 평균 구하기\n",
    "target = train_df['APPEARANCES']\n",
    "\n",
    "mean_value = round(target.mean(), 2)\n",
    "std_value = round(target.std(), 2)\n",
    "\n",
    "lower = mean_value - 1.5 * std_value\n",
    "upper = mean_value + 1.5 * std_value\n",
    "\n",
    "cond = (target >= lower) & ( target <= upper)\n",
    "result = target[cond].mean()\n",
    "\n",
    "answer = round(result, 2)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 28 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Carseats` 데이터\n",
    "- 매출(`Sales`)의 이상값을 제외한 데이터를 훈련 데이터로 선정할 떄, `Age`의 표준편차 구하기\n",
    "    - 이상값은 평균보다 1.5 표준편차 미만이거나 초과인 값으로 선정하기\n",
    "- 소수점 둘째 자리로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/M2-3.csv')\n",
    "\n",
    "# 매출(Sales)의 이상값을 제외한 데이터를 훈련 데이터로 선정하기\n",
    "target = df['Sales']\n",
    "mean_value = target.mean()\n",
    "std_value = target.std()\n",
    "\n",
    "lower = mean_value - 1.5 * std_value\n",
    "upper = mean_value + 1.5 * std_value\n",
    "\n",
    "cond = (target > lower) & (target < upper)\n",
    "\n",
    "train_data = df[cond]\n",
    "\n",
    "# Age의 표준편차 구하기\n",
    "result = train_data['Age'].std()\n",
    "answer = round(result, 2)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고로, 다음과 같이 Z-Score를 이용하여 이상값을 제외한 데이터를 추출할 수 있다.\n",
    "\n",
    "```py\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(df['컬럼명'])\n",
    "target_df = df[abs(z_scores) <= 1.5]   # z-score 절댓값이 1.5 이하인 데이터 선택\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# 데이터 읽기\n",
    "df = pd.read_csv('./datasets/M2-3.csv')\n",
    "\n",
    "# Sales 열의 z-score 계산\n",
    "z_scores = zscore(df['Sales'])\n",
    "\n",
    "# 이상값 제거 (z-score의 절대값이 1.5 이하인 데이터 선택)\n",
    "train_data = df[abs(z_scores) <= 1.5]\n",
    "\n",
    "# Age 열의 표준편차 계산\n",
    "answer = round(train_data['Age'].std(), 2)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제2유형\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1 (21년 2회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기업에서 생성된 주문 데이터\n",
    "- `P210204-01.csv` 파일의 데이터로 정시 도착 가능 여부 예측 모델을 만들고, `P210204-02.csv` 파일에 대하여 정시 도착 여부를 예측한 확률을 기록한 CSV 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966 359]\n",
      " [232 446]]\n",
      "0.7049425861208187\n",
      "0.7290566037735849\n",
      "0.8063439065108514\n",
      "0.7657550535077289\n",
      "0.6934368564590639\n",
      "[[0.40666667 0.59333333]\n",
      " [0.29666667 0.70333333]\n",
      " [0.63333333 0.36666667]\n",
      " ...\n",
      " [0.30333333 0.69666667]\n",
      " [0.23       0.77      ]\n",
      " [0.33333333 0.66666667]]\n",
      "         ID      pred\n",
      "0      8010  0.593333\n",
      "1      8011  0.703333\n",
      "2      8012  0.366667\n",
      "3      8013  0.430000\n",
      "4      8014  0.513333\n",
      "...     ...       ...\n",
      "2985  10995  0.740000\n",
      "2986  10996  0.666667\n",
      "2987  10997  0.696667\n",
      "2988  10998  0.770000\n",
      "2989  10999  0.666667\n",
      "\n",
      "[2990 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P210204-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P210204-02.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "## 정수형 -> 범주형\n",
    "df1['Reached.on.Time_Y.N'] = df1['Reached.on.Time_Y.N'].astype('category')\n",
    "\n",
    "## 결측치가 있을 경우, fillna를 이용하여 중앙값 또는 0으로 대치\n",
    "## Object인 컬럼이 여러개 있을 경우, Label Encoder를 이용해서 전부 수치형으로 바꿔주기\n",
    "\n",
    "## 독립변수, 종속 변수 구분\n",
    "x = df1.drop('Reached.on.Time_Y.N', axis=1)   # 독립변수\n",
    "y = df1['Reached.on.Time_Y.N']   # 종속변수\n",
    "\n",
    "## 원-핫 인코딩\n",
    "x = x.drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 모델링 및 예측\n",
    "## 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "## 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "## 예측\n",
    "pred = md.predict(x_valid)\n",
    "\n",
    "## 성능 평가\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(recall_score(y_valid, pred))\n",
    "print(precision_score(y_valid, pred))\n",
    "print(f1_score(y_valid, pred))\n",
    "print(roc_auc_score(y_valid, pred))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "## 원-핫 인코딩\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "## 예측\n",
    "pred = md.predict_proba(x_test_encoded) \n",
    "print(pred)\n",
    "\n",
    "# CSV로 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'pred': pred[:, 1]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 💡 나만의 방식으로 풀어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 1]\n",
      "[[966 328]\n",
      " [249 460]]\n",
      "0.7119321018472291\n",
      "0.7465224111282844\n",
      "0.7950617283950617\n",
      "0.7700278995615784\n",
      "0.6976617697390364\n",
      "[[0.35 0.65]\n",
      " [0.24 0.76]\n",
      " [0.54 0.46]\n",
      " ...\n",
      " [0.43 0.57]\n",
      " [0.3  0.7 ]\n",
      " [0.24 0.76]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P210204-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P210204-02.csv')\n",
    "\n",
    "# print(df1.info())\n",
    "# print(df2.info())\n",
    "\n",
    "# (1) 데이터 전처리\n",
    "## 정수형 -> 범주형\n",
    "df1['Reached.on.Time_Y.N'] = df1['Reached.on.Time_Y.N'].astype('category')\n",
    "\n",
    "## 독립 변수, 종속 변수 구분\n",
    "x = df1.drop('Reached.on.Time_Y.N', axis=1)\n",
    "y = df1['Reached.on.Time_Y.N']\n",
    "\n",
    "## 원-핫 인코딩 (훈련용 데이터, 테스트 데이터)\n",
    "x = x.drop('ID', axis=1)\n",
    "x_test = df2.copy().drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)         # 훈련용 데이터\n",
    "x_test_encoded = pd.get_dummies(x_test)  # 테스트용 데이터 (df2)\n",
    "\n",
    "# (2) 모델링 및 예측\n",
    "## 데이터 분할\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "## 모델링\n",
    "md = RandomForestClassifier()\n",
    "md.fit(x_tr, y_tr)   # 훈련용 데이터셋으로 모델링\n",
    "\n",
    "## 예측\n",
    "pred = md.predict(x_val)   # 검증용 데이터셋으로 예측\n",
    "print(pred)\n",
    "\n",
    "## 모델 성능 평가\n",
    "cm = confusion_matrix(y_val, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_val, pred))\n",
    "print(recall_score(y_val, pred))\n",
    "print(precision_score(y_val, pred))\n",
    "print(f1_score(y_val, pred))\n",
    "print(roc_auc_score(y_val, pred))\n",
    "\n",
    "## 테스트 데이터로 예측\n",
    "pred = md.predict_proba(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# (3) CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'pred': pred[:, 1]   # 두 번째 컬럼의 값만 (정시 도착했을 경우)\n",
    "})\n",
    "result.to_csv('./outputs/20241112_Q1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2 (21년 3회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 고객의 예약 현황을 나타낸 데이터\n",
    "- `P210304-01.csv` 파일에 저장된 학습 데이터로 여행 보험 가입 여부 예측 모델을 만들고, `P210304-02.csv` 파일에 저장된 테스트 데이터로 여행 보험 패키지 가입 여부를 예측하는 결과 예시 파일과 동일한 형태의 CSV 파일로 생성하여 제출하기\n",
    "\n",
    "|index|y_pred|\n",
    "|:-:|:-:|\n",
    "|1|0.538132|\n",
    "|2|0.759230|\n",
    "|...|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83  46]\n",
      " [ 31 213]]\n",
      "0.7935656836461126\n",
      "0.6434108527131783\n",
      "0.7280701754385965\n",
      "0.6831275720164609\n",
      "0.7581808361926548\n",
      "[[1.26666667e-01 8.73333333e-01]\n",
      " [1.46666667e-01 8.53333333e-01]\n",
      " [8.51666667e-01 1.48333333e-01]\n",
      " [6.82777778e-01 3.17222222e-01]\n",
      " [9.66111111e-01 3.38888889e-02]\n",
      " [5.85531746e-01 4.14468254e-01]\n",
      " [1.40000000e-01 8.60000000e-01]\n",
      " [8.32222222e-01 1.67777778e-01]\n",
      " [5.16087302e-01 4.83912698e-01]\n",
      " [2.19825397e-01 7.80174603e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.89166667e-01 1.08333333e-02]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [8.00000000e-01 2.00000000e-01]\n",
      " [6.77235450e-01 3.22764550e-01]\n",
      " [9.98888889e-01 1.11111111e-03]\n",
      " [9.34884921e-01 6.51150794e-02]\n",
      " [1.60000000e-01 8.40000000e-01]\n",
      " [5.88833333e-01 4.11166667e-01]\n",
      " [9.95000000e-01 5.00000000e-03]\n",
      " [8.04666667e-01 1.95333333e-01]\n",
      " [9.81595238e-01 1.84047619e-02]\n",
      " [6.66666667e-03 9.93333333e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [8.50957672e-01 1.49042328e-01]\n",
      " [8.91255291e-01 1.08744709e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [8.62388889e-01 1.37611111e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.32000000e-01 1.68000000e-01]\n",
      " [1.33333333e-02 9.86666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.34884921e-01 6.51150794e-02]\n",
      " [4.00000000e-02 9.60000000e-01]\n",
      " [3.71935786e-01 6.28064214e-01]\n",
      " [8.52619048e-01 1.47380952e-01]\n",
      " [1.20000000e-01 8.80000000e-01]\n",
      " [1.05500000e-01 8.94500000e-01]\n",
      " [9.73333333e-01 2.66666667e-02]\n",
      " [9.87222222e-01 1.27777778e-02]\n",
      " [9.34884921e-01 6.51150794e-02]\n",
      " [9.04000000e-01 9.60000000e-02]\n",
      " [2.16666667e-01 7.83333333e-01]\n",
      " [4.46666667e-01 5.53333333e-01]\n",
      " [7.84166667e-01 2.15833333e-01]\n",
      " [5.42055556e-01 4.57944444e-01]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [4.41666667e-01 5.58333333e-01]\n",
      " [5.02348846e-01 4.97651154e-01]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [8.91177249e-01 1.08822751e-01]\n",
      " [9.56288360e-01 4.37116402e-02]\n",
      " [5.98333333e-01 4.01666667e-01]\n",
      " [2.26666667e-01 7.73333333e-01]\n",
      " [7.82888889e-01 2.17111111e-01]\n",
      " [8.47222222e-03 9.91527778e-01]\n",
      " [5.56907407e-01 4.43092593e-01]\n",
      " [4.96861241e-01 5.03138759e-01]\n",
      " [8.77388889e-01 1.22611111e-01]\n",
      " [1.74424603e-01 8.25575397e-01]\n",
      " [1.05500000e-01 8.94500000e-01]\n",
      " [1.66666667e-02 9.83333333e-01]\n",
      " [9.03333333e-01 9.66666667e-02]\n",
      " [4.33333333e-02 9.56666667e-01]\n",
      " [1.20000000e-01 8.80000000e-01]\n",
      " [7.67722222e-01 2.32277778e-01]\n",
      " [9.56055556e-01 4.39444444e-02]\n",
      " [9.68333333e-01 3.16666667e-02]\n",
      " [6.67925926e-01 3.32074074e-01]\n",
      " [9.38349206e-01 6.16507937e-02]\n",
      " [9.80888889e-01 1.91111111e-02]\n",
      " [7.15222222e-01 2.84777778e-01]\n",
      " [8.96230159e-01 1.03769841e-01]\n",
      " [1.25000000e-01 8.75000000e-01]\n",
      " [1.79166667e-02 9.82083333e-01]\n",
      " [1.86666667e-01 8.13333333e-01]\n",
      " [9.26666667e-01 7.33333333e-02]\n",
      " [6.71491582e-01 3.28508418e-01]\n",
      " [7.46666667e-01 2.53333333e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.35945767e-01 6.40542328e-02]\n",
      " [3.23333333e-01 6.76666667e-01]\n",
      " [6.76666667e-01 3.23333333e-01]\n",
      " [5.59071429e-01 4.40928571e-01]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [9.85194195e-01 1.48058053e-02]\n",
      " [9.69777778e-01 3.02222222e-02]\n",
      " [8.71388889e-01 1.28611111e-01]\n",
      " [9.63333333e-01 3.66666667e-02]\n",
      " [8.11984127e-02 9.18801587e-01]\n",
      " [9.44857143e-01 5.51428571e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.95916667e-01 4.08333333e-03]\n",
      " [6.00000000e-02 9.40000000e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [6.80613757e-01 3.19386243e-01]\n",
      " [8.76666667e-01 1.23333333e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [3.60000000e-01 6.40000000e-01]\n",
      " [9.95916667e-01 4.08333333e-03]\n",
      " [3.00000000e-02 9.70000000e-01]\n",
      " [9.50000000e-01 5.00000000e-02]\n",
      " [3.33333333e-02 9.66666667e-01]\n",
      " [9.33111111e-01 6.68888889e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.62388889e-01 1.37611111e-01]\n",
      " [3.20000000e-01 6.80000000e-01]\n",
      " [9.77936508e-01 2.20634921e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.57833333e-01 4.21666667e-02]\n",
      " [9.93194444e-01 6.80555556e-03]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [9.60166667e-01 3.98333333e-02]\n",
      " [9.03428571e-01 9.65714286e-02]\n",
      " [9.40000000e-01 6.00000000e-02]\n",
      " [7.70000000e-01 2.30000000e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [9.42182540e-01 5.78174603e-02]\n",
      " [8.56666667e-01 1.43333333e-01]\n",
      " [1.73333333e-01 8.26666667e-01]\n",
      " [6.66666667e-03 9.93333333e-01]\n",
      " [8.50000000e-01 1.50000000e-01]\n",
      " [7.69723184e-01 2.30276816e-01]\n",
      " [7.83555556e-01 2.16444444e-01]\n",
      " [6.30473545e-01 3.69526455e-01]\n",
      " [5.83333333e-01 4.16666667e-01]\n",
      " [8.91596504e-01 1.08403496e-01]\n",
      " [6.82777778e-01 3.17222222e-01]\n",
      " [9.54611111e-01 4.53888889e-02]\n",
      " [8.81666667e-01 1.18333333e-01]\n",
      " [7.46666667e-01 2.53333333e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [3.64329365e-01 6.35670635e-01]\n",
      " [9.93000000e-01 7.00000000e-03]\n",
      " [8.95358919e-01 1.04641081e-01]\n",
      " [9.35436508e-01 6.45634921e-02]\n",
      " [9.44825397e-01 5.51746032e-02]\n",
      " [6.78500000e-01 3.21500000e-01]\n",
      " [8.81666667e-01 1.18333333e-01]\n",
      " [5.06166667e-01 4.93833333e-01]\n",
      " [7.67722222e-01 2.32277778e-01]\n",
      " [8.34444444e-01 1.65555556e-01]\n",
      " [9.84103175e-01 1.58968254e-02]\n",
      " [1.20000000e-01 8.80000000e-01]\n",
      " [2.33333333e-02 9.76666667e-01]\n",
      " [8.70000000e-01 1.30000000e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [9.65222222e-01 3.47777778e-02]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [7.15222222e-01 2.84777778e-01]\n",
      " [9.40984127e-01 5.90158730e-02]\n",
      " [8.94952381e-01 1.05047619e-01]\n",
      " [8.34444444e-01 1.65555556e-01]\n",
      " [7.33904762e-01 2.66095238e-01]\n",
      " [7.51666667e-01 2.48333333e-01]\n",
      " [8.52785714e-01 1.47214286e-01]\n",
      " [9.43019841e-01 5.69801587e-02]\n",
      " [1.13333333e-01 8.86666667e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [2.88000000e-01 7.12000000e-01]\n",
      " [5.62150794e-01 4.37849206e-01]\n",
      " [8.00000000e-03 9.92000000e-01]\n",
      " [9.76666667e-01 2.33333333e-02]\n",
      " [8.95358919e-01 1.04641081e-01]\n",
      " [9.93666667e-01 6.33333333e-03]\n",
      " [4.66666667e-01 5.33333333e-01]\n",
      " [9.62222222e-01 3.77777778e-02]\n",
      " [9.76777778e-01 2.32222222e-02]\n",
      " [9.99166667e-01 8.33333333e-04]\n",
      " [9.63333333e-01 3.66666667e-02]\n",
      " [7.65595238e-01 2.34404762e-01]\n",
      " [8.91839947e-01 1.08160053e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [2.03333333e-01 7.96666667e-01]\n",
      " [9.49472222e-01 5.05277778e-02]\n",
      " [7.88888889e-01 2.11111111e-01]\n",
      " [5.62150794e-01 4.37849206e-01]\n",
      " [1.30000000e-01 8.70000000e-01]\n",
      " [5.66666667e-02 9.43333333e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [2.63986772e-01 7.36013228e-01]\n",
      " [3.86388889e-01 6.13611111e-01]\n",
      " [1.37777778e-01 8.62222222e-01]\n",
      " [9.59166667e-01 4.08333333e-02]\n",
      " [9.93000000e-01 7.00000000e-03]\n",
      " [7.27777778e-02 9.27222222e-01]\n",
      " [9.93666667e-01 6.33333333e-03]\n",
      " [4.87500000e-01 5.12500000e-01]\n",
      " [9.60166667e-01 3.98333333e-02]\n",
      " [9.59583333e-01 4.04166667e-02]\n",
      " [9.36666667e-01 6.33333333e-02]\n",
      " [1.73333333e-01 8.26666667e-01]\n",
      " [7.80000000e-01 2.20000000e-01]\n",
      " [3.68333333e-01 6.31666667e-01]\n",
      " [9.93333333e-01 6.66666667e-03]\n",
      " [6.66611111e-01 3.33388889e-01]\n",
      " [6.71491582e-01 3.28508418e-01]\n",
      " [2.40000000e-01 7.60000000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.00000000e-01 3.00000000e-01]\n",
      " [5.36666667e-01 4.63333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.27500000e-01 7.25000000e-02]\n",
      " [1.47769841e-01 8.52230159e-01]\n",
      " [8.80420635e-01 1.19579365e-01]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [2.63986772e-01 7.36013228e-01]\n",
      " [8.75833333e-01 1.24166667e-01]\n",
      " [8.62388889e-01 1.37611111e-01]\n",
      " [3.21666667e-01 6.78333333e-01]\n",
      " [7.75138889e-01 2.24861111e-01]\n",
      " [1.66666667e-03 9.98333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.40000000e-01 8.60000000e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.46880952e-01 1.53119048e-01]\n",
      " [9.85555556e-01 1.44444444e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.30473545e-01 3.69526455e-01]\n",
      " [8.75833333e-01 1.24166667e-01]\n",
      " [9.90000000e-01 1.00000000e-02]\n",
      " [3.02112434e-01 6.97887566e-01]\n",
      " [9.87777778e-01 1.22222222e-02]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [5.10000000e-01 4.90000000e-01]\n",
      " [1.06666667e-01 8.93333333e-01]\n",
      " [1.79166667e-02 9.82083333e-01]\n",
      " [9.08888889e-01 9.11111111e-02]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [2.63986772e-01 7.36013228e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.72222222e-01 2.77777778e-02]\n",
      " [9.98888889e-01 1.11111111e-03]\n",
      " [2.18833333e-01 7.81166667e-01]\n",
      " [9.83222222e-01 1.67777778e-02]\n",
      " [5.29111111e-01 4.70888889e-01]\n",
      " [6.56666667e-01 3.43333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [5.02361111e-01 4.97638889e-01]\n",
      " [2.66111111e-02 9.73388889e-01]\n",
      " [1.99166667e-01 8.00833333e-01]\n",
      " [9.59166667e-01 4.08333333e-02]\n",
      " [6.76666667e-01 3.23333333e-01]\n",
      " [8.58095238e-01 1.41904762e-01]\n",
      " [9.57444444e-01 4.25555556e-02]\n",
      " [8.91177249e-01 1.08822751e-01]\n",
      " [8.91177249e-01 1.08822751e-01]\n",
      " [9.79166667e-01 2.08333333e-02]\n",
      " [4.70000000e-01 5.30000000e-01]\n",
      " [7.65833333e-01 2.34166667e-01]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [1.86666667e-01 8.13333333e-01]\n",
      " [7.80000000e-01 2.20000000e-01]\n",
      " [8.47777778e-01 1.52222222e-01]\n",
      " [9.93194444e-01 6.80555556e-03]\n",
      " [9.99666667e-01 3.33333333e-04]\n",
      " [8.03388889e-01 1.96611111e-01]\n",
      " [2.24166667e-01 7.75833333e-01]\n",
      " [1.13333333e-01 8.86666667e-01]\n",
      " [8.97500000e-01 1.02500000e-01]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [3.40000000e-01 6.60000000e-01]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [6.80000000e-01 3.20000000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.33888889e-01 2.66111111e-01]\n",
      " [8.21111111e-01 1.78888889e-01]\n",
      " [9.35436508e-01 6.45634921e-02]\n",
      " [9.83333333e-01 1.66666667e-02]\n",
      " [6.60000000e-01 3.40000000e-01]\n",
      " [6.80555556e-01 3.19444444e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.54872146e-01 3.45127854e-01]\n",
      " [8.80420635e-01 1.19579365e-01]\n",
      " [5.02361111e-01 4.97638889e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.10000000e-01 9.00000000e-02]\n",
      " [9.86388889e-01 1.36111111e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [7.33333333e-02 9.26666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.78000000e-01 3.22000000e-01]\n",
      " [9.46666667e-01 5.33333333e-02]\n",
      " [5.00000000e-02 9.50000000e-01]\n",
      " [9.66666667e-01 3.33333333e-02]\n",
      " [7.89055556e-01 2.10944444e-01]\n",
      " [3.10126984e-01 6.89873016e-01]\n",
      " [6.35817460e-01 3.64182540e-01]\n",
      " [8.42333333e-01 1.57666667e-01]\n",
      " [7.23944444e-01 2.76055556e-01]\n",
      " [9.41690476e-01 5.83095238e-02]\n",
      " [9.33111111e-01 6.68888889e-02]\n",
      " [7.98928571e-01 2.01071429e-01]\n",
      " [6.87190476e-01 3.12809524e-01]\n",
      " [3.26613757e-01 6.73386243e-01]\n",
      " [9.98571429e-01 1.42857143e-03]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.66666667e-03 9.93333333e-01]\n",
      " [9.03567460e-01 9.64325397e-02]\n",
      " [5.16087302e-01 4.83912698e-01]\n",
      " [7.01293651e-01 2.98706349e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.16666667e-01 8.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.93333333e-01 6.66666667e-03]\n",
      " [3.66666667e-02 9.63333333e-01]\n",
      " [8.52785714e-01 1.47214286e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.80555556e-01 3.19444444e-01]\n",
      " [8.95358919e-01 1.04641081e-01]\n",
      " [5.97716931e-01 4.02283069e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.41166667e-01 5.88333333e-02]\n",
      " [6.92940476e-01 3.07059524e-01]\n",
      " [3.68333333e-01 6.31666667e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.50000000e-01 3.50000000e-01]\n",
      " [3.11666667e-01 6.88333333e-01]\n",
      " [8.88333333e-01 1.11666667e-01]\n",
      " [8.66666667e-01 1.33333333e-01]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [2.92777056e-01 7.07222944e-01]\n",
      " [9.98750000e-01 1.25000000e-03]\n",
      " [8.66666667e-02 9.13333333e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.23333333e-01 8.76666667e-01]\n",
      " [3.70000000e-01 6.30000000e-01]\n",
      " [9.34888889e-01 6.51111111e-02]\n",
      " [8.98492063e-01 1.01507937e-01]\n",
      " [8.76666667e-01 1.23333333e-01]\n",
      " [9.95916667e-01 4.08333333e-03]\n",
      " [6.50000000e-01 3.50000000e-01]\n",
      " [5.00000000e-02 9.50000000e-01]\n",
      " [9.96666667e-01 3.33333333e-03]\n",
      " [8.80420635e-01 1.19579365e-01]\n",
      " [9.76777778e-01 2.32222222e-02]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [8.49015873e-01 1.50984127e-01]\n",
      " [6.49333333e-01 3.50666667e-01]\n",
      " [9.20685185e-01 7.93148148e-02]\n",
      " [6.64789683e-01 3.35210317e-01]\n",
      " [8.32500000e-01 1.67500000e-01]\n",
      " [6.64789683e-01 3.35210317e-01]\n",
      " [6.78000000e-01 3.22000000e-01]\n",
      " [6.67925926e-01 3.32074074e-01]\n",
      " [9.83055556e-01 1.69444444e-02]\n",
      " [9.99666667e-01 3.33333333e-04]\n",
      " [9.67222222e-01 3.27777778e-02]\n",
      " [9.50000000e-01 5.00000000e-02]\n",
      " [9.40000000e-01 6.00000000e-02]\n",
      " [9.54055556e-01 4.59444444e-02]\n",
      " [9.99666667e-01 3.33333333e-04]\n",
      " [2.03333333e-01 7.96666667e-01]\n",
      " [9.85555556e-01 1.44444444e-02]\n",
      " [5.58611111e-01 4.41388889e-01]\n",
      " [7.39870370e-01 2.60129630e-01]\n",
      " [2.00000000e-02 9.80000000e-01]\n",
      " [9.87416667e-01 1.25833333e-02]\n",
      " [8.65880952e-01 1.34119048e-01]\n",
      " [3.15238095e-01 6.84761905e-01]\n",
      " [7.62666667e-01 2.37333333e-01]\n",
      " [9.86666667e-01 1.33333333e-02]\n",
      " [6.41678571e-01 3.58321429e-01]\n",
      " [9.58416667e-01 4.15833333e-02]\n",
      " [9.33111111e-01 6.68888889e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.76666667e-01 2.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [6.16666667e-02 9.38333333e-01]\n",
      " [3.33333333e-03 9.96666667e-01]\n",
      " [2.33333333e-02 9.76666667e-01]\n",
      " [9.60166667e-01 3.98333333e-02]\n",
      " [9.92777778e-01 7.22222222e-03]\n",
      " [9.62222222e-01 3.77777778e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [8.47222222e-03 9.91527778e-01]\n",
      " [9.43333333e-01 5.66666667e-02]\n",
      " [9.99166667e-01 8.33333333e-04]\n",
      " [9.01388889e-01 9.86111111e-02]\n",
      " [8.97388889e-01 1.02611111e-01]\n",
      " [9.91714286e-01 8.28571429e-03]\n",
      " [1.86666667e-01 8.13333333e-01]\n",
      " [6.77235450e-01 3.22764550e-01]\n",
      " [3.85555556e-01 6.14444444e-01]\n",
      " [2.34777778e-01 7.65222222e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.03000000e-01 9.70000000e-02]\n",
      " [8.72166667e-01 1.27833333e-01]\n",
      " [3.22000000e-01 6.78000000e-01]\n",
      " [9.04000000e-01 9.60000000e-02]\n",
      " [6.51357143e-01 3.48642857e-01]\n",
      " [9.93194444e-01 6.80555556e-03]\n",
      " [7.83333333e-01 2.16666667e-01]\n",
      " [4.96861241e-01 5.03138759e-01]\n",
      " [9.83888889e-01 1.61111111e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [5.73055556e-01 4.26944444e-01]\n",
      " [9.41333333e-01 5.86666667e-02]\n",
      " [9.31666667e-01 6.83333333e-02]\n",
      " [8.62579365e-01 1.37420635e-01]\n",
      " [8.32000000e-01 1.68000000e-01]\n",
      " [9.42648148e-01 5.73518519e-02]\n",
      " [7.13333333e-01 2.86666667e-01]\n",
      " [9.66666667e-01 3.33333333e-02]\n",
      " [9.41333333e-01 5.86666667e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.76666667e-01 2.33333333e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.97777778e-01 2.22222222e-03]\n",
      " [9.71187831e-01 2.88121693e-02]\n",
      " [3.06666667e-01 6.93333333e-01]\n",
      " [5.50579365e-01 4.49420635e-01]\n",
      " [9.65277778e-01 3.47222222e-02]\n",
      " [4.67619048e-01 5.32380952e-01]\n",
      " [9.98750000e-01 1.25000000e-03]\n",
      " [9.66666667e-01 3.33333333e-02]\n",
      " [9.99333333e-01 6.66666667e-04]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.56055556e-01 4.39444444e-02]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [5.50579365e-01 4.49420635e-01]\n",
      " [9.12484127e-01 8.75158730e-02]\n",
      " [7.93333333e-01 2.06666667e-01]\n",
      " [9.93333333e-01 6.66666667e-03]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.54989418e-01 2.45010582e-01]\n",
      " [2.33333333e-02 9.76666667e-01]\n",
      " [9.85000000e-01 1.50000000e-02]\n",
      " [9.81944444e-01 1.80555556e-02]\n",
      " [2.93333333e-01 7.06666667e-01]\n",
      " [9.06666667e-01 9.33333333e-02]\n",
      " [6.84166667e-01 3.15833333e-01]\n",
      " [3.46666667e-01 6.53333333e-01]\n",
      " [5.16666667e-01 4.83333333e-01]\n",
      " [1.09166667e-01 8.90833333e-01]\n",
      " [4.76666667e-01 5.23333333e-01]\n",
      " [3.66666667e-02 9.63333333e-01]\n",
      " [9.45000000e-01 5.50000000e-02]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [5.56907407e-01 4.43092593e-01]\n",
      " [6.56099206e-01 3.43900794e-01]\n",
      " [5.05714286e-01 4.94285714e-01]\n",
      " [8.47222222e-03 9.91527778e-01]\n",
      " [7.60000000e-01 2.40000000e-01]\n",
      " [6.74388889e-01 3.25611111e-01]\n",
      " [8.46666667e-01 1.53333333e-01]\n",
      " [1.12500000e-01 8.87500000e-01]\n",
      " [9.32777778e-02 9.06722222e-01]\n",
      " [6.69583333e-01 3.30416667e-01]\n",
      " [6.70997354e-01 3.29002646e-01]\n",
      " [6.00000000e-02 9.40000000e-01]\n",
      " [1.31190476e-01 8.68809524e-01]\n",
      " [4.24285714e-01 5.75714286e-01]\n",
      " [7.52161376e-01 2.47838624e-01]\n",
      " [7.86432540e-01 2.13567460e-01]\n",
      " [7.15222222e-01 2.84777778e-01]\n",
      " [2.13333333e-01 7.86666667e-01]\n",
      " [2.03333333e-01 7.96666667e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.83888889e-01 1.61111111e-02]\n",
      " [3.40000000e-01 6.60000000e-01]\n",
      " [5.23988095e-01 4.76011905e-01]\n",
      " [5.32083333e-01 4.67916667e-01]\n",
      " [5.59071429e-01 4.40928571e-01]\n",
      " [7.25000000e-01 2.75000000e-01]\n",
      " [9.43333333e-01 5.66666667e-02]\n",
      " [9.80555556e-01 1.94444444e-02]\n",
      " [1.57777778e-01 8.42222222e-01]\n",
      " [9.76873016e-01 2.31269841e-02]\n",
      " [8.96888889e-01 1.03111111e-01]\n",
      " [3.30000000e-01 6.70000000e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [8.63333333e-01 1.36666667e-01]\n",
      " [6.66666667e-02 9.33333333e-01]\n",
      " [6.25059524e-01 3.74940476e-01]\n",
      " [1.00000000e-02 9.90000000e-01]\n",
      " [5.58611111e-01 4.41388889e-01]\n",
      " [5.48686508e-01 4.51313492e-01]\n",
      " [6.83003968e-01 3.16996032e-01]\n",
      " [9.77936508e-01 2.20634921e-02]\n",
      " [1.93333333e-01 8.06666667e-01]\n",
      " [1.56666667e-01 8.43333333e-01]\n",
      " [9.98888889e-01 1.11111111e-03]\n",
      " [2.93333333e-01 7.06666667e-01]\n",
      " [5.50579365e-01 4.49420635e-01]]\n",
      "     index    y_pred\n",
      "0     1491  0.873333\n",
      "1     1492  0.853333\n",
      "2     1493  0.148333\n",
      "3     1494  0.317222\n",
      "4     1495  0.033889\n",
      "..     ...       ...\n",
      "491   1982  0.806667\n",
      "492   1983  0.843333\n",
      "493   1984  0.001111\n",
      "494   1985  0.706667\n",
      "495   1986  0.449421\n",
      "\n",
      "[496 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P210304-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P210304-02.csv')\n",
    "\n",
    "# 종속 변수를 범주형으로 만들기\n",
    "df1['TravelInsurance'] = df1['TravelInsurance'].astype('category')\n",
    "\n",
    "# 독립 변수, 종속 변수 구별\n",
    "x = df1.drop('TravelInsurance', axis=1)    # 독립 변수\n",
    "y = df1['TravelInsurance']   # 종속 변수\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x = x.drop('X', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_valid)\n",
    "\n",
    "# 성능 평가\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred))\n",
    "print(recall_score(y_valid, pred))\n",
    "print(precision_score(y_valid, pred))\n",
    "print(f1_score(y_valid, pred))\n",
    "print(roc_auc_score(y_valid, pred))\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('X', axis=1)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "# 평가\n",
    "pred = md.predict_proba(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'index': df2['X'],\n",
    "    'y_pred': pred[:, 1]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 3 (22년 4회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 자동차 보험 회사는 새로운 전략을 수립하기 위해 고객을 4가지로 분류(A, B, C, D)로 세분화 하였다.\n",
    "- 기존 고객에 대한 분류(`P220404-01.csv`)를 바탕으로 신규 고객(`P220404-02.csv`)이 어떤 분류에 속할지 예측하여 제출하기\n",
    "\n",
    "```text\n",
    "평가 : Macro F1-score\n",
    "예측할 값 : Segmentation\n",
    "제출되는 파일은 테스트 데이터의 행의 수와 같아야 함.\n",
    "```\n",
    "\n",
    "\n",
    "|ID|pred|\n",
    "|:-:|:-:|\n",
    "|1|A|\n",
    "|2|B|\n",
    "|3|C|\n",
    "|...|...|\n",
    "|1500|D|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'D' 'A' ... 'B' 'A' 'A']\n",
      "[[152 111  46  73]\n",
      " [ 91 120 113  42]\n",
      " [ 58 113 222  25]\n",
      " [ 87  56  48 310]]\n",
      "0.47106737801769927\n",
      "['B' 'C' 'C' ... 'B' 'C' 'D']\n",
      "          ID pred\n",
      "0     458989    B\n",
      "1     458994    C\n",
      "2     459000    C\n",
      "3     459003    C\n",
      "4     459005    A\n",
      "...      ...  ...\n",
      "2149  467950    A\n",
      "2150  467954    D\n",
      "2151  467958    B\n",
      "2152  467961    C\n",
      "2153  467968    D\n",
      "\n",
      "[2154 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P220404-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P220404-02.csv')\n",
    "\n",
    "# 자료형 변환\n",
    "df1['Segmentation'] = df1['Segmentation'].astype('category')   # object -> category\n",
    "\n",
    "# 독립 변수, 종속 변수 나누기\n",
    "x = df1.drop('Segmentation', axis=1)   # 독립 변수\n",
    "y = df1['Segmentation']   # 종속 변수\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x = x.drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# 성능 평가\n",
    "cm = confusion_matrix(y_valid, pred, labels=['A', 'B', 'C', 'D'])\n",
    "print(cm)\n",
    "\n",
    "print(f1_score(y_valid, pred, average='macro'))\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)   # 원-핫 인코딩\n",
    "\n",
    "pred = md.predict(x_test_encoded)    # 예측\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'pred': pred[:]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 4 (22년 5회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주어진 훈련 데이터를 이용하여 중고 차량 가격(`price`)을 예측하는 모형을 만들고, 테스트 데이터를 이용하여 중고 차량 가격을 예측하여 제출하기\n",
    "\n",
    "```text\n",
    "평가 : RMSE\n",
    "제출되는 파일은 테스트 데이터의 행의 수와 같아야 함.\n",
    "```\n",
    "\n",
    "|pred|\n",
    "|:-:|\n",
    "|1230|\n",
    "|2562|\n",
    "|...|\n",
    "|3761|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651.631597158918\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P220504-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P220504-02.csv')\n",
    "\n",
    "# 독립 변수, 종속 변수 나누기\n",
    "x = df1.drop('price', axis=1)  # 독립 변수\n",
    "y = df1['price']\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "x_test_encoded = pd.get_dummies(df2)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 검증 데이터 예측 및 평가\n",
    "pred_valid = md.predict(x_valid)\n",
    "rmse = root_mean_squared_error(y_valid, pred_valid)   # scikit-learn 1.4 버전 이상에서 사용 가능\n",
    "print(rmse)\n",
    "\n",
    "# 공통 피쳐 처리\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)   # 빈 컬럼의 값은 0으로 넣기\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "pred_test = md.predict(x_test_encoded)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred_test\n",
    "})\n",
    "result.to_csv('./outputs/20240615_Q4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 5 (23년 6회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모바일 데이터 세트\n",
    "- 분류 모델을 사용하여 `price_range` 값을 예측하려고 한다.\n",
    "- `P230604-01.csv` 파일의 학습 데이터로 모델을 생성하고 `P230604-02.csv` 파일의 평가 데이터로 평가하여 예측하기\n",
    "\n",
    "```text\n",
    "Macro F1 Score로 평가\n",
    "feature engineering, 하이퍼파라미터 최적화 등을 수행할 수 있으며, 과대적합이 발생할 수 있다.\n",
    "```\n",
    "\n",
    "|pred|\n",
    "|:-:|\n",
    "|2|\n",
    "|3|\n",
    "|0|\n",
    "|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 3 0 2 0 2 2 1 1 2 0 3 1 2 0 3 3 0 0 3 0 0 0 2 3 2 1 0 2 0 2 2 3 1\n",
      " 2 1 0 2 1 2 3 2 1 2 3 2 2 0 0 0 3 2 1 3 1 3 3 0 0 1 3 0 0 0 0 2 3 2 3 2 0\n",
      " 3 2 2 0 0 3 1 2 1 1 0 1 3 0 1 3 3 1 1 1 2 2 2 2 0 1 2 0 0 1 2 0 1 1 1 1 0\n",
      " 1 1 3 1 0 1 3 1 0 3 2 0 0 2 1 0 2 2 1 1 0 3 0 1 1 2 2 3 1 1 0 2 1 2 0 0 1\n",
      " 2 0 2 0 1 2 2 3 1 2 3 3 1 0 1 0 1 2 1 0 3 0 1 1 0 1 2 1 0 3 2 1 2 2 1 0 1\n",
      " 2 2 3 0 3 1 3 0 0 0 2 1 1 1 3 3 2 1 1 0 2 1 2 0 1 0 3 3 3 0 0 1 2 1 1 2 1\n",
      " 2 0 3 2 3 3 0 1 3 1 0 3 1 0 0 1 2 3 1 1 1 3 0 2 2 3 0 1 2 3 3 0 3 1 0 2 0\n",
      " 3 0 3 0 0 0 1 3 1 1 0 1 3 1 0 2 1 2 2 1 3 3 1 1 0 2 1 3 1 3 3 3 2 2 1 1 1\n",
      " 2 3 1 2 2 3 2 3 1 3 0 2 0 0 2 2 0 1 3 3 3 2 3 3 3 3 2 1 3 0 2 1 1 0 1 3 1\n",
      " 3 3 3 0 3 1 2 2 0 0 2 3 1 3 3 0 0 2 1 0 0 2 0 0 2 2 0 0 1 1 3 2 0 2 1 2 2\n",
      " 1 3 2 2 2 3 3 3 1 1 0 3 3 2 2 3 1 3 2 3 3 0 3 3 3 3 0 0 1 1 2 3 2 0 1 2 3\n",
      " 1 1 1 0 3 1 1 0 0 1 3 3 3 0 0 0 0 0 3 2 3 0 3 3 2 0 0 1 2 1 2 2 0 2 3 0 2\n",
      " 3 2 2 3 2 2 3 2 2 1 3 3 2 3 3 1 2 0 0 1 2 0 0 3 3 1 3 1 2 1 1 0 1 2 0 2 0\n",
      " 2 1 3 0 3 3 2 0 0 3 0 2 2 3 0 1 1 0 2]\n",
      "[[119   3   0   0]\n",
      " [  7 110  11   0]\n",
      " [  0  15 108   7]\n",
      " [  0   0   5 115]]\n",
      "0.9049648358206841\n",
      "[3 3 2 3 1 3 3 1 3 0 3 3 0 0 2 0 2 1 3 2 1 3 1 1 3 0 2 0 2 0 2 0 3 0 0 1 3\n",
      " 1 2 1 1 2 0 0 0 1 0 3 1 2 1 0 3 0 3 1 3 1 1 3 3 2 0 1 1 1 1 3 1 2 1 2 2 3\n",
      " 3 0 2 0 2 3 0 3 3 0 3 0 3 1 3 0 1 1 2 1 2 1 0 2 1 2 1 0 0 3 1 2 0 1 2 3 3\n",
      " 3 1 3 3 3 3 1 3 0 0 3 2 1 2 0 3 2 3 1 0 1 1 1 3 1 1 0 3 2 1 3 1 2 2 3 3 2\n",
      " 2 3 2 3 0 0 2 2 3 3 3 3 2 2 3 3 3 3 1 0 3 0 0 0 1 1 0 1 0 0 1 2 0 0 0 1 2\n",
      " 2 2 1 0 0 0 1 0 3 1 0 2 2 2 3 1 2 3 3 3 1 2 0 0 0 1 2 1 2 3 3 0 2 0 3 2 2\n",
      " 3 0 0 1 0 3 0 1 0 2 2 1 3 0 3 0 3 1 2 0 0 2 1 3 3 3 1 1 3 0 0 2 3 3 1 3 1\n",
      " 1 3 2 1 2 3 3 3 1 0 1 2 3 1 1 3 2 0 3 0 1 2 0 0 3 2 3 3 2 1 3 3 2 3 2 2 1\n",
      " 1 0 2 3 1 0 0 3 0 3 0 1 2 0 2 3 1 3 2 2 1 2 0 0 0 1 3 2 0 0 0 3 2 0 3 3 1\n",
      " 2 3 2 3 1 3 3 2 2 3 3 3 0 3 0 3 1 3 1 3 3 0 1 1 3 1 3 2 3 0 0 0 0 2 0 0 1\n",
      " 1 1 2 3 2 0 1 0 0 3 2 0 3 1 2 2 1 2 3 1 1 2 2 1 2 0 1 1 0 3 2 0 0 1 0 0 1\n",
      " 1 0 0 0 2 2 3 2 3 0 3 0 3 0 1 1 1 1 0 3 2 3 3 1 3 1 3 1 3 2 1 2 2 1 1 0 0\n",
      " 0 1 2 1 0 3 2 0 2 3 0 0 2 1 1 1 2 2 3 0 3 0 2 3 3 3 0 2 0 1 3 0 1 1 0 0 1\n",
      " 1 1 3 3 3 2 3 1 1 2 3 3 3 1 0 2 2 2 2 1 0 2 3 0 0 0 3 1 1 2 2 2 0 3 0 2 2\n",
      " 0 3 0 2 3 0 1 1 3 3 1 1 2 3 2 0 2 1 2 0 3 3 1 3 2 2 3 0 1 2 3 1 3 2 3 1 0\n",
      " 1 0 3 1 0 3 2 3 2 0 3 3 3 2 3 3 1 2 0 2 3 3 0 0 1 1 2 2 2 0 0 2 2 3 2 0 2\n",
      " 1 3 3 0 1 3 1 2 1 0 0 0 2 1 0 1 1 2 2 0 2 2 1 0 3 0 0 3 2 0 0 0 0 0 3 0 3\n",
      " 1 3 2 1 3 2 0 1 1 3 2 3 1 0 3 0 2 0 2 0 0 1 1 1 2 1 3 1 3 2 2 1 3 2 0 1 2\n",
      " 0 3 3 0 2 1 1 2 0 3 2 0 3 2 3 0 0 3 0 1 2 3 2 2 2 2 1 2 3 0 1 1 1 2 1 0 0\n",
      " 1 0 0 3 0 1 1 0 1 1 0 3 0 3 2 3 0 0 1 2 2 1 0 1 1 0 1 1 0 0 3 3 0 3 1 2 3\n",
      " 0 1 0 2 2 0 3 1 0 3 0 1 0 3 3 3 2 3 0 3 2 0 1 0 3 3 2 0 2 1 3 1 0 3 2 0 3\n",
      " 1 2 1 1 1 3 1 1 1 2 0 0 1 2 0 2 0 0 0 0 3 3 3 3 0 1 2 1 1 0 0 2 1 0 2 0 2\n",
      " 2 2 1 2 0 2 1 3 0 0 3 1 3 0 0 2 3 3 1 3 2 1 0 0 2 3 1 3 0 0 0 2 2 1 3 0 3\n",
      " 2 1 2 3 3 0 1 1 2 1 2 2 0 1 3 1 1 3 1 2 3 1 1 1 2 3 3 0 2 3 0 2 3 2 2 2 3\n",
      " 2 0 1 2 0 2 1 1 2 2 2 1 2 0 0 1 3 1 0 1 2 3 1 0 0 3 2 2 3 0 3 3 2 1 3 0 1\n",
      " 3 1 2 1 2 2 2 0 3 0 2 3 0 3 1 3 3 1 0 2 3 1 0 1 1 2 1 3 0 2 2 0 2 3 2 3 0\n",
      " 2 1 1 2 2 3 3 0 2 1 2 1 3 0 1 3 0 1 0 0 3 2 2 0 0 0 0 3 2 3 3 0 0 2 1 0 2\n",
      " 2]\n",
      "     pred\n",
      "0       3\n",
      "1       3\n",
      "2       2\n",
      "3       3\n",
      "4       1\n",
      "..    ...\n",
      "995     2\n",
      "996     1\n",
      "997     0\n",
      "998     2\n",
      "999     2\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P230604-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P230604-02.csv')\n",
    "\n",
    "# 독립 변수, 종속 변수 분리\n",
    "x = df1.drop('price_range', axis=1)\n",
    "y = df1['price_range']\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# 성능 평가\n",
    "cm = confusion_matrix(y_valid, pred)\n",
    "print(cm)\n",
    "\n",
    "print(f1_score(y_valid, pred, average='macro'))  # Macro F1 Score\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('id', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)  # 원-핫 인코딩\n",
    "\n",
    "pred = md.predict(x_test_encoded)   # 예측\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20240615_Q5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 6 (23년 7회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 제주 업종별 카드 이용 정보 데이터\n",
    "- 종속 변수 : 이용금액\n",
    "- 평가 지표 : RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.75328097e+06 9.88669042e+08 1.00307781e+09 3.46754489e+09\n",
      " 3.50359333e+05 2.47077573e+08 1.53050946e+06 2.02290687e+08\n",
      " 7.63515613e+06 4.14832637e+08 4.60308856e+07 8.03569754e+07\n",
      " 4.99999046e+08 1.08230370e+09 3.52369359e+09 4.28967358e+08\n",
      " 4.68753858e+08 2.45895745e+08 8.80266625e+08 7.94647044e+08\n",
      " 3.60605573e+08 6.66128622e+07 4.63779523e+08 4.53275136e+08\n",
      " 1.19942736e+08 1.32362557e+09 5.64756849e+07 7.38848675e+07\n",
      " 2.30393298e+08 7.38583838e+08 2.31588662e+08 2.81260002e+09\n",
      " 6.30175678e+07 4.54360437e+09 2.03543795e+08 4.22146487e+08\n",
      " 8.38410195e+09 2.29815648e+08 4.59020265e+08 1.58205648e+07\n",
      " 2.52170893e+07 2.12914215e+06 5.99647593e+06 2.84414939e+08\n",
      " 6.51855607e+07 5.22517574e+07 1.44985075e+06 2.07479952e+07\n",
      " 2.14828777e+06 2.55824658e+08 4.45256727e+08 3.82658173e+06\n",
      " 3.38981478e+08 5.61439118e+08 1.17094138e+09 1.83028991e+09\n",
      " 1.84607987e+08 3.70020675e+07 5.09377733e+05 2.57278429e+07\n",
      " 7.51352267e+05 1.31278954e+08 3.39226081e+08 4.49827141e+08\n",
      " 5.71685338e+07 1.03679745e+08 7.83088420e+06 2.42212811e+06\n",
      " 2.24704021e+08 5.55729851e+06 1.24833777e+09 3.55048302e+08\n",
      " 4.00108081e+07 4.91525791e+08 5.04156377e+07 1.14819927e+06\n",
      " 1.90065648e+07 9.00207447e+07 3.15116819e+06 8.31767783e+08\n",
      " 3.97118030e+06 6.94110580e+08 1.13913617e+06 9.54923006e+07\n",
      " 5.57375386e+08 3.42618888e+06 9.97042466e+07 3.34088482e+08\n",
      " 1.16337040e+08 1.36530691e+08 7.87395199e+07 1.93456524e+08\n",
      " 2.74389133e+06 8.70234070e+06 1.49829758e+08 2.85673745e+09\n",
      " 7.28303364e+06 3.36544208e+06 2.42874334e+08 1.46340538e+07\n",
      " 2.08858754e+08 3.32845857e+08 6.48842983e+07 3.03813932e+08\n",
      " 3.32069009e+08 1.56259385e+08 1.26036993e+08 1.75044450e+08\n",
      " 7.19270633e+08 1.02915968e+07 5.12599681e+07 4.36186100e+05\n",
      " 5.72908675e+08 5.31289751e+08 1.26259483e+07 4.15478675e+08\n",
      " 2.93605913e+06 2.39597095e+09 1.06948576e+09 3.90286278e+08\n",
      " 3.35987587e+09 6.56076437e+06 9.23519254e+09 5.00823926e+09\n",
      " 1.52381358e+08 1.06505464e+09 1.43834340e+08 2.71365600e+09\n",
      " 4.09596584e+09 9.01282800e+05 3.98505484e+07 5.33408628e+08\n",
      " 1.01291476e+10 1.75457629e+09 5.21591249e+09 1.93874440e+08\n",
      " 9.69794780e+07 2.70560684e+09 3.62995591e+08 3.30236322e+09\n",
      " 1.06316417e+08 2.76450870e+06 4.38149507e+05 4.14788124e+07\n",
      " 4.69788017e+06 3.67339144e+07 4.25649428e+08 3.48183007e+08\n",
      " 3.84322743e+08 1.09364245e+09 4.36159560e+09 3.44111393e+08\n",
      " 1.43980724e+08 3.42070358e+08 1.48020460e+09 3.60364613e+08\n",
      " 4.80629591e+09 1.25094248e+09 7.88713646e+07 6.16872313e+08\n",
      " 1.14075765e+09 1.60236675e+08 1.22403894e+09 4.68418353e+08\n",
      " 4.75809472e+08 9.91257054e+06 4.09660552e+08 2.33867300e+06\n",
      " 9.36647508e+08 2.27124500e+05 3.69660833e+05 5.08878969e+08\n",
      " 1.06824177e+07 6.21798488e+09 3.13767954e+08 1.22319638e+07\n",
      " 1.88706588e+09 6.12264295e+08 5.73791769e+07 2.66788770e+08\n",
      " 1.83341912e+09 2.42536493e+08 5.66435777e+07 3.54740106e+08\n",
      " 1.94805307e+08 8.33003500e+05 6.48866479e+07 3.86794933e+06\n",
      " 4.59759923e+08 1.65792604e+06 1.27206291e+09 6.71887392e+08\n",
      " 5.15509635e+08 7.18234453e+06 1.49320995e+06 1.02883826e+08\n",
      " 1.72438294e+08 5.72089249e+08 8.75676053e+07 6.46057148e+09\n",
      " 4.95907475e+06 7.56220087e+07 1.62551943e+07 5.89436091e+08\n",
      " 5.83907893e+08 3.64674950e+08 1.28335402e+08 4.82095465e+07\n",
      " 4.64395180e+08 4.44470826e+08 5.72333700e+05 3.60199000e+05\n",
      " 5.57335430e+08 1.38260160e+09 3.31457601e+09 6.31138202e+06\n",
      " 1.33332443e+08 2.14015741e+08 6.20715433e+05 4.22096823e+08\n",
      " 1.78445488e+08 2.76329255e+06 1.20953347e+08 4.77075037e+09\n",
      " 9.82216654e+08 1.68104809e+08 1.73172948e+09 3.08614996e+09\n",
      " 1.30924587e+09 1.62075018e+09 4.09726233e+05 4.67323133e+06\n",
      " 1.08208738e+07 1.96591982e+06 5.14605574e+09 4.57846900e+05\n",
      " 2.89778914e+08 1.20091754e+09 9.77735626e+08 1.01673104e+09\n",
      " 1.65222895e+09 1.35965830e+06 3.16303999e+06 1.16147282e+09\n",
      " 1.11180359e+09 3.37330362e+07 4.96868217e+07 2.33753891e+06\n",
      " 5.48467995e+08 9.96493498e+08 6.08536102e+07 4.14052776e+08\n",
      " 4.00325801e+06 9.82135839e+08 6.71828031e+07 9.54073773e+08\n",
      " 1.86382057e+08 5.64634558e+06 4.55788075e+06 6.44372315e+08\n",
      " 1.52262604e+08 3.42942220e+08 1.77476583e+09 2.13205525e+08\n",
      " 3.64828663e+08 3.49482721e+09 3.36402694e+08 3.03670083e+09\n",
      " 9.26876896e+08 8.09708307e+06 3.26848456e+09 8.91258891e+08\n",
      " 5.53276779e+07 2.71480313e+06 8.10643600e+05 4.30804220e+09\n",
      " 4.77444539e+07 2.01706459e+08 2.10104612e+09 4.27199185e+08\n",
      " 6.04613569e+08 3.31249267e+05 1.03588868e+08 2.14209360e+07\n",
      " 2.34523397e+08 4.27314578e+08 7.70795724e+08 4.58154636e+08\n",
      " 5.86199673e+08 1.46782459e+09 1.75667611e+09 9.28034868e+06\n",
      " 4.36720316e+06 4.28284772e+09 1.55724319e+09 3.31684034e+09\n",
      " 9.15074177e+07 6.07935116e+08 1.51200620e+09 7.46162506e+08\n",
      " 2.97635573e+07 1.22555619e+08 4.41705134e+08 3.71803262e+07\n",
      " 4.21475718e+08 4.25507250e+06 1.90229297e+06 4.19993310e+06\n",
      " 9.13594765e+08 1.16157945e+09 6.71121316e+08 4.40781208e+08\n",
      " 4.98549389e+09 1.79432740e+07 1.58916287e+09 1.50223951e+08\n",
      " 1.34106646e+08 8.83942484e+08 1.58314036e+09 9.83937906e+09\n",
      " 7.93980983e+09 4.13762794e+09 1.58766349e+07 4.86458042e+08\n",
      " 5.52328805e+08 9.95598608e+07 2.12305430e+06 4.59563769e+08\n",
      " 5.61347553e+08 4.82134809e+08 5.62209301e+09 1.57927570e+09\n",
      " 4.46923422e+09 3.19877423e+08 3.35271598e+06 2.93167930e+09\n",
      " 4.52006636e+08 7.14230473e+08 1.27200506e+09 4.19845463e+08\n",
      " 4.34336770e+08 3.65176645e+08 8.76886940e+05 3.24390893e+08\n",
      " 9.92668759e+07 1.55137795e+08 1.83257012e+08 2.15889416e+09\n",
      " 1.10986628e+08 5.93334017e+07 3.63785479e+08 1.15864563e+08\n",
      " 4.30144107e+08 1.32531229e+08 1.64236119e+09 2.81561210e+08\n",
      " 6.32799736e+09 1.42235612e+07 2.12806489e+09 4.76437415e+08\n",
      " 8.07936286e+08 3.24309458e+09 5.89375665e+08 7.96278052e+07\n",
      " 3.53489047e+08 4.97676833e+05 4.12904452e+09 4.37279138e+08\n",
      " 2.21669833e+08 1.30801409e+08 5.30813113e+09 3.76844123e+09\n",
      " 3.74024100e+06 9.94590795e+09 4.98411824e+07 1.66944265e+07\n",
      " 2.74085676e+08 1.30834966e+08 2.83727222e+09 1.83567813e+08\n",
      " 4.18986007e+08 3.89385418e+08 9.93428915e+07 8.34138814e+08\n",
      " 3.07438933e+05 8.36829046e+08 9.74816408e+08 9.54775658e+07\n",
      " 5.23320913e+08 8.09037326e+08 1.60649651e+09 1.04923012e+09\n",
      " 8.57465730e+09 7.82073357e+09 3.37899089e+08 2.76951019e+08\n",
      " 4.78110167e+05 2.63679474e+08 3.53539006e+07 4.54281426e+08\n",
      " 9.16177418e+06 4.10234284e+08 1.12144838e+09 4.68899660e+06\n",
      " 5.21060967e+05 7.97262119e+08 1.39008626e+06 1.88386516e+09\n",
      " 8.88762422e+07 4.77444764e+08 9.22392274e+08 7.03345718e+08\n",
      " 2.63164340e+09 4.98788420e+09 6.30283234e+07 1.23468700e+06\n",
      " 6.17546673e+05 2.98711803e+08 5.30643507e+09 5.29093743e+08\n",
      " 6.96365731e+08 1.54494976e+09 2.83395838e+07 5.23719622e+08\n",
      " 1.65344960e+09 3.63017094e+08 1.65318210e+09 3.52956764e+08\n",
      " 7.38943633e+05 4.63337750e+08 9.71627862e+08 1.86562659e+09\n",
      " 6.12535855e+07 9.97800855e+08 9.55807708e+09 9.63567594e+07\n",
      " 2.04405619e+09 1.63221394e+09 1.00524203e+06 2.42947860e+08\n",
      " 9.29369132e+06 1.59183994e+09 5.08313579e+09 1.73452533e+09\n",
      " 1.49984447e+08 2.76400375e+08 1.00741304e+08 2.55666032e+08\n",
      " 5.05117859e+07 5.04827065e+09 5.28139324e+07 4.46079536e+08\n",
      " 7.56834996e+07 4.04452930e+06 1.09817443e+09 1.49323362e+09\n",
      " 4.56040151e+08 3.50803682e+07 1.95717815e+08 3.98631258e+07\n",
      " 8.39666937e+08 1.87926949e+06 3.48656503e+09 3.59289016e+08\n",
      " 5.84388013e+05 4.62942355e+08 7.59119388e+08 8.73444837e+07\n",
      " 3.49863557e+08 9.85496659e+06 9.09086856e+09 3.42510586e+08\n",
      " 6.59524422e+09 4.06482230e+07 2.55260693e+08 3.40806318e+09\n",
      " 1.25127940e+09 9.53921332e+07 4.11734904e+08 2.77182157e+08\n",
      " 3.78029133e+08 3.48173084e+08 2.70118707e+08 2.96124608e+07\n",
      " 4.71070016e+07 1.01070716e+08 7.29171110e+07 1.92432168e+08\n",
      " 3.19885569e+08 1.58486195e+09 1.05215082e+09 1.80926170e+09\n",
      " 9.10351143e+06 1.75579780e+08 2.30001261e+08 3.66573567e+05\n",
      " 4.46627497e+07 9.35842012e+09 4.64582171e+08 1.53210448e+08\n",
      " 7.73582145e+07 5.91724467e+05 5.90128603e+07 1.48061110e+08\n",
      " 2.21134457e+08 9.87526882e+07 7.58739621e+07 1.60255142e+08\n",
      " 7.41529300e+05 2.70291486e+08 4.09426397e+08 5.06208102e+08\n",
      " 1.74127475e+09 1.98888947e+07 1.06419972e+09 4.95154547e+09\n",
      " 8.77163547e+05 4.26151147e+08 2.93618067e+05 3.71171155e+08\n",
      " 4.14244702e+09 1.94554306e+07 5.48087328e+09 1.12999209e+07\n",
      " 5.15658509e+08 3.47706678e+08 1.11990306e+07 4.33853931e+08\n",
      " 7.12995861e+08 8.89511985e+07 1.91192804e+07 3.69896600e+05\n",
      " 1.70350654e+09 2.54759618e+08 6.19962758e+08 5.16297667e+05\n",
      " 1.01634111e+09 3.80807933e+05 2.99713112e+07 3.52475501e+08\n",
      " 4.79426520e+08 3.44014991e+09 5.37407020e+05 4.45000315e+08\n",
      " 9.49937563e+08 1.04386739e+09 4.37649103e+08 1.34127720e+09\n",
      " 1.49853249e+08 2.62387692e+08 1.10087917e+09 3.61624842e+07\n",
      " 8.09879318e+07 1.00342734e+07 3.04010881e+08 2.95047504e+06\n",
      " 2.27769874e+07 2.98149651e+09 4.25080475e+08 1.25653292e+08\n",
      " 1.00465500e+06 4.68594580e+08]\n",
      "171673450.02128342\n",
      "[6.03154368e+09 4.06901901e+07 2.43867567e+06 ... 5.50099992e+09\n",
      " 9.76408876e+08 6.69997977e+08]\n",
      "           ID         price\n",
      "0     ID_2575  6.031544e+09\n",
      "1     ID_6637  4.069019e+07\n",
      "2     ID_5704  2.438676e+06\n",
      "3     ID_3606  1.516398e+06\n",
      "4     ID_6443  6.364775e+05\n",
      "...       ...           ...\n",
      "5015  ID_4523  4.680746e+08\n",
      "5016  ID_3483  1.051279e+08\n",
      "5017   ID_453  5.501000e+09\n",
      "5018   ID_998  9.764089e+08\n",
      "5019  ID_3237  6.699980e+08\n",
      "\n",
      "[5020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/P230704-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P230704-02.csv')\n",
    "\n",
    "\n",
    "# 독립 변수, 종속 변수 분리\n",
    "x = df1.drop('이용금액', axis=1)\n",
    "y = df1['이용금액']\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x = x.drop('ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# 성능 평가\n",
    "result = root_mean_squared_error(y_valid, pred)   # RMSE\n",
    "print(result)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('ID', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "pred = md.predict(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'ID': df2['ID'],\n",
    "    'price': pred,\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>결정나무(Decision Tree)계열의 모델(랜덤 포레스트 등)은 <b>범주형 데이터(Object)</b> 를 라벨 인코딩(Label Encoding)하면 된다. </p>\n",
    "    <p>그리고 변수 스케일 변환을 하지 않아도 된다.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit   color  weight  fruit_encoded  color_encoded\n",
      "0   apple     red     1.2              0              1\n",
      "1  banana  yellow     2.5              1              2\n",
      "2   apple   green     1.3              0              0\n",
      "3  banana  yellow     2.4              1              2\n",
      "4  cherry     red     1.0              2              1\n",
      "5  cherry     red     1.2              2              1\n",
      "6   apple   green     1.1              0              0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 샘플 데이터프레임 생성\n",
    "data = {\n",
    "    'fruit': ['apple', 'banana', 'apple', 'banana', 'cherry', 'cherry', 'apple'],\n",
    "    'color': ['red', 'yellow', 'green', 'yellow', 'red', 'red', 'green'],\n",
    "    'weight': [1.2, 2.5, 1.3, 2.4, 1.0, 1.2, 1.1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fruit 컬럼에 LabelEncoder 적용\n",
    "df['fruit_encoded'] = le.fit_transform(df['fruit'])\n",
    "\n",
    "# color 컬럼에 LabelEncoder 적용\n",
    "df['color_encoded'] = le.fit_transform(df['color'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p><b>라벨 인코더(Label Encoder)</b>는 순서형 데이터, 트리 기반 모델(Decision Tree, Random Forest, XGBoost 등), 범주의 개수가 많고 희소 행렬을 피하고 싶을 때 사용하면 좋다..</p>\n",
    "    <p><b>원핫 인코더(OneHot Encoder)</b>는 순서가 없는 데이터, 선형 모델(Logistic Regression, SVM 등), 신경망 모델, 범주의 개수가 적을 때 사용하면 좋다.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 7 (24년 8회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 종속 변수 : 지하철역 인원수\n",
    "- 평가지표 : MAE(Mean Absolute Error)\n",
    "    - 예측값과 실제값 간의 절대 오차의 평균 계산\n",
    "        - $MAE = \\frac{1}{n} \\sum^{n}_{i=1} |y_i - \\hat{y_i}|$\n",
    "    - 값이 작을수록 모델 성능이 좋다. (Error 이므로)\n",
    "    - 특징\n",
    "        - 직관적 해석 가능\n",
    "        - 모델의 이상값에 민감하지 않음. (절댓값 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p>종속 변수가 인원수이므로 회귀 문제였고, 범주형 컬럼들이 있어서 원-핫 인코딩을 사용한다. (MAE 104 정도) </p>\n",
    "    <p><code>name</code> 컬럼을 뺄 경우, <code>x_test</code> 개수가 맞지 않아서 포함시켜서 해야 한다. </p>\n",
    "    <p>참고 사이트 : <a href=\"https://data-fox.tistory.com/41\">Blog Post</a></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 8)\n",
      "(300, 7)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           900 non-null    object \n",
      " 1   day_of_week    900 non-null    object \n",
      " 2   month          900 non-null    int64  \n",
      " 3   station_name   895 non-null    object \n",
      " 4   visibility     892 non-null    float64\n",
      " 5   precipitation  900 non-null    float64\n",
      " 6   temperature    900 non-null    float64\n",
      " 7   num_people     900 non-null    int64  \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 56.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           300 non-null    object \n",
      " 1   day_of_week    300 non-null    object \n",
      " 2   month          300 non-null    int64  \n",
      " 3   station_name   300 non-null    object \n",
      " 4   visibility     300 non-null    float64\n",
      " 5   precipitation  300 non-null    float64\n",
      " 6   temperature    300 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 16.5+ KB\n",
      "None\n",
      "            month  visibility  precipitation  temperature    num_people\n",
      "count  900.000000  892.000000     900.000000   900.000000    900.000000\n",
      "mean     6.122222    9.996512       9.339334    15.070645  12556.747778\n",
      "std      3.314202    2.039593       6.721645     9.914046   1827.065461\n",
      "min      1.000000    3.223144       0.008814   -17.394377   7261.000000\n",
      "25%      3.000000    8.627064       4.002631     8.513877  11314.500000\n",
      "50%      6.000000   10.043633       8.004760    14.994892  12558.000000\n",
      "75%      9.000000   11.427402      13.151872    21.865623  13766.000000\n",
      "max     12.000000   16.509295      37.604911    51.577018  18186.000000\n",
      "            month  visibility  precipitation  temperature\n",
      "count  300.000000  300.000000     300.000000   300.000000\n",
      "mean     6.486667   10.191748       9.098002    16.307271\n",
      "std      2.834892    2.032578       6.845629    10.172719\n",
      "min      2.000000    4.818908       0.030805   -11.267863\n",
      "25%      4.000000    8.598862       3.660717    10.510916\n",
      "50%      6.500000   10.301550       7.895151    16.573051\n",
      "75%      9.000000   11.575936      12.958960    23.227468\n",
      "max     11.000000   16.991756      29.344086    40.625277\n",
      "date             0\n",
      "day_of_week      0\n",
      "month            0\n",
      "station_name     5\n",
      "visibility       8\n",
      "precipitation    0\n",
      "temperature      0\n",
      "num_people       0\n",
      "dtype: int64\n",
      "date             0\n",
      "day_of_week      0\n",
      "month            0\n",
      "station_name     0\n",
      "visibility       0\n",
      "precipitation    0\n",
      "temperature      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Columns: 916 entries, month to station_name_Sillim Station\n",
      "dtypes: bool(912), float64(3), int64(1)\n",
      "memory usage: 829.8 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Columns: 916 entries, month to station_name_Sillim Station\n",
      "dtypes: bool(290), float64(3), int64(623)\n",
      "memory usage: 1.5 MB\n",
      "None\n",
      "(720, 916)\n",
      "(180, 916)\n",
      "(720,)\n",
      "(180,)\n",
      "[14232.57 13978.17 11011.84 12321.08 10767.14 11109.88 16614.31 14371.92\n",
      " 12598.59 13217.6  13909.38 12702.59 11140.38 11872.71 15622.69 16024.54\n",
      " 14873.63 13681.16 13741.79 13177.29 13009.42 12824.77 11313.05 13090.75\n",
      " 12911.33 13766.62 12646.44 10984.8  16765.5  11714.24 10776.76 10963.56\n",
      " 14127.24 12819.28 11123.7  13922.4  13941.56 14547.62 11074.68 15704.62\n",
      " 12035.55 10700.49 14308.19 12781.44 13111.84 14461.57 12498.9  11511.54\n",
      " 11077.72 12798.21  9980.75 12157.77 13489.23 13742.93 14882.52 14878.81\n",
      " 14984.74 12503.83 10134.75 14715.08 14269.71 15431.37 11385.63 12893.89\n",
      " 15263.07 12850.23 11410.9  15353.8  14682.32 10373.31 13818.83 14314.73\n",
      " 10685.39 12420.52  9099.23 12641.3  12910.03 11529.98 11947.39 11521.6\n",
      " 16266.04 13089.93 13818.61 12137.42 14165.51 12821.5  12737.36 12816.42\n",
      " 11225.31 13417.53 15032.44 14062.34 12393.39 13681.01 11433.57 13002.47\n",
      " 12770.02 11463.87 11797.31 12957.33 15065.42 12730.25  8765.32 12468.41\n",
      " 10999.1  12197.87 11640.58 15788.24 13612.48 10792.16 13528.32 11399.09\n",
      " 13529.94 10817.55 12735.2  14499.28 10820.69 12498.97 12228.97 13000.69\n",
      " 14334.86 16694.57 12080.73 14178.65 12092.13 10717.1  12654.27 11699.38\n",
      " 13018.58 12734.06 14405.09 13542.43 14551.73 13727.06 12607.68 11001.89\n",
      " 11885.21 13807.22 12432.6  13896.97 13322.06 12770.02 12807.71 12699.29\n",
      " 11243.88  9153.45  8712.12 12262.14  8618.14 12844.42 13956.41 11658.13\n",
      " 12394.65 14723.94 12797.61 11687.54 13675.34 11203.94 12420.97 14750.14\n",
      " 12746.05 13497.78 13934.83 11412.72 13378.23 12619.01 11935.05 14332.23\n",
      " 10170.07 12641.55 10857.88 12866.14 12294.97 10470.38 14105.1  10674.08\n",
      " 11023.8  11560.38 14408.89 14650.25]\n",
      "663.4968888888889\n",
      "[12038.28 11567.51 12736.87 13128.18 14093.14 12667.23 12480.88 12306.74\n",
      " 10386.68 14115.16 12668.05 13442.71 13590.23 13542.23 14019.22 11928.76\n",
      " 13341.61 12460.56 12854.29 11854.31 13132.62 13352.06 14257.04 13865.43\n",
      " 14263.42 12084.49 11445.96 11138.01 12190.98  9634.81 14147.48 12461.99\n",
      " 12623.21  9033.2  12700.98 13844.29 10539.79 12202.02 12454.7  10994.26\n",
      " 13492.56 11380.16 11974.01 14647.43 12238.54 13238.5  13137.7  14087.09\n",
      " 12349.45 11753.15 12995.83 11155.79 16215.01 13253.65 10561.46  9161.83\n",
      " 12410.47 11693.53 12567.85 13645.49 13152.5  12522.1  14954.85 11139.55\n",
      " 12814.75 11048.02 14846.69  8765.28  9103.21 12196.87 14995.07 14225.65\n",
      " 12896.97 14041.05 12236.53 14466.11 10679.4  12574.22 12745.92 10299.22\n",
      " 14664.27 12849.17 11802.13 14390.74 10305.61 15253.16 14708.03 12136.85\n",
      " 14503.04 10242.3  13023.3  10440.83 13245.34 15199.8  15443.24 14757.33\n",
      " 11424.5  10736.05 13317.45 14681.31 15250.75  8703.51 15571.22 13224.55\n",
      " 11168.93 13805.79 14733.33 12695.2  10448.52 11411.2  13928.94 12479.28\n",
      " 13749.31 14541.08 13770.87 13914.76 12650.12 13007.64 10672.95 11179.6\n",
      " 14324.19 12028.47 12580.8  14855.23 12582.86 13089.64 11737.9  12061.11\n",
      " 15524.15 12703.99 15159.34 11010.63 12822.03 12116.38 15067.51 14174.95\n",
      " 13703.9  14171.31 11317.73 12176.49  9847.34 11837.6  12364.41 12416.65\n",
      " 14141.8  12703.83 10938.56 13040.29 12790.92 12599.87 10469.61 11508.96\n",
      " 12423.39 11551.34 13792.44 11864.41  9922.48  8829.72 11595.49 11330.13\n",
      " 14084.84 15935.28 12979.52 10622.75 14021.45 12048.62 10922.96 10525.31\n",
      " 14879.2  15821.38  8226.27 12042.83 13715.56 11379.67 13811.48 11576.53\n",
      " 13794.04 11304.75 13754.99 13319.24 12535.24 13733.7  12026.22 11167.78\n",
      " 15188.74 12576.77 11627.29 13638.84 10458.04 15788.69 12396.34 10539.57\n",
      " 14745.23 12015.95 12686.23 12405.09 14236.19 12884.48 11648.32 13905.47\n",
      " 13439.61 12752.14 15108.2  13000.99 11644.47 14036.47 15160.62 11425.93\n",
      " 12582.2  15316.29 14466.31 11098.88 11200.1  13242.91 14494.12 14405.68\n",
      " 13423.54 12063.99 12433.96 11626.48 12745.46  9619.36 15492.42  9387.41\n",
      " 13801.22 12344.95 14631.73 12477.36 11333.87 12770.03 10764.15 12722.18\n",
      " 14557.61  8903.54 13485.93 11657.54 11678.76 14290.74 10690.24 11842.85\n",
      " 13866.59 14621.71 12701.58 10577.42 13051.27 14120.21 12176.15 12923.7\n",
      " 13917.54 11524.01 14837.87 11785.37 11773.66 10876.81 13317.62 10356.02\n",
      " 11954.39 12574.37 11902.87 12309.12 13625.93 12791.88  8668.88 15868.54\n",
      " 15054.62 15379.79 12770.27 14633.58 12292.44 11823.14 12110.   11317.7\n",
      " 12505.79  8051.22 13077.92 13910.58 12789.45 15381.01 12081.93 15512.24\n",
      " 11286.94 14213.88 13894.51 12589.24  9113.53 12504.75 12673.9  15460.93\n",
      " 14619.52 16339.42 14575.11 11202.31 11230.72 13962.82 12878.5  14236.13\n",
      " 16210.85 15626.88 13990.3  14403.18]\n",
      "         pred\n",
      "0    12038.28\n",
      "1    11567.51\n",
      "2    12736.87\n",
      "3    13128.18\n",
      "4    14093.14\n",
      "..        ...\n",
      "295  14236.13\n",
      "296  16210.85\n",
      "297  15626.88\n",
      "298  13990.30\n",
      "299  14403.18\n",
      "\n",
      "[300 rows x 1 columns]\n",
      "         date day_of_week  month     station_name  visibility  precipitation  \\\n",
      "0  2023-02-01   Wednesday      2  Hongdae Station    8.181270       8.811098   \n",
      "1  2023-02-02   Wednesday      2  Gangnam Station   10.057751      18.851489   \n",
      "2  2023-02-03      Friday      2   Jamsil Station    9.895961      11.771597   \n",
      "3  2023-02-04   Wednesday      2   Sillim Station   13.283054       1.346370   \n",
      "4  2023-02-05   Wednesday      2   Sillim Station    9.832798       4.033435   \n",
      "\n",
      "   temperature  \n",
      "0    11.411536  \n",
      "1    15.566285  \n",
      "2    16.331512  \n",
      "3    18.014205  \n",
      "4    22.576629  \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "# 데이터셋 임의 생성\n",
    "df1 = pd.read_csv('./datasets/P240622-01.csv')\n",
    "df2 = pd.read_csv('./datasets/P240622-02.csv')\n",
    "\n",
    "# [확인] 행, 열 개수 확인\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "\n",
    "# [확인] info() : category나 object 있는지 확인 => 있을 경우 원-핫 인코딩\n",
    "print(df1.info())\n",
    "print(df2.info())\n",
    "\n",
    "# [확인] describe() : 이상치 확인 => 있을 경우 대체(0, 평균값, 중앙값, 최빈값 등)\n",
    "print(df1.describe())\n",
    "print(df2.describe())\n",
    "\n",
    "# [확인] isna().sum() : 결측치 확인 => 있을 경우 대체 => fillna()\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "y = df1['num_people']   # 종속 변수\n",
    "x = df1.drop('num_people', axis=1)    # 독립 변수\n",
    "\n",
    "x_test = df2.copy()   # 테스트 데이터\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "# 테스트 데이터의 열을 학습 데이터에 맞추기\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "# [확인] 원-핫 인코딩 성공 여부\n",
    "print(x_encoded.info())\n",
    "print(x_test_encoded.info())\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.2)\n",
    "\n",
    "# [확인] 분할 여부 확인\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestRegressor()\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_valid)\n",
    "print(pred)\n",
    "\n",
    "# 성능 평가\n",
    "result = mean_absolute_error(y_valid, pred)   # MAE\n",
    "print(result)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "pred = md.predict(x_test_encoded)\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred\n",
    "})\n",
    "print(result)\n",
    "result.to_csv('./outputs/20241112_Q7.csv', index=False)\n",
    "\n",
    "# [확인]\n",
    "print(df2.head())\n",
    "print(len(df2) == 2064)   # 최종 제출 컬럼 크기 확인 (문제 제시)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 8 (시험장 환경 체험 예제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 백화점 고객이 1년간 상품을 구매한 속성 데이터\n",
    "- 제공된 학습용 데이터(`customer_train.csv`)를 이용하여 백화점 구매 고객의 성별을 예측하는 모델을 개발하고, 개발한 모델에 기반하여 평가용 데이터(`customer_test.csv`)에 적용하여 성별 예측하기\n",
    "\n",
    "```text\n",
    "예측 결과는 ROC-AUC 평가 지표에 따라 평가\n",
    "예측 성별 컬럼명 : pred\n",
    "제출 컬럼 개수 : 1개\n",
    "평가용 데이터 개수와 예측 결과 데이터 개수 일치 : 2482개\n",
    "pred 컬럼 데이터 개수 : 2,482개\n",
    "학습용 데이터 : 3,500개\n",
    "평가용 데이터 : 2,482개\n",
    "```\n",
    "\n",
    "|pred|\n",
    "|:-:|\n",
    "|0|\n",
    "|1|\n",
    "|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv(\"./datasets/customer_train.csv\")\n",
    "df2 = pd.read_csv(\"./datasets/customer_test.csv\")\n",
    "\n",
    "# 라벨 인코딩 (객체 -> 수치형)\n",
    "le_product = LabelEncoder()\n",
    "le_store = LabelEncoder()\n",
    "\n",
    "df1['주구매상품'] = le_product.fit_transform(df1['주구매상품'])  \n",
    "df2['주구매상품'] = le_product.transform(df2['주구매상품']) \n",
    "\n",
    "df1['주구매지점'] = le_store.fit_transform(df1['주구매지점']) \n",
    "df2['주구매지점'] = le_store.transform(df2['주구매지점'])  \n",
    "\n",
    "# 결측값 처리 (평균값으로 대체)\n",
    "# print(\"결측치 확인 (df1\", df1.isnull().sum())\n",
    "# print(\"결측치 확인 (df2\", df2.isnull().sum())\n",
    "\n",
    "df1['환불금액'] = df1['환불금액'].fillna(df1['환불금액'].mean())   # 평균값으로 대체\n",
    "df2['환불금액'] = df2['환불금액'].fillna(df2['환불금액'].mean())   # 평균값으로 대체\n",
    "\n",
    "# 종속 변수 범주형으로 변환\n",
    "df1['성별'] = df1['성별'].astype('category')\n",
    "\n",
    "# 독립 변수, 종속 변수 분리\n",
    "x = df1.drop('성별', axis=1)\n",
    "y = df1['성별']\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x = x.drop('회원ID', axis=1)\n",
    "\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.2)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = md.predict(x_valid)\n",
    "proba = md.predict_proba(x_valid)[:, :1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_valid, proba)\n",
    "print(roc_auc)\n",
    "\n",
    "# 성능 평가\n",
    "cm = confusion_matrix(y_valid, pred, labels=[1, 0])\n",
    "print(cm)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2.copy()\n",
    "x_test = x_test.drop('회원ID', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test) # 원-핫 인코딩\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "pred = md.predict(x_test_encoded)   # 예측\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "\t'pred': pred\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "train = pd.read_csv(\"./datasets/customer_train.csv\")\n",
    "test = pd.read_csv(\"./datasets/customer_test.csv\")\n",
    "\n",
    "train['환불금액'] = train['환불금액'].fillna(0)\n",
    "test['환불금액'] = test['환불금액'].fillna(0)\n",
    "\n",
    "### 필요없는 변수 제거\n",
    "train = train.drop('회원ID', axis=1)\n",
    "test = test.drop('회원ID', axis=1)\n",
    "\n",
    "# print(train.info())\n",
    "# print(test.info())\n",
    "\n",
    "## (2) 독립/종속 변수 설정\n",
    "x = train.drop('성별', axis=1)\n",
    "y = train['성별']\n",
    "\n",
    "## (2) 원핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "x_test_encoded = pd.get_dummies(test)\n",
    "\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "## (3) 데이터 분할\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.2)\n",
    "\n",
    "## (4) 모델링\n",
    "from sklearn.ensemble import *\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "## (5) 예측\n",
    "pred = model.predict(x_valid)\n",
    "print(pred[:10])\n",
    "\n",
    "## (6) 평가\n",
    "from sklearn.metrics import *\n",
    "roc_auc = roc_auc_score(y_valid, pred)\n",
    "print(roc_auc)\n",
    "\n",
    "## (7) 테스트 데이터 예측\n",
    "pred = model.predict(x_test_encoded)\n",
    "print(pred[:10])\n",
    "\n",
    "\n",
    "result = pd.DataFrame({\n",
    "\t'pred': pred\n",
    "})\n",
    "result.to_csv('result.csv', index=False)\n",
    "\n",
    "result = pd.read_csv('result.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 9 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 고객이 가입한 서비스와 계정 정보, 인구에 대한 통계 정보가 들어 있는 `telco-customer-churn` 데이터\n",
    "- 훈련 데이터(`M1-4-1.csv`)를 이용하여 모델을 훈련한 후 테스트 데이터(`M1-4-2.csv`)로 고객의 이탈 여부를 예측하기\n",
    "    - 이탈 : `Yes`, 유지 : `No`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[562 118]\n",
      " [ 53 111]]\n",
      "0.79739336492891\n",
      "0.4847161572052402\n",
      "0.676829268292683\n",
      "0.5648854961832062\n",
      "0.6992686477083111\n",
      "[0 0 1 ... 0 1 0]\n",
      "     pred\n",
      "0      No\n",
      "1      No\n",
      "2     Yes\n",
      "3     Yes\n",
      "4     Yes\n",
      "...   ...\n",
      "3652   No\n",
      "3653   No\n",
      "3654   No\n",
      "3655  Yes\n",
      "3656   No\n",
      "\n",
      "[3657 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/M1-4-1.csv')\n",
    "df2 = pd.read_csv('./datasets/M1-4-2.csv')\n",
    "\n",
    "# 라벨 인코딩 (Object -> Int)\n",
    "columns_to_encode = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df1[col])\n",
    "\n",
    "    df1[col] = le.transform(df1[col])\n",
    "    df2[col] = le.transform(df2[col])\n",
    "\n",
    "# Churn 컬럼의 값에서 Yes -> 0, No -> 1로 매핑\n",
    "df1['Churn'] = df1['Churn'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "\n",
    "df2['Churn'] = df2['Churn'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "})\n",
    "\n",
    "# 자료형 변환\n",
    "df1['Churn'] = df1['Churn'].astype('category')\n",
    "\n",
    "\n",
    "# 독립 변수, 종속 변수 분리\n",
    "x = df1.drop('Churn', axis=1)\n",
    "y = df1['Churn']\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestClassifier(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 검증 데이터 평가\n",
    "x_valid_encoded = pd.get_dummies(x_valid)\n",
    "x_valid_encoded = x_valid_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "# 예측\n",
    "pred_valid = md.predict(x_valid_encoded)\n",
    "\n",
    "# 성능 평가\n",
    "cm = confusion_matrix(pred_valid, y_valid)\n",
    "print(cm)\n",
    "\n",
    "print(accuracy_score(y_valid, pred_valid))\n",
    "print(recall_score(y_valid, pred_valid))\n",
    "print(precision_score(y_valid, pred_valid))\n",
    "print(f1_score(y_valid, pred_valid))\n",
    "print(roc_auc_score(y_valid, pred_valid))\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2.drop('Churn', axis=1)\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)   # 원-핫 인코딩\n",
    "x_test_encoded = x_test_encoded.reindex(columns=x_encoded.columns, fill_value=0)\n",
    "\n",
    "pred_new = md.predict(x_test_encoded)   # 예측\n",
    "pred_new_label = ['No' if pred == 0 else 'Yes' for pred in pred_new]\n",
    "print(pred_new)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred_new_label\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 10 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32개 자동차들의 디자인과 성능을 비교한 `mtcars` 데이터\n",
    "\n",
    "> (1) 훈련 데이터와 평가 데이터를 순서대로 7.5 : 2.5로 분할하기\n",
    "\n",
    "> (2) 종속 변수는 연비(`mpg`), 독립 변수를 차측 비율(`dart`), 무게(`wt`), 전진 기어 개수(`gear`), 기화기 개수(`carb`)로 선형 회귀 모형 만들기\n",
    "\n",
    "> (3) 생성된 모델을 RMSE로 평가하고 결과를 반올림하여 소수점 셋째 자리로 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kss34\\anaconda3\\envs\\bigdata\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3530474509211956\n",
      "[14.67       32.376      30.40666667 33.82266667 21.58133333 15.57466667\n",
      " 18.66333333 18.1        14.303      24.384      22.80066667 19.17666667\n",
      " 17.8        16.392      17.3        15.221      10.4        10.4\n",
      " 14.67       32.376      30.40666667 33.82266667 21.58133333 15.57466667\n",
      " 18.66333333 18.1        14.303      24.384      22.80066667 19.17666667\n",
      " 17.8        16.392      17.3        15.221      10.4        10.4\n",
      " 14.67       32.376      30.40666667 33.82266667 21.58133333 15.57466667]\n",
      "         pred\n",
      "0   14.670000\n",
      "1   32.376000\n",
      "2   30.406667\n",
      "3   33.822667\n",
      "4   21.581333\n",
      "5   15.574667\n",
      "6   18.663333\n",
      "7   18.100000\n",
      "8   14.303000\n",
      "9   24.384000\n",
      "10  22.800667\n",
      "11  19.176667\n",
      "12  17.800000\n",
      "13  16.392000\n",
      "14  17.300000\n",
      "15  15.221000\n",
      "16  10.400000\n",
      "17  10.400000\n",
      "18  14.670000\n",
      "19  32.376000\n",
      "20  30.406667\n",
      "21  33.822667\n",
      "22  21.581333\n",
      "23  15.574667\n",
      "24  18.663333\n",
      "25  18.100000\n",
      "26  14.303000\n",
      "27  24.384000\n",
      "28  22.800667\n",
      "29  19.176667\n",
      "30  17.800000\n",
      "31  16.392000\n",
      "32  17.300000\n",
      "33  15.221000\n",
      "34  10.400000\n",
      "35  10.400000\n",
      "36  14.670000\n",
      "37  32.376000\n",
      "38  30.406667\n",
      "39  33.822667\n",
      "40  21.581333\n",
      "41  15.574667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "df1 = pd.read_csv('./datasets/M2-4-1.csv')\n",
    "df2 = pd.read_csv('./datasets/M2-4-2.csv')\n",
    "\n",
    "# 독립 변수, 종속 변수 분할\n",
    "x = df1.drop('mpg', axis=1)\n",
    "y = df1['mpg']\n",
    "\n",
    "# 원-핫 인코딩\n",
    "x_encoded = pd.get_dummies(x)\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_encoded, y, test_size=0.25)\n",
    "\n",
    "# 모델링\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train, y_train)\n",
    "\n",
    "# 평가\n",
    "pred = md.predict(x_valid)\n",
    "result = root_mean_squared_error(y_valid, pred)   # RMSE\n",
    "print(result)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "x_test = df2\n",
    "\n",
    "x_test_encoded = pd.get_dummies(x_test)   # 원-핫 인코딩\n",
    "\n",
    "# 공통된 열 추출하기\n",
    "common_features = list(set(x_encoded.columns).intersection(x_test_encoded.columns))\n",
    "\n",
    "x_train_common = x_encoded[common_features]\n",
    "x_test_common = x_test_encoded[common_features]\n",
    "\n",
    "# 모델링 (한번 더)\n",
    "md = RandomForestRegressor(n_estimators=300)\n",
    "md.fit(x_train_common, y)\n",
    "\n",
    "# 평가\n",
    "pred = md.predict(x_test_common)\n",
    "print(pred)\n",
    "\n",
    "# CSV 내보내기\n",
    "result = pd.DataFrame({\n",
    "    'pred': pred\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('./outputs/20241112_Q8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제3유형\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 1 (23년 6회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감기약을 복용할 때 부작용에 대한 분류와 비율 데이터\n",
    "- 위약 효과가 있는지 253건의 데이터를 추출하여 검증하려고 한다.\n",
    "- 감기 부작용에 대한 비율이 위약 효과 부작용 비율과 같은지 카이제곱 검정하기\n",
    "\n",
    "|부작용 유형|코드|비율|\n",
    "|:-:|:-:|:-:|\n",
    "|두통|1|0.05|\n",
    "|졸림|2|0.1|\n",
    "|속쓰림|3|0.05|\n",
    "|부작용 없음|4|0.8|\n",
    "|합계| |1|\n",
    "\n",
    "> (1) 위약 샘플 데이터가 `부작용 없음`인 데이터를 0~1 사이의 확률로 출력하기 (반올림하여 소수점 셋째 자리로 출력)\n",
    "\n",
    "> (2) 카이제곱 검정으로 검정 통계량 출력하기 (반올림하여 소수점 셋째 자리로 출력)\n",
    "\n",
    "> (3) 유의확률(p-value) 출력하기 (반올림하여 소수점 셋째 자리로 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787\n",
      "Power_divergenceResult(statistic=0.9970355731225298, pvalue=0.801969260894451)\n",
      "0.997\n",
      "0.802\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "df = pd.read_csv('./datasets/P230605.csv', encoding='euckr')\n",
    "\n",
    "# 코드별로 그룹화 및 비율 계산하여 컬럼 추가\n",
    "df_placebo = df.groupby('코드').size().reset_index(name='건수')\n",
    "\n",
    "total_count = len(df)\n",
    "df_placebo['비율'] = df_placebo['건수'] / total_count\n",
    "\n",
    "# (1) 위약 샘플 데이터가 '부작용 없음'인 데이터를 0~1 사이의 확률로 출력하기\n",
    "answer1 = round(df_placebo['비율'][3], 3)\n",
    "print(answer1)\n",
    "\n",
    "# (2) 카이제곱 검정으로 검정 통계량 출력하기\n",
    "df_rate = pd.DataFrame({\n",
    "    '코드': [1, 2, 3, 4],\n",
    "    '비율' : [0.05, 0.1, 0.05, 0.8]\n",
    "})\n",
    "result_chisquare = chisquare(df_placebo['건수'], f_exp=df_rate['비율'] * total_count)\n",
    "print(result_chisquare)\n",
    "\n",
    "answer2 = round(result_chisquare.statistic, 3)\n",
    "print(answer2)\n",
    "\n",
    "# (3) 유의 확률(p-value) 구하기\n",
    "answer3 = round(result_chisquare.pvalue, 3)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기출 변형 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   코드   건수\n",
      "0   1   15\n",
      "1   2   25\n",
      "2   3   17\n",
      "3   4  196\n",
      "(1) 위약 샘플 데이터 '부작용 없음' 확률: 0.775\n",
      "0     12.65\n",
      "1     25.30\n",
      "2     12.65\n",
      "3    202.40\n",
      "Name: 비율, dtype: float64\n",
      "(2) 카이제곱 검정 통계량: 2.138\n",
      "(3) 유의확률(p-value): 0.544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# 가상 데이터 생성 \n",
    "np.random.seed(42)\n",
    "sample_size = 253\n",
    "\n",
    "effect_rates = {\n",
    "    1: 0.05,  # 두통\n",
    "    2: 0.1,   # 졸림\n",
    "    3: 0.05,  # 속쓰림\n",
    "    4: 0.8    # 부작용 없음\n",
    "}\n",
    "\n",
    "sample_data = np.random.choice(list(effect_rates.keys()), size=sample_size, p=list(effect_rates.values()))\n",
    "df = pd.DataFrame(sample_data, columns=['코드'])\n",
    "\n",
    "# (1) 위약 샘플 데이터가 '부작용 없음'인 데이터를 0~1 사이의 확률로 출력하기\n",
    "df_placebo = df.groupby('코드').size().reset_index(name='건수')\n",
    "print(df_placebo)\n",
    "\n",
    "total_count = len(df)\n",
    "df_placebo['비율'] = df_placebo['건수'] / total_count\n",
    "\n",
    "# '부작용 없음' 비율\n",
    "answer1 = round(df_placebo['비율'][df_placebo['코드'] == 4].values[0], 3)\n",
    "print(\"(1) 위약 샘플 데이터 '부작용 없음' 확률:\", answer1)\n",
    "\n",
    "# (2) 카이제곱 검정으로 검정 통계량 구하기\n",
    "df_rate = pd.DataFrame({\n",
    "    '코드': [1, 2, 3, 4],\n",
    "    '비율' : [0.05, 0.1, 0.05, 0.8]\n",
    "})\n",
    "\n",
    "## 기대값 계산\n",
    "expected_counts = df_rate['비율'] * total_count\n",
    "print(expected_counts)\n",
    "\n",
    "## 카이제곱 검정\n",
    "statistics, pvalue = chisquare(df_placebo['건수'], f_exp=expected_counts)\n",
    "answer2 = round(statistics, 3)\n",
    "print(\"(2) 카이제곱 검정 통계량:\", answer2)\n",
    "\n",
    "# (3) 유의확률(p-value) 구하기\n",
    "answer3 = round(pvalue, 3)\n",
    "print(\"(3) 유의확률(p-value):\", answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2 (23년 6회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 날씨 데이터\n",
    "- 다중 선형 회귀 모델을 사용하여 오존(`O3`), 일사량(`Solar`), 풍속(`Wind`) 변수에 대한 온도(`Temperature`)를 예측하는 모델 생성하기\n",
    "\n",
    "> (1) 오존농도 변수에 대한 회귀계수 추정값 출력하기 (반올림하여 소수점 셋째 자리로 출력)\n",
    "\n",
    "> (2) 오존농도, 일사량이 고정일 때 풍속이 증가함에 따라 온도가 낮아진다는 것을 검증했다. t-검증 값의 유의확률(p-value) 구하기 (반올림하여 소수점 셋째 자리로 출력)\n",
    "\n",
    "> (3) 어떤 날이 오존농도 10, 일사량 90, 풍속 20일 때 온도의 예측값 구하기 (반올림하여 소수점 셋째 자리로 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Coefficient\n",
      "0      O3     0.171966\n",
      "1   Solar     0.007276\n",
      "2    Wind    -0.322945\n",
      "0.172\n",
      "0.0\n",
      "68.334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('./datasets/P230606.csv', encoding='euckr')\n",
    "\n",
    "x = df[['O3', 'Solar', 'Wind']]\n",
    "y = df['Temperature']\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(x, y)\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': ['O3', 'Solar', 'Wind'],\n",
    "    'Coefficient': lm.coef_\n",
    "})\n",
    "print(coefs)\n",
    "    \n",
    "# (1) 오존농도 변수에 대한 회귀 계수 추정값 구하기\n",
    "answer1 = round(float(coefs[coefs['Feature'] == 'O3']['Coefficient'].iloc[0]), 3)\n",
    "print(answer1)\n",
    "\n",
    "# (2) 오존농도, 일사량이 고정일 때 풍속이 증가함에 따라 온도가 낮아지는 것을 t-검증을 이용하여 유의 확률(p-value) 구하기\n",
    "[statistic, p_value] = ttest_ind(x['Wind'], y)\n",
    "answer2 = round(p_value, 3)\n",
    "print(answer2)\n",
    "\n",
    "# (3) 어떤 날이 오존농도 10, 일사량 90, 풍속 20일 때 온도의 예측값 구하기 \n",
    "df_oneday = pd.DataFrame({\n",
    "    'O3': [10],\n",
    "    'Solar': [90],\n",
    "    'Wind': [20]\n",
    "})\n",
    "answer3 = lm.predict(df_oneday)\n",
    "answer3 = np.round(answer3[0], 3)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기출 변형 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 방법 1 : `sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Coefficient\n",
      "0      O3     0.060398\n",
      "1   Solar    -0.028957\n",
      "2    Wind    -0.117663\n",
      "(1) 오존농도 변수에 대한 회귀 계수: 0.06\n",
      "(2) t-검증 p-value: 0.026\n",
      "(3) 예측된 온도: 18.644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 가상의 날씨 데이터 생성\n",
    "np.random.seed(42)  \n",
    "n_samples = 100\n",
    "\n",
    "O3 = np.random.uniform(0, 200, n_samples)   # 오존 농도 (0~200 사이의 값)\n",
    "Solar = np.random.uniform(0, 1000, n_samples)  # 일사량 (0~1000 사이의 값)\n",
    "Wind = np.random.uniform(0, 20, n_samples)    # 풍속 (0~20 사이의 값)\n",
    "Temperature = 25 + 0.05 * O3 - 0.03 * Solar - 0.2 * Wind + np.random.normal(0, 5, n_samples)  # 온도\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'O3': O3,\n",
    "    'Solar': Solar,\n",
    "    'Wind': Wind,\n",
    "    'Temperature': Temperature\n",
    "})\n",
    "\n",
    "# 선형 회귀 모델 학습\n",
    "X = df[['O3', 'Solar', 'Wind']]    # 독립 변수\n",
    "y = df['Temperature']              # 종속 변수\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': ['O3', 'Solar', 'Wind'],\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "print(coefs)\n",
    "\n",
    "# (1) 오존농도 변수에 대한 회귀 계수 추정값 구하기\n",
    "answer1 = round(float(coefs[coefs['Feature'] == 'O3']['Coefficient'].iloc[0]), 3)\n",
    "print(\"(1) 오존농도 변수에 대한 회귀 계수:\", answer1)\n",
    "\n",
    "# (2) 오존농도, 일사량이 고정일 때 풍속이 증가함에 따라 온도가 낮아지는 것을 t-검증을 이용하여 유의 확률(p-value) 구하기\n",
    "statistic, p_value = ttest_ind(x['Wind'], y)\n",
    "\n",
    "answer2 = round(p_value, 3)\n",
    "print(\"(2) t-검증 p-value:\", answer2)\n",
    "\n",
    "# (3) 어떤 날이 오존농도 10, 일사량 90, 풍속 20일 때 온도의 예측값 구하기\n",
    "df_oneday = pd.DataFrame({\n",
    "    'O3': [10],\n",
    "    'Solar': [90],\n",
    "    'Wind': [20]\n",
    "})\n",
    "\n",
    "answer3 = model.predict(df_oneday)\n",
    "answer3 = np.round(answer3[0], 3)\n",
    "print(\"(3) 예측된 온도:\", answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 방법 2 : `statsmodels.api.OLS()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            Temperature   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.779\n",
      "Method:                 Least Squares   F-statistic:                     117.4\n",
      "Date:                Sat, 16 Nov 2024   Prob (F-statistic):           5.35e-32\n",
      "Time:                        21:49:16   Log-Likelihood:                -299.12\n",
      "No. Observations:                 100   AIC:                             606.2\n",
      "Df Residuals:                      96   BIC:                             616.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         22.9999      1.639     14.032      0.000      19.746      26.253\n",
      "O3             0.0604      0.008      7.261      0.000       0.044       0.077\n",
      "Solar         -0.0290      0.002    -16.978      0.000      -0.032      -0.026\n",
      "Wind          -0.1177      0.085     -1.381      0.170      -0.287       0.051\n",
      "==============================================================================\n",
      "Omnibus:                        5.375   Durbin-Watson:                   2.376\n",
      "Prob(Omnibus):                  0.068   Jarque-Bera (JB):                4.964\n",
      "Skew:                          -0.402   Prob(JB):                       0.0836\n",
      "Kurtosis:                       3.738   Cond. No.                     1.94e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.94e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "(1) 오존농도(O3) 변수에 대한 회귀 계수: 0.06\n",
      "(2) 풍속(Wind)에 대한 t-검증 p-value: 0.17\n",
      "(3) 예측된 온도: 18.644\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 가상의 날씨 데이터 생성\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "O3 = np.random.uniform(0, 200, n_samples)   # 오존 농도 (0~200 사이의 값)\n",
    "Solar = np.random.uniform(0, 1000, n_samples)  # 일사량 (0~1000 사이의 값)\n",
    "Wind = np.random.uniform(0, 20, n_samples)    # 풍속 (0~20 사이의 값)\n",
    "Temperature = 25 + 0.05 * O3 - 0.03 * Solar - 0.2 * Wind + np.random.normal(0, 5, n_samples)  # 온도\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'O3': O3,\n",
    "    'Solar': Solar,\n",
    "    'Wind': Wind,\n",
    "    'Temperature': Temperature\n",
    "})\n",
    "\n",
    "# 독립 변수에 상수항 추가 (statsmodels에서는 상수항을 명시적으로 추가해야 함)\n",
    "X = df[['O3', 'Solar', 'Wind']]   # 독립 변수\n",
    "X = sm.add_constant(X)  # 상수항 추가\n",
    "\n",
    "y = df['Temperature']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "# (1) 회귀 계수 추정값 출력 (오존농도에 대한 회귀 계수)\n",
    "answer1 = round(model.params['O3'], 3)\n",
    "\n",
    "print(\"(1) 오존농도(O3) 변수에 대한 회귀 계수:\", answer1)\n",
    "\n",
    "# (2) t-검증 p-value 출력\n",
    "answer2 = round(model.pvalues['Wind'], 3)\n",
    "\n",
    "print(\"(2) 풍속(Wind)에 대한 t-검증 p-value:\", answer2)\n",
    "\n",
    "# (3) 예측값 계산\n",
    "new_data = pd.DataFrame({\n",
    "    'const': [1],  # 상수항\n",
    "    'O3': [10],\n",
    "    'Solar': [90],\n",
    "    'Wind': [20]\n",
    "})\n",
    "\n",
    "answer3 = model.predict(new_data)\n",
    "answer3 = np.round(answer3[0], 3)\n",
    "\n",
    "print(\"(3) 예측된 온도:\", answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 3 (23년 7회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 종속 변수 : `Target`\n",
    "\n",
    "> (1) 선형 관계 가장 큰 변수 찾아 상관 계수 구하기\n",
    "\n",
    "> (2) `Target` 변수를 종속 변수로 하여 다중 선형 회귀 모델링을 진행했을 때 `v2` 컬럼의 회귀 계수 구하기\n",
    "\n",
    "> (3) 회귀 계수들이 가지는 p-값들 중 최대값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6270251925517436\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 5.228e+04\n",
      "Date:                Sat, 16 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        19:37:44   Log-Likelihood:                -707.67\n",
      "No. Observations:                1000   AIC:                             1459.\n",
      "Df Residuals:                     978   BIC:                             1567.\n",
      "Df Model:                          21                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0118      0.016      0.739      0.460      -0.019       0.043\n",
      "v1             5.5360      0.016    353.805      0.000       5.505       5.567\n",
      "v2             6.4403      0.016    410.550      0.000       6.410       6.471\n",
      "v3             9.6506      0.016    614.757      0.000       9.620       9.681\n",
      "v4             8.9758      0.016    576.776      0.000       8.945       9.006\n",
      "v5             1.9523      0.016    124.711      0.000       1.922       1.983\n",
      "v6             0.0145      0.016      0.899      0.369      -0.017       0.046\n",
      "v7            -0.0023      0.016     -0.140      0.888      -0.034       0.029\n",
      "v8             0.0173      0.016      1.096      0.274      -0.014       0.048\n",
      "v9            -0.0123      0.016     -0.781      0.435      -0.043       0.019\n",
      "v10           -0.0019      0.016     -0.117      0.906      -0.033       0.030\n",
      "v11            0.0171      0.016      1.099      0.272      -0.013       0.048\n",
      "v12            0.0161      0.016      1.018      0.309      -0.015       0.047\n",
      "v13           -0.0167      0.016     -1.058      0.290      -0.048       0.014\n",
      "v14            0.0068      0.016      0.412      0.681      -0.026       0.039\n",
      "v15           -0.0432      0.017     -2.605      0.009      -0.076      -0.011\n",
      "v16            0.0117      0.016      0.749      0.454      -0.019       0.043\n",
      "v17            0.0156      0.015      1.012      0.312      -0.015       0.046\n",
      "v18            0.0100      0.016      0.628      0.530      -0.021       0.041\n",
      "v19           -0.0174      0.016     -1.119      0.263      -0.048       0.013\n",
      "v20            0.0098      0.015      0.637      0.524      -0.020       0.040\n",
      "v21            0.0015      0.016      0.092      0.927      -0.030       0.033\n",
      "==============================================================================\n",
      "Omnibus:                        4.701   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.095   Jarque-Bera (JB):                4.745\n",
      "Skew:                          -0.167   Prob(JB):                       0.0932\n",
      "Kurtosis:                       2.955   Cond. No.                         1.32\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "6.440301364843059\n",
      "0.9265545986907169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kss34\\AppData\\Local\\Temp\\ipykernel_8816\\1785163409.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  answer1 = target.sort_values(ascending=False)[1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import *\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('./datasets/P230705.csv')\n",
    "\n",
    "# (1) 선형 관계 가장 큰 변수 찾아 상관 계수 구하기\n",
    "corr_df = df.corr()\n",
    "target = corr_df['Target']\n",
    "answer1 = target.sort_values(ascending=False)[1]\n",
    "print(answer1)\n",
    "\n",
    "# (2) Target 변수를 종속 변수로 하여 다중 선형 회귀 모델링을 진행했을 때 v2 컬럼의 회귀 계수 구하기\n",
    "\n",
    "x = df.drop('Target', axis=1)   # 독립 변수\n",
    "x = sm.add_constant(x)   # 상수항 추가\n",
    "y = df['Target']   # 종속 변수\n",
    "\n",
    "## OLS는 \"Ordinary Least Squares\"의 약자로, 선형 회귀 분석 방법 중 하나이다. statsmodels.api의 일부로서, OLS 클래스를 사용하여 선형 회귀 모델을 정의할 수 있다.\n",
    "md = sm.OLS(y, x).fit()\n",
    "summary = md.summary()\n",
    "print(summary)\n",
    "\n",
    "answer2 = md.params['v2']\n",
    "print(answer2)\n",
    "\n",
    "# (3) 회귀 계수들이 가지는 p-값들 중 최대값 구하기\n",
    "answer3 = md.pvalues.max()\n",
    "print(answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기출 변형 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              v1        v2        v3        v4        v5    Target\n",
      "v1      1.000000 -0.066107 -0.036512  0.021895 -0.005389  0.872265\n",
      "v2     -0.066107  1.000000 -0.124047 -0.061987 -0.114401 -0.383313\n",
      "v3     -0.036512 -0.124047  1.000000 -0.115117  0.062719  0.310146\n",
      "v4      0.021895 -0.061987 -0.115117  1.000000  0.033356 -0.011590\n",
      "v5     -0.005389 -0.114401  0.062719  0.033356  1.000000  0.036221\n",
      "Target  0.872265 -0.383313  0.310146 -0.011590  0.036221  1.000000\n",
      "(1) 선형 관계 가장 큰 변수의 상관 계수: 0.8723\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.960\n",
      "Model:                            OLS   Adj. R-squared:                  0.957\n",
      "Method:                 Least Squares   F-statistic:                     447.0\n",
      "Date:                Sat, 16 Nov 2024   Prob (F-statistic):           7.20e-64\n",
      "Time:                        19:52:55   Log-Likelihood:                -443.47\n",
      "No. Observations:                 100   AIC:                             898.9\n",
      "Df Residuals:                      94   BIC:                             914.6\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2852      9.174      0.358      0.721     -14.929      21.500\n",
      "v1             3.0453      0.073     41.575      0.000       2.900       3.191\n",
      "v2            -2.1320      0.155    -13.754      0.000      -2.440      -1.824\n",
      "v3             0.5132      0.036     14.452      0.000       0.443       0.584\n",
      "v4            -0.0582      0.093     -0.624      0.534      -0.244       0.127\n",
      "v5            -0.3720      0.705     -0.528      0.599      -1.771       1.027\n",
      "==============================================================================\n",
      "Omnibus:                        2.625   Durbin-Watson:                   1.810\n",
      "Prob(Omnibus):                  0.269   Jarque-Bera (JB):                2.212\n",
      "Skew:                          -0.361   Prob(JB):                        0.331\n",
      "Kurtosis:                       3.101   Cond. No.                         577.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(2) v2 변수의 회귀 계수: -2.1320\n",
      "(3) 회귀 계수의 p-값 중 최대값: 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kss34\\AppData\\Local\\Temp\\ipykernel_8816\\3716619668.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  most_correlated_variable = target_corr.sort_values(ascending=False)[1]  # 'Target' 제외한 가장 높은 상관 변수\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 가상 데이터 생성\n",
    "np.random.seed(0)  # 재현성을 위해 시드 설정\n",
    "n_samples = 100\n",
    "\n",
    "# 독립 변수(v1 ~ v5) 및 종속 변수(Target) 생성\n",
    "data = {\n",
    "    'v1': np.random.rand(n_samples) * 100,\n",
    "    'v2': np.random.rand(n_samples) * 50,\n",
    "    'v3': np.random.rand(n_samples) * 200,\n",
    "    'v4': np.random.rand(n_samples) * 80,\n",
    "    'v5': np.random.rand(n_samples) * 10,\n",
    "}\n",
    "\n",
    "# Target 변수는 v1, v2, v3에 영향을 받도록 생성\n",
    "data['Target'] = (\n",
    "    3 * data['v1'] - 2 * data['v2'] + 0.5 * data['v3'] +\n",
    "    np.random.randn(n_samples) * 20  # 노이즈 추가\n",
    ")\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# (1) 선형 관계 가장 큰 변수 찾아 상관 계수 구하기\n",
    "corr_df = df.corr()\n",
    "print(corr_df)\n",
    "\n",
    "target_corr = corr_df['Target']\n",
    "most_correlated_variable = target_corr.sort_values(ascending=False)[1]  # 'Target' 제외한 가장 높은 상관 변수\n",
    "\n",
    "print(f\"(1) 선형 관계 가장 큰 변수의 상관 계수: {most_correlated_variable:.4f}\")\n",
    "\n",
    "# (2) Target 변수를 종속 변수로 하여 다중 선형 회귀 모델링을 진행했을 때 v2 컬럼의 회귀 계수 구하기\n",
    "x = df.drop('Target', axis=1)\n",
    "x = sm.add_constant(x)  # 상수항 추가\n",
    "y = df['Target']\n",
    "\n",
    "# 다중 선형 회귀 분석 모델 생성\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "v2_coef = model.params['v2']\n",
    "print(f\"(2) v2 변수의 회귀 계수: {v2_coef:.4f}\")\n",
    "\n",
    "# (3) 회귀 계수들이 가지는 p-값들 중 최대값 구하기\n",
    "max_pvalue = model.pvalues.max()\n",
    "print(f\"(3) 회귀 계수의 p-값 중 최대값: {max_pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 4 (23년 7회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 심장병 발병 예측\n",
    "- 종속 변수 : `target 1` (발병)\n",
    "- train 데이터는 앞의 210개 행을, test 데이터는 나머지 부분을 사용\n",
    "\n",
    "> (1) train 데이터로 `target`을 종속 변수로 로지스틱 회귀를 진행할 때, `age` 컬럼의 오즈비 구하기\n",
    "\n",
    "> (2) train 데이터로 로지스틱 회귀를 진행했을 경우 잔차 이탈도(Residual Deviance) 계산하기\n",
    "\n",
    "> (3) train 데이터로 로지스틱 회귀를 진행했을 경우 로짓 우도값 도출하기\n",
    "\n",
    "> (4) test 데이터의 독립 변수로 `target` 예측 후 오류율 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343347\n",
      "         Iterations 7\n",
      "0.9562078844664191\n",
      "144.205620063278\n",
      "-72.102810031639\n",
      "0.1954022988505747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('./datasets/P230706.csv')\n",
    "\n",
    "train_data = df[:210].reset_index(drop=True)\n",
    "test_data = df[210:].reset_index(drop=True)\n",
    "\n",
    "# (1) train 데이터로 target을 종속 변수로 로지스틱 회귀를 진행할 때, age 컬럼의 오즈비 구하기\n",
    "x = train_data.drop('target', axis=1)   # 독립 변수\n",
    "y = train_data['target']   # 종속 변수\n",
    "\n",
    "model1 = sm.Logit(y, x).fit()\n",
    "\n",
    "answer1 = np.exp(model1.params['age'])\n",
    "print(answer1)\n",
    "\n",
    "# (2) train 데이터로 로지스틱 회귀를 진행했을 경우 잔차 이탈도 계산하기\n",
    "model2 = sm.GLM(y, x, family=sm.families.Binomial()).fit()\n",
    "\n",
    "answer2 = model2.deviance\n",
    "print(answer2)\n",
    "\n",
    "# (3) train 데이터로 로지스틱 회귀를 진행했을 경우 로짓 우도값 도출하기\n",
    "answer3 = model1.llf\n",
    "print(answer3)\n",
    "\n",
    "# (4) test 데이터의 독립변수로 target 예측 후 오류율 구하기\n",
    "data = test_data.drop('target', axis=1)\n",
    "pred = model1.predict(data)\n",
    "\n",
    "pred = (pred > 0.5).astype('int')\n",
    "target = test_data['target']\n",
    "answer3 = 1 - accuracy_score(target, pred)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기출 변형 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.676137\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      194\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sat, 16 Nov 2024   Pseudo R-squ.:                0.003669\n",
      "Time:                        21:15:27   Log-Likelihood:                -135.23\n",
      "converged:                       True   LL-Null:                       -135.73\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.9629\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9495      1.424     -0.667      0.505      -3.740       1.841\n",
      "age            0.0011      0.010      0.107      0.915      -0.019       0.021\n",
      "chol           0.0012      0.003      0.370      0.712      -0.005       0.008\n",
      "trestbps       0.0029      0.006      0.470      0.638      -0.009       0.015\n",
      "thalach       -0.0019      0.005     -0.376      0.707      -0.012       0.008\n",
      "oldpeak        0.0549      0.102      0.537      0.591      -0.145       0.255\n",
      "==============================================================================\n",
      "(1) 오즈비 (age): 1.001112327790342\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                  200\n",
      "Model:                            GLM   Df Residuals:                      194\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -135.23\n",
      "Date:                Sat, 16 Nov 2024   Deviance:                       270.45\n",
      "Time:                        21:15:27   Pearson chi2:                     200.\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.004967\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.9495      1.424     -0.667      0.505      -3.740       1.841\n",
      "age            0.0011      0.010      0.107      0.915      -0.019       0.021\n",
      "chol           0.0012      0.003      0.370      0.712      -0.005       0.008\n",
      "trestbps       0.0029      0.006      0.470      0.638      -0.009       0.015\n",
      "thalach       -0.0019      0.005     -0.376      0.707      -0.012       0.008\n",
      "oldpeak        0.0549      0.102      0.537      0.591      -0.145       0.255\n",
      "==============================================================================\n",
      "(2) 잔차 이탈도: 270.45483621802725\n",
      "(3) 로짓 우도값: -135.22741810901363\n",
      "(4) 오류율: 0.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 가상의 데이터 생성\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 300\n",
    "data = {\n",
    "    'age': np.random.randint(30, 80, n_samples),               # 나이 (30~80세)\n",
    "    'chol': np.random.randint(150, 300, n_samples),            # 콜레스테롤 수치 (150~300)\n",
    "    'trestbps': np.random.randint(100, 180, n_samples),        # 안정 시 혈압 (100~180)\n",
    "    'thalach': np.random.randint(100, 200, n_samples),         # 최대 심박수 (100~200)\n",
    "    'oldpeak': np.random.uniform(0, 5, n_samples),             # ST depression induced by exercise\n",
    "    'target': np.random.binomial(1, 0.4, n_samples)            # 심장병 발병 여부 (0 또는 1, 40% 확률)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# train/test 데이터 분할\n",
    "train_data = df[:200].reset_index(drop=True)\n",
    "test_data = df[200:].reset_index(drop=True)\n",
    "\n",
    "# [1] train 데이터로 로지스틱 회귀 분석 수행\n",
    "X = train_data.drop('target', axis=1)   # 독립 변수\n",
    "X = sm.add_constant(X)                  # 상수항 추가\n",
    "y = train_data['target']               # 종속 변수\n",
    "\n",
    "# 로지스틱 회귀 모델 생성\n",
    "model1 = sm.Logit(y, X).fit()\n",
    "\n",
    "summary1 = model1.summary()\n",
    "print(summary1)\n",
    "\n",
    "# (1) 오즈비 계산 (age)|\n",
    "answer1 = np.exp(model1.params['age'])\n",
    "print(\"(1) 오즈비 (age):\", answer1)\n",
    "\n",
    "# (2) 잔차 이탈도 계산\n",
    "model2 = sm.GLM(y, X, family=sm.families.Binomial()).fit()    # GLM(Generalized Linear Models) 모델링, Bionomial : 로지스틱 회귀\n",
    "\n",
    "summary2 = model2.summary()\n",
    "print(summary2)\n",
    "\n",
    "answer2 = model2.deviance\n",
    "print(\"(2) 잔차 이탈도:\", answer2)\n",
    "\n",
    "# (3) 로짓 우도값(Log-Likelihood) 계산\n",
    "answer3 = model1.llf\n",
    "print(\"(3) 로짓 우도값:\", answer3)\n",
    "\n",
    "# (4) test 데이터로 target 예측 후 오류율(Error Rate) 계산\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "X_test = sm.add_constant(X_test)    # 상수항 추가\n",
    "y_test = test_data['target']\n",
    "\n",
    "pred = model1.predict(X_test)\n",
    "\n",
    "## 방법 1 (1 - Accuracy 구하기)\n",
    "pred = (pred > 0.5).astype(int)    # 예측된 확률값을 0.5 기준으로 이진 분류하여 변환 (0.5 초과 : 1, 0.5 이하 : 0)\n",
    "\n",
    "error_rate = 1 - accuracy_score(y_test, pred)   # Error Rate = 1 - Accuracy\n",
    "# print(\"(4) 오류율:\", error_rate)\n",
    "\n",
    "## 방법 2 (혼동 행렬 이용하기)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "# 오류율 계산\n",
    "error_rate = (cm[0, 1] + cm[1, 0]) / cm.sum()   # 오차 행렬에서 오답의 합을 전체로 나누기\n",
    "print(\"(4) 오류율:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 5 (24년 8회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) 로지스틱 회귀를 적용하여 유의하지 않은 변수의 개수 구하기\n",
    "    - 상수항을 추가해야 한다.\n",
    "    - 종속 변수 : 고객이탈지수\n",
    "\n",
    "> statsmodels 방식으로 풀어서 0.05보다 큰 값을 고르면 되는 문제였습니다. 회귀식에서는 귀무가설:회귀식의 해당 변수가 영향력이 없다 vs 대립가설:회귀식의 해당변수가 영향력이 있다 입니다. 그러므로 0.05 보다 작으면 대립가설 채택, 0.05보다 크면 귀무가설 채택(=해당 변수가 영향력이 없다=유의하지 않다) 입니다.\n",
    "\n",
    "- (2) 유의미한 변수만을 독립 변수로 하여 로지스틱 회귀 다시 적용한 후, 회귀 계수의 평균 구하기\n",
    "\n",
    "> 다시 생각났는데 회귀계수 평균을 구할때 저는 상수항을 빼고 구한 것 같습니다 b1+b2+b3 의 평균. 근데 bo+b1+b2+b3 까지 해서 구해야 해서 -0.456이 맞을 겁니다\n",
    "\n",
    "- (3) (2)에서 적용한 회귀식에서 calls 변수가 5증가하면 오즈비는 몇배 증가하는가?\n",
    "\n",
    "> ```text \n",
    "> np.exp(5*call 변수의 회귀계수 값) =7.919= 정답\n",
    "> 5 * np.exp(call 변수의 회귀계수값) =7.563= 오답\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "x = df.drop(columns=['이탈지수'])\n",
    "y = df['이탈지수']\n",
    "\n",
    "# 로지스틱 회귀모형 적합\n",
    "x = sm.add_constant(x)\n",
    "model = sm.Logit(y, x).fit()\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age의 weight 오즈비 계산\n",
    "odds_ratios = np.exp((model.params['calls']) * 5)\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기출 변형 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630233\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  churn   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       96\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 16 Nov 2024   Pseudo R-squ.:                 0.09077\n",
      "Time:                        09:45:55   Log-Likelihood:                -63.023\n",
      "converged:                       True   LL-Null:                       -69.315\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.005632\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2608      1.060      3.075      0.002       1.182       5.339\n",
      "age           -0.0345      0.019     -1.792      0.073      -0.072       0.003\n",
      "salary     -1.611e-05   8.89e-06     -1.812      0.070   -3.35e-05    1.32e-06\n",
      "calls         -0.0301      0.015     -2.026      0.043      -0.059      -0.001\n",
      "==============================================================================\n",
      "유의하지 않은 변수의 개수: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669250\n",
      "         Iterations 4\n",
      "유의미한 변수들에 대한 회귀 계수 평균: 0.35029495471365896\n",
      "calls 변수가 5 증가하면 오즈비는 0.8589494047822301배 증가합니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 예시 데이터 생성\n",
    "np.random.seed(23123123)\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 60, 100),\n",
    "    'salary': np.random.randint(30000, 120000, 100),\n",
    "    'calls': np.random.randint(0, 50, 100),\n",
    "    'churn': np.random.randint(0, 2, 100)  # 고객이탈지수 (종속변수)\n",
    "})\n",
    "\n",
    "# (1) 로지스틱 회귀 모델을 적용하여 유의하지 않은 변수 개수 구하기\n",
    "\n",
    "# 상수항 추가\n",
    "X = data[['age', 'salary', 'calls']]\n",
    "X = sm.add_constant(X)  # 상수항 추가\n",
    "y = data['churn']\n",
    "\n",
    "# 로지스틱 회귀 모델 적합\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "summary = result.summary()\n",
    "print(summary)\n",
    "\n",
    "# p-value 확인\n",
    "p_values = result.pvalues\n",
    "\n",
    "# 유의미하지 않은 변수 (p-value > 0.05)\n",
    "insignificant_vars = p_values[p_values > 0.05]\n",
    "print(f\"유의하지 않은 변수의 개수: {len(insignificant_vars)}\")\n",
    "\n",
    "# (2) 유의미한 변수만을 독립 변수로 하여 로지스틱 회귀를 다시 적용하고 회귀 계수의 평균 구하기\n",
    "significant_vars = p_values[p_values <= 0.05].index  # 유의미한 변수 추출 (p-value <= 유의수준)\n",
    "\n",
    "# 유의미한 변수가 있는지 확인\n",
    "if len(significant_vars) > 0:\n",
    "    X_significant = X[significant_vars]\n",
    "    logit_model_significant = sm.Logit(y, X_significant)\n",
    "    result_significant = logit_model_significant.fit()\n",
    "\n",
    "    # 회귀 계수의 평균 구하기\n",
    "    coefficients = result_significant.params\n",
    "    mean_coefficient = coefficients.mean()\n",
    "    print(f\"유의미한 변수들에 대한 회귀 계수 평균: {mean_coefficient}\")\n",
    "else:\n",
    "    print(\"유의미한 변수가 없습니다.\")\n",
    "\n",
    "# (3) 'calls' 변수가 5 증가할 때 오즈비 증가 배수 계산\n",
    "if 'calls' in significant_vars:\n",
    "    call_coeff = result_significant.params['calls']\n",
    "    odds_ratio_increase = np.exp(5 * call_coeff)\n",
    "    print(f\"calls 변수가 5 증가하면 오즈비는 {odds_ratio_increase}배 증가합니다.\")\n",
    "else:\n",
    "    print(\"'calls' 변수는 유의미하지 않거나 모델에 포함되지 않았습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 6 (24년 8회 기출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) 다중선형 회귀를 적용하여 가장 유의미한 변수의 회귀계수를 쓰시오\n",
    "    - 종속 변수 : `piq`\n",
    "    - 독립 변수 : `brain`. `height`, `weight`\n",
    "- (2) 결정 계수 값 구하기\n",
    "- (3) 위에서 적합하여 나온 다중선형회귀식에서 키:70, 몸무게:150, 뇌크기:90 일때의 piq 값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# (1) 유의미한 회귀 계수 쓰기\n",
    "x = df.drop(columns=['PIQ'])\n",
    "y = df['PIQ']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "summary = model.summary()\n",
    "print(summary)\n",
    "\n",
    "# 2.129\n",
    "# brain의 회귀계수의 p-value값이 가장 작았다. \n",
    "# p-value > 0.5이면 귀무가설 기각, 대립가설 채택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 결정 계수 구하기\n",
    "## 상수함 포함해서 결정계수 구한다.\n",
    "r_squared = model.rsquared\n",
    "print(r_squared)\n",
    "\n",
    "# 0.313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) PIQ 값 구하기\n",
    "PIQ = (brain * 90) + (height * 70) + (weight * 150)\n",
    "\n",
    "# 104.873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기출 변형 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회귀 결과 요약:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            house_price   R-squared:                       0.047\n",
      "Model:                            OLS   Adj. R-squared:                  0.017\n",
      "Method:                 Least Squares   F-statistic:                     1.574\n",
      "Date:                Fri, 15 Nov 2024   Prob (F-statistic):              0.201\n",
      "Time:                        02:03:29   Log-Likelihood:                -1377.9\n",
      "No. Observations:                 100   AIC:                             2764.\n",
      "Df Residuals:                      96   BIC:                             2774.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       7.002e+05   8.77e+04      7.988      0.000    5.26e+05    8.74e+05\n",
      "size        -676.8792    319.354     -2.120      0.037   -1310.792     -42.967\n",
      "location   -3044.8104   8910.179     -0.342      0.733   -2.07e+04    1.46e+04\n",
      "age          216.6799   1701.382      0.127      0.899   -3160.536    3593.895\n",
      "==============================================================================\n",
      "Omnibus:                        9.060   Durbin-Watson:                   2.075\n",
      "Prob(Omnibus):                  0.011   Jarque-Bera (JB):                3.390\n",
      "Skew:                           0.038   Prob(JB):                        0.184\n",
      "Kurtosis:                       2.101   Cond. No.                         703.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "결정 계수 (R-squared): 0.046868286704138895\n",
      "예측된 house_price: 551755.6794774851\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 예시 데이터 생성\n",
    "np.random.seed(123123)\n",
    "data = pd.DataFrame({\n",
    "    'size': np.random.randint(50, 300, 100),  # 주택 크기 (평수)\n",
    "    'location': np.random.randint(1, 10, 100),  # 위치 (1~10)\n",
    "    'age': np.random.randint(1, 50, 100),  # 나이 (년)\n",
    "    'house_price': np.random.randint(100000, 1000000, 100)  # 주택 가격\n",
    "})\n",
    "\n",
    "# (1) 다중선형 회귀 모델을 적용하여 가장 유의미한 변수의 회귀계수 구하기\n",
    "x = data[['size', 'location', 'age']]\n",
    "y = data['house_price']\n",
    "\n",
    "# 상수항 추가\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# 다중선형 회귀 모델 적합\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# 회귀 결과 출력\n",
    "summary = model.summary()\n",
    "print(\"회귀 결과 요약:\")\n",
    "print(summary)\n",
    "\n",
    "# (2) 결정 계수 구하기\n",
    "r_squared = model.rsquared\n",
    "print(f\"결정 계수 (R-squared): {r_squared}\")\n",
    "\n",
    "# (3) size=200, location=5, age=10 일 때 house_price 값 예측\n",
    "predicted_price = model.predict([1, 200, 5, 10])  # 상수항을 포함하여 예측\n",
    "print(f\"예측된 house_price: {predicted_price[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1) 다중선형 회귀를 적합한 후, summary()를 통해 회귀 계수를 확인합니다. size 변수의 p-value가 유의수준(0.05)보다 크므로, 귀무가설(해당 변수는 종속 변수에 영향을 미치지 않는다)를 기각하게 된다. 따라서 가장 유의미한 변수는 size이며, 이때 회귀 계수는 -676.8792이다.\n",
    ">\n",
    "> (2) model.rsquared를 사용하여 결정 계수 값을 구합니다.\n",
    ">\n",
    "> (3) 예측된 house_price 값을 구하는 방법을 보여줍니다. model.predict()에 상수항을 포함한 값을 넣어서 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 7 (시험장 환경 체험 예제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 타이타닉호의 침몰 사건에서 생존한 승객 및 사망한 승객의 정보를 담은 데이터\n",
    "- 생존 여부(`Survibed`) 예측\n",
    "\n",
    "> (1) `Gender`와 `Survived` 변수 간의 독립성 검정을 실시하였을 때, 카이제곱 통계량 구하기 (반올림하여 소수 셋째 자리까지 계산)\n",
    "\n",
    "> (2) `Gender`, `SibSp`, `Parch`, `Fare`를 독립 변수로 사용하여 로지스틱 회귀 모형을 실시하였을 때, `Parch` 변수의 계수값 구하기 (반올림하여 소수 셋째 자리까지 계산)\n",
    "\n",
    "> (3) (2)에서 추정된 로지스틱 회귀모형에서 `SibSp` 변수가 한 단위 증가할 때 생존할 오즈비(Odds Ratio) 값 구하기 (반올림하여 소수 셋째 자리까지 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260.717 / p-value 1.1973570627755645e-58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482065\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                          Logit   Df Residuals:                      886\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 17 Jun 2024   Pseudo R-squ.:                  0.2761\n",
      "Time:                        13:44:18   Log-Likelihood:                -429.52\n",
      "converged:                       True   LL-Null:                       -593.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.192e-69\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.9466      0.169      5.590      0.000       0.615       1.279\n",
      "Gender[T.male]    -2.6422      0.186    -14.197      0.000      -3.007      -2.277\n",
      "SibSp             -0.3539      0.098     -3.604      0.000      -0.546      -0.161\n",
      "Parch             -0.2007      0.112     -1.792      0.073      -0.420       0.019\n",
      "Fare               0.0147      0.003      5.553      0.000       0.010       0.020\n",
      "==================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482065\n",
      "         Iterations 6\n",
      "Intercept         0.946635\n",
      "Gender[T.male]   -2.642219\n",
      "SibSp            -0.353892\n",
      "Parch            -0.200724\n",
      "Fare              0.014685\n",
      "dtype: float64\n",
      "0.702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import *\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "df = pd.read_csv('./datasets/titanic.csv')\n",
    "\n",
    "# (1) Gender와 Survived 변수 간의 독립성 검정을 실시하였을 때, 카이제곱 통계량 구하기\n",
    "table =pd.crosstab(df['Gender'], df['Survived'])\n",
    "chi2, pvalue, dof, exp = chi2_contingency(table)   # 독립성 검정\n",
    "answer1 = round(chi2, 3)\n",
    "print(answer1, \"/ p-value\", pvalue)   # 유의 수준(0.5)보다 작으므로 대립가설 채택 (서로 독립)\n",
    "\n",
    "# (2) Gender, SibSp, Parch, Fare를 독립 변수로 사용하여 로지스틱 회귀 모형을 실시하였을 때, Parch 변수의 계수값 구하기\n",
    "answer2 = logit('Survived ~ Gender+SibSp+Parch+Fare', data=df).fit().summary()\n",
    "print(answer2)   # Parch 변수의 coef 값 확인 (-0.2007)\n",
    "\n",
    "# (3) SibSp 변수가 한 단위 증가할 때 생존할 오즈비 값 구하기\n",
    "result = logit('Survived ~ Gender+SibSp+Parch+Fare', data=df).fit().params\n",
    "print(result)\n",
    "answer3 = round(np.exp(result['SibSp']), 3)\n",
    "print(answer3)   # 0.702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 8 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5명의 환자를 대상으로 치료제를 복용하기 전과 후의 혈압을 측정하였다.\n",
    "- 치료제가 효과가 있는지 쌍체 표본 T-검정을 통해 답하고자 한다.\n",
    "    - 단, 표본이 정규성을 만족한다는 가정하에 단측 검정 수행\n",
    "\n",
    "```text\n",
    "μd : (치료 후 혈압 - 치료 전 혈압)의 평균\n",
    "H0 : μd ≥ 0 (치료 후 혈압과 치료 전 혈압의 차이에 대한 평균은 0보다 크거나 같다.)\n",
    "H1 : μd ≤ 0 (치료 후에 혈압이 더 낮아졌으므로 치료제의 효과가 있다.)\n",
    "```\n",
    "\n",
    "```text\n",
    "치료제 복용 전 5명의 환자들의 혈압 : 200, 210, 190, 180, 175\n",
    "치료제 복용 후 5명의 환자들의 혈압 : 180, 175, 160, 150, 160\n",
    "\n",
    "```\n",
    "\n",
    "> (1) 위의 가설을 검정하기 위한 검정 통계량 구하기 (소수 다섯째 자리까지 계산)\n",
    "\n",
    "> (2) 위의 통계량에 대한 p-값 구하기 (소수 다섯째 자리까지 계산)\n",
    "\n",
    "> (3) 유의수준 0.05 하에서 가설 검정의 결과를 (채택/기각) 중 하나를 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TtestResult(statistic=-7.076303701373625, pvalue=0.0010523957839292206, df=4)\n",
      "-7.0763\n",
      "0.00105\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'before': [200, 210, 190, 180, 175],\n",
    "    'after': [180, 175, 160, 150, 160]\n",
    "})\n",
    "\n",
    "result = ttest_rel(df['after'], df['before'], alternative='less')   # less : after의 평균이 before의 평균 보다 크거나 같다.\n",
    "print(result)\n",
    "\n",
    "# (1) 검정 통계량 구하기\n",
    "answer1 = round(result.statistic, 4)\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-값 구하기\n",
    "answer2 = round(result.pvalue, 5)\n",
    "print(answer2)\n",
    "\n",
    "# (3) 유의수준 0.05 하에서 가설 검정의 결과 출력하기\n",
    "answer3 = '기각' if answer2 < 0.05 else '채택'\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 9 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 뉴욕의 공기 오염도를 측정한 `airqty` 데이터\n",
    "- `Temp` 데이터는 온도를 나타낸다.\n",
    "- `airqty` 데이터에서 다음 가설에 대한 통계적 검정 수행하기 (양측 검정 수행)\n",
    "\n",
    "```text\n",
    "H0 : 뉴욕의 평균 온도(Temp 변수 값의 평균)는 75이다.\n",
    "H1 : 뉴욕의 평균 온도(Temp 변수 값의 평균)는 75가 아니다.\n",
    "```\n",
    "\n",
    "> (1) 위의 가설을 검정하기 위한 검정 통계량 구하기 (소수 셋째 자리까지 계산)\n",
    "\n",
    "> (2) 위의 통계량에 대한 p-값 구하기 (소수 넷째 자리까지 계산)\n",
    "\n",
    "> (3) 유의수준 0.05 하에서 가설 검정의 결과를 (채택/기각) 중 하나를 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9761729640090072, pvalue=0.009319356335949125)\n",
      "WilcoxonResult(statistic=0.0, pvalue=7.24267495195268e-27)\n",
      "0.0\n",
      "0.0\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import shapiro, wilcoxon\n",
    "\n",
    "df = pd.read_csv('./datasets/M1-6.csv')\n",
    "\n",
    "# 정규성 검정\n",
    "result = shapiro(df['Temp'])\n",
    "print(result)   # p-값이 유의수준 0.05보다 작으므로 대립가설 채택 (정규성 만족 X)\n",
    "\n",
    "# 윌콕슨 검정\n",
    "result = wilcoxon(df['Temp'], alternative='two-sided', zero_method='wilcox', correction=False)   # 양측 검정\n",
    "print(result)\n",
    "\n",
    "# (1) 검정 통계량 구하기\n",
    "answer1 = round(result.statistic, 3)\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-값 구하기\n",
    "answer2 = round(result.pvalue, 4)\n",
    "print(answer2)\n",
    "\n",
    "# (3) 유의수준 0.05 하에서 가설 검정의 결과 출력하기\n",
    "answer3 = '기각' if answer2 < 0.05 else '채택'\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 10 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 무작위로 100개의 값을 생성한 두 그룹(A, B)의 분산이 같은지에 대해 F-검정 수행하기\n",
    "    - A 그룹 : 1, 2, 3, 4, 6\n",
    "    - B 그룹 : 4, 5, 6, 7, 8\n",
    "\n",
    "```text\n",
    "H0 : 두 그룹의 분산은 같다.\n",
    "H1 : 두 그룹의 분산은 같지 않다.\n",
    "```\n",
    "\n",
    "> (1) 검정 통계량을 소수 2번째 자리까지 출력하기\n",
    "\n",
    "> (2) p-값을 소수 4번째 자리까지 출력하기\n",
    "\n",
    "> (3) 유의수준 0.05에서 귀무가설의 '채택', '기각' 여부 출력하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n",
      "2.5\n",
      "1.48\n",
      "0.7133\n",
      "채택\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "df1 = np.array([1, 2, 3, 4, 6])\n",
    "df2 = np.array([4, 5, 6, 7, 8])\n",
    "\n",
    "print(np.var(df1, ddof=1))   # 분산 구하기 (표본)\n",
    "print(np.var(df2, ddof=1))   # 분산 구하기 (표본)\n",
    "\n",
    "# F-검정 수행하기\n",
    "def f_test(x, y):\n",
    "    var_x = np.var(x, ddof=1)\n",
    "    var_y = np.var(y, ddof=1)\n",
    "\n",
    "    if var_x < var_y:\n",
    "        var_x, var_y = var_y, var_x\n",
    "    \n",
    "    f_value = var_x / var_y\n",
    "    x_dof = x.size - 1\n",
    "    y_dof = y.size - 1\n",
    "    p_value = round((1 - f.cdf(f_value, x_dof, y_dof)) * 2, 4)   # 양측 검정\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        result = '기각'\n",
    "    else:\n",
    "        result = '채택'\n",
    "    \n",
    "    return f_value, p_value, result\n",
    "\n",
    "\n",
    "result = f_test(df1, df2)\n",
    "\n",
    "# (1) 검정 통계량 출력하기\n",
    "answer1 = result[0]\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-값 출력하기\n",
    "answer2 = result[1]\n",
    "print(answer2)\n",
    "\n",
    "# (3) 유의수준 0.05 하에서 가설 검정의 결과 출력하기\n",
    "answer3 = result[2]\n",
    "print(answer3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 11 (연습 문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 콘서트장에서 남성이 340명, 여성이 540명이 있을 때 남성, 여성 비율이 35%와 65%인지를 카이제곱 검정을 이용하여 분석하는데, 적합도 검정 실시하기\n",
    "\n",
    "```text\n",
    "H0 : 콘서트장에서 남성, 여성의 비율은 35%와 65%\n",
    "H1 : 콘서트장에서 남성, 여성의 비율은 35%와 65%가 아님.\n",
    "```\n",
    "\n",
    "> (1) 검정 통계량을 소수 5번째 자리까지 출력하기\n",
    "\n",
    "> (2) p-값을 소수 5번째 자리까지 출력하기\n",
    "\n",
    "> (3) 유의수준 0.05에서 귀무가설의 '채택', '기각' 여부 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=5.114885114885115, pvalue=0.023721436858355486)\n",
      "5.11489\n",
      "0.02372\n",
      "기각\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "num = np.array([340, 540])\n",
    "expected = np.array([0.35, 0.65]) * np.sum(num)\n",
    "\n",
    "result = chisquare(f_obs=num, f_exp=expected)\n",
    "print(result)\n",
    "\n",
    "# (1) 검정 통계량 구하기\n",
    "answer1 = round(result.statistic, 5)\n",
    "print(answer1)\n",
    "\n",
    "# (2) p-값 구하기\n",
    "answer2 = round(result.pvalue, 5)\n",
    "print(answer2)\n",
    "\n",
    "# (3) 유의수준 0.05 하에서 가설 검정 결과 출력하기\n",
    "answer3 = '기각' if answer2 < 0.05 else '채택'\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단일 표본 T-검정 (One Sample T-Test)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 학교에서 10명의 학생들의 평균 키가 160cm인지 아닌지 검정하려고 한다. 학생들의 키는 다음과 같다.\n",
    "\n",
    "```text\n",
    "학생들의 키 (cm): [162, 159, 158, 160, 165, 163, 157, 161, 159, 160]\n",
    "```\n",
    "\n",
    "유의수준 0.05일 때, 이 학생들의 평균 키가 160cm인지 아닌지 검정하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규성 만족\n",
      "귀무 가설 채택\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp, shapiro, wilcoxon\n",
    "\n",
    "# 학생들의 키\n",
    "data = [162, 159, 158, 160, 165, 163, 157, 161, 159, 160]\n",
    "\n",
    "# 평균값\n",
    "avg_value = 160\n",
    "\n",
    "# [1] 정규성 검정 (표본의 개수가 30개 미만인 경우)\n",
    "stat, pvalue = shapiro(data)\n",
    "\n",
    "alpha = 0.05   # 유의수준\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print(\"정규성 만족\")\n",
    "\n",
    "    # [2] 단일 표본 T-검정\n",
    "    stats, pvalue = ttest_1samp(data, avg_value)\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"귀무 가설 채택\")\n",
    "    else:\n",
    "        print(\"귀무 가설 기각\")\n",
    "    \n",
    "else:\n",
    "    print(\"정규성 불만족\")\n",
    "\n",
    "    # [3] 윌콕슨 부호 순위 검정\n",
    "    stats, pvalue = wilcoxon(data - avg_value, alternative=\"two-sided\")   # 양측 검정\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"귀무 가설 채택\")\n",
    "    else:\n",
    "        print(\"귀무 가설 기각\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 회사에서 최근 10명의 직원들의 연봉을 조사한 결과, 직원들의 연봉은 다음과 같습니다(단위: 만원).\n",
    "\n",
    "```text\n",
    "직원들의 연봉(만원): [4500, 4800, 4700, 5000, 4600, 4900, 4850, 4700, 4550, 4800]\n",
    "```\n",
    "\n",
    "유의수준 0.05일 때, 이 회사의 직원들의 평균 연봉이 4700만원인지 아닌지 검정하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규성 만족\n",
      "귀무 가설 채택\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp, shapiro, wilcoxon\n",
    "\n",
    "# 학생들의 키\n",
    "data = [4500, 4800, 4700, 5000, 4600, 4900, 4850, 4700, 4550, 4800]\n",
    "\n",
    "# 평균값\n",
    "avg_value = 4700\n",
    "\n",
    "# [1] 정규성 검정 (표본의 개수가 30개 미만인 경우)\n",
    "stat, pvalue = shapiro(data)\n",
    "\n",
    "alpha = 0.05   # 유의수준\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print(\"정규성 만족\")\n",
    "\n",
    "    # [2] 단일 표본 T-검정\n",
    "    stats, pvalue = ttest_1samp(data, avg_value)\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"귀무 가설 채택\")\n",
    "    else:\n",
    "        print(\"귀무 가설 기각\")\n",
    "    \n",
    "else:\n",
    "    print(\"정규성 불만족\")\n",
    "\n",
    "    # [3] 윌콕슨 부호 순위 검정\n",
    "    stats, pvalue = wilcoxon(data - avg_value, alternative=\"two-sided\")   # 양측 검정\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print(\"귀무 가설 채택\")\n",
    "    else:\n",
    "        print(\"귀무 가설 기각\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   과목  남학생  여학생\n",
      "0  수학   30   35\n",
      "1  영어   40   30\n",
      "2  과학   20   35\n",
      "    남학생  여학생\n",
      "과목          \n",
      "수학   30   35\n",
      "영어   40   30\n",
      "과학   20   35\n",
      "귀무 가설 채택\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "data = {\n",
    "    '과목': ['수학', '영어', '과학'],\n",
    "    '남학생': [30, 40, 20],\n",
    "    '여학생': [35, 30, 35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\"\"\" 출력 결과\n",
    "   과목  남학생  여학생\n",
    "0  수학   30   35\n",
    "1  영어   40   30\n",
    "2  과학   20   35\n",
    "\"\"\"\n",
    "\n",
    "table = df.set_index('과목')   # <과목> 컬럼을 인덱스로 설정\n",
    "print(table)\n",
    "\n",
    "\"\"\" 출력 결과\n",
    "    남학생  여학생\n",
    "과목          \n",
    "수학   30   35\n",
    "영어   40   30\n",
    "과학   20   35\n",
    "\"\"\"\n",
    "\n",
    "stat, pvalue, dof, expected = chi2_contingency(table)\n",
    "\n",
    "alpha = 0.05   # 유의수준\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print(\"귀무 가설 채택\")\n",
    "else:\n",
    "    print(\"귀무 가설 기각\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
